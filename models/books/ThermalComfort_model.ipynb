{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFbVBvJjAfm4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import seaborn as sns\n",
        "from google.colab import data_table\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from imblearn.over_sampling import SMOTENC, SMOTE, RandomOverSampler\n",
        "\n",
        "from keras.utils.np_utils import to_categorical   \n",
        "from numpy import newaxis\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional, Embedding, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, accuracy_score, f1_score\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FUA64M-5JuA"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler, PolynomialFeatures, OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7qSacIRBARz",
        "outputId": "dba850d6-6e45-4d06-dc3b-71c6bb655d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuMaqqxYQQnl"
      },
      "source": [
        "# Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkTYZJoIhYiD"
      },
      "source": [
        "## Call Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm_oj5ZzQRBJ",
        "outputId": "9acb9907-74de-4034-ea29-f0d3acf4e7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original dataset shape Counter({0.0: 1959, -1.0: 1200, 1.0: 817, -2.0: 569, 2.0: 289})\n",
            "Original dataset shape Counter({2.0: 1959, 0.0: 1959, -1.0: 1200, 1.0: 817, -2.0: 569})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (5,35,36) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "df_ashrae = pd.read_csv(\"/content/drive/MyDrive/WPI/Deep Learning/Project/db_measurements_v2.1.0.csv\")\n",
        "\n",
        "df_ashrae_mod = df_ashrae[['age', 'gender', 't_out', 'ta', 'rh', 'vel', 'tr', 'thermal_acceptability',\n",
        "                           'thermal_preference', 'thermal_comfort', 'met', 'clo', 'thermal_sensation']]\n",
        "\n",
        "columns = df_ashrae_mod.columns\n",
        "df_ashrae_mod = df_ashrae_mod.dropna().reset_index().drop('index', axis = 1)         \n",
        "\n",
        "#Making the range from [-3,3] to[2,2]\n",
        "df_ashrae_mod['thermal_sensation'] = df_ashrae_mod['thermal_sensation'].apply(lambda x: -2 if x <= -2 else x)\n",
        "df_ashrae_mod['thermal_sensation'] = df_ashrae_mod['thermal_sensation'].apply(lambda x: 2 if x >= 2 else x)\n",
        "#Rounding off the values to make it categorical in nature \n",
        "df_ashrae_mod['thermal_sensation'] = df_ashrae_mod['thermal_sensation'].apply(lambda x: np.round(x))\n",
        "df_ashrae_mod = df_ashrae_mod.round(3)\n",
        "\n",
        "# Sampling Minority Data\n",
        "\n",
        "X = df_ashrae_mod.drop(['thermal_sensation'], axis = 1)\n",
        "y = df_ashrae_mod[ 'thermal_sensation']\n",
        "\n",
        "X = pd.get_dummies(X, columns =['gender', 'thermal_acceptability' , 'thermal_preference'])\n",
        "X = X.values\n",
        "y = y.values\n",
        "sm = RandomOverSampler(sampling_strategy = 'minority', random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "\n",
        "from collections import Counter\n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "print('Original dataset shape %s' % Counter(y_resampled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WkLY26NgF8L4",
        "outputId": "1635d59d-b047-46d3-d811-c29f11ae1a37"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ae902cbb-7d50-41c0-a25f-202fdfca65ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>t_out</th>\n",
              "      <th>ta</th>\n",
              "      <th>rh</th>\n",
              "      <th>vel</th>\n",
              "      <th>tr</th>\n",
              "      <th>thermal_acceptability</th>\n",
              "      <th>thermal_preference</th>\n",
              "      <th>thermal_comfort</th>\n",
              "      <th>met</th>\n",
              "      <th>clo</th>\n",
              "      <th>thermal_sensation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>55.0</td>\n",
              "      <td>female</td>\n",
              "      <td>15.1</td>\n",
              "      <td>23.41</td>\n",
              "      <td>49.55</td>\n",
              "      <td>0.155</td>\n",
              "      <td>23.548</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>cooler</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.379</td>\n",
              "      <td>0.49</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34.0</td>\n",
              "      <td>female</td>\n",
              "      <td>15.1</td>\n",
              "      <td>21.73</td>\n",
              "      <td>54.05</td>\n",
              "      <td>0.102</td>\n",
              "      <td>22.000</td>\n",
              "      <td>unacceptable</td>\n",
              "      <td>cooler</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.628</td>\n",
              "      <td>0.35</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40.0</td>\n",
              "      <td>female</td>\n",
              "      <td>15.1</td>\n",
              "      <td>21.21</td>\n",
              "      <td>55.70</td>\n",
              "      <td>0.067</td>\n",
              "      <td>21.312</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>no change</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.203</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27.0</td>\n",
              "      <td>female</td>\n",
              "      <td>15.1</td>\n",
              "      <td>21.46</td>\n",
              "      <td>55.62</td>\n",
              "      <td>0.060</td>\n",
              "      <td>21.550</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>no change</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.031</td>\n",
              "      <td>0.53</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31.0</td>\n",
              "      <td>female</td>\n",
              "      <td>15.1</td>\n",
              "      <td>22.23</td>\n",
              "      <td>52.57</td>\n",
              "      <td>0.106</td>\n",
              "      <td>22.328</td>\n",
              "      <td>acceptable</td>\n",
              "      <td>no change</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.688</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae902cbb-7d50-41c0-a25f-202fdfca65ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae902cbb-7d50-41c0-a25f-202fdfca65ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae902cbb-7d50-41c0-a25f-202fdfca65ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    age  gender  t_out     ta     rh    vel      tr thermal_acceptability  \\\n",
              "0  55.0  female   15.1  23.41  49.55  0.155  23.548            acceptable   \n",
              "1  34.0  female   15.1  21.73  54.05  0.102  22.000          unacceptable   \n",
              "2  40.0  female   15.1  21.21  55.70  0.067  21.312            acceptable   \n",
              "3  27.0  female   15.1  21.46  55.62  0.060  21.550            acceptable   \n",
              "4  31.0  female   15.1  22.23  52.57  0.106  22.328            acceptable   \n",
              "\n",
              "  thermal_preference  thermal_comfort    met   clo  thermal_sensation  \n",
              "0             cooler              5.0  1.379  0.49               -1.0  \n",
              "1             cooler              3.0  1.628  0.35                2.0  \n",
              "2          no change              6.0  1.203  0.94                0.0  \n",
              "3          no change              6.0  1.031  0.53               -1.0  \n",
              "4          no change              5.0  1.688  0.72                1.0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_ashrae_mod.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyA4yFRdhbm0"
      },
      "source": [
        "AV : Air Velocity OAT: Outdoor Air Temperature Gender RH: Relative Humidity Age IAT: Indoor Air Temperature MRT: Mean Radiant Temperature IRH: Indoor Relative Humidity CF: Clothing Insulation MR: Metabolic Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWkpuW8e0bhH"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIE799s1y1NP"
      },
      "source": [
        "## Machine Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-7_etSogR6d"
      },
      "outputs": [],
      "source": [
        "labels = ['very cold (-2)', 'cold (-1)', 'Neutral (0)', 'hot (1)', 'very hot (2)'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EdwOC2s9ooY",
        "outputId": "d7cc59f4-d19b-46d2-d2b7-4ad5d5a01be5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 52.4212\n",
            "f1 score : 0.5242\n",
            "MSE score : 1.2975\n",
            "\n",
            "\n",
            "Without Resampling\n",
            "Accuracy : 50.2585\n",
            "f1 score : 0.5026\n",
            "MSE score : 0.7725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Logisitc Regression \n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, accuracy_score\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "print('Accuracy : %.4f' % (accuracy_score(y_test, pred_lr)*100))\n",
        "print('f1 score : %.4f' % (f1_score(y_test, pred_lr, average='micro')))\n",
        "print('MSE score : %.4f' % (mean_squared_error(y_test, pred_lr)))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "print('\\n')\n",
        "print('Without Resampling')\n",
        "print('Accuracy : %.4f' % (accuracy_score(y_test, pred_lr)*100))\n",
        "print('f1 score : %.4f' % (f1_score(y_test, pred_lr, average='micro')))\n",
        "print('MSE score : %.4f' % (mean_squared_error(y_test, pred_lr)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "yqDaw2jMeCKj",
        "outputId": "aec016ac-c6c2-417c-db3b-377d1a1c6236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Confusion Matrix Thermal Sensation LR')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "\n",
        "confusion_Matrix = confusion_matrix(pred_lr, y_test)\n",
        "\n",
        "disp_train = ConfusionMatrixDisplay(confusion_matrix=confusion_Matrix, display_labels = labels)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
        "disp_train.plot()\n",
        "plt.title('Confusion Matrix Thermal Sensation LR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upY948Sl0JjN",
        "outputId": "05bba02d-a746-443d-a5c2-c70565cd0aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With Resampling\n",
            "Score of Logistic Regression Model : 53.8048\n",
            "f1 score : 0.5380\n",
            "MSE score : 1.1729\n",
            "\n",
            "\n",
            "Without Resampling\n",
            "Score of Logistic Regression Model : 40.4343\n",
            "f1 score : 0.4043\n",
            "MSE score : 1.2327\n"
          ]
        }
      ],
      "source": [
        "# k Nearest Neighbour\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train, y_train)\n",
        "pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "print('With Resampling')\n",
        "print('Score of Logistic Regression Model : %.4f' % (knn_model.score(X_test, y_test)*100))\n",
        "print('f1 score : %.4f' % (f1_score(y_test, pred_knn, average='micro')))\n",
        "print('MSE score : %.4f' % (mean_squared_error(y_test, pred_knn)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train, y_train)\n",
        "pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "print('\\n')\n",
        "print('Without Resampling')\n",
        "print('Score of Logistic Regression Model : %.4f' % (knn_model.score(X_test, y_test)*100))\n",
        "print('f1 score : %.4f' % (f1_score(y_test, pred_knn, average='micro')))\n",
        "print('MSE score : %.4f' % (mean_squared_error(y_test, pred_knn)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "c9MWx-8aesy8",
        "outputId": "5e5c4f2d-1386-4e36-99cf-6915b649cac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Confusion Matrix Thermal Sensation kNN')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "confusion_Matrix = confusion_matrix(pred_knn, y_test)\n",
        "\n",
        "disp_train = ConfusionMatrixDisplay(confusion_matrix=confusion_Matrix, display_labels = labels)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
        "disp_train.plot()\n",
        "plt.title('Confusion Matrix Thermal Sensation kNN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGgbVMbRu_kz",
        "outputId": "3561dda8-b2cb-48aa-cdf8-0a097ad51bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With Resampling\n",
            "Score of Logistic Regression Model : 68.8701\n",
            "f1 score : 0.6887\n",
            "MSE score : 0.4374\n",
            "\n",
            " Without Resampling\n",
            "Score of Logistic Regression Model : 55.0155\n",
            "f1 score : 0.5502\n",
            "MSE score : 0.6660\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "\n",
        "# Random Forest Classifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 540) # ideally the number of estimators in a random forest algorithm should be 10 x number of features\n",
        "clf.fit(X_train, y_train)\n",
        "pred_rf = clf.predict(X_test)\n",
        "MSE = mean_squared_error(y_test, pred_rf)\n",
        "# r2 = r2_score(pred_rf, y_test['Thermal comfort'])\n",
        "\n",
        "print('With Resampling')\n",
        "print('Score of Logistic Regression Model : %.4f' % (clf.score(X_test, y_test)*100))\n",
        "print('f1 score : %.4f' % (f1_score(y_test, pred_rf, average='micro')))\n",
        "print('MSE score : %.4f' % (mean_squared_error(y_test, pred_rf)))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 540) # ideally the number of estimators in a random forest algorithm should be 10 x number of features\n",
        "clf.fit(X_train, y_train)\n",
        "pred_rf = clf.predict(X_test)\n",
        "MSE = mean_squared_error(y_test, pred_rf)\n",
        "# r2 = r2_score(pred_rf, y_test['Thermal comfort'])\n",
        "\n",
        "print('\\n Without Resampling')\n",
        "print('Score of Logistic Regression Model : %.4f' % (clf.score(X_test, y_test)*100))\n",
        "print('f1 score : %.4f' % (f1_score(y_test, pred_rf, average='micro')))\n",
        "print('MSE score : %.4f' % (mean_squared_error(y_test, pred_rf)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "rMVptbiUgLMF",
        "outputId": "db892db8-8f92-4a4a-f910-9bfbe1dd537e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Confusion Matrix Thermal Sensation kNN')"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAIzCAYAAADicAgLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5xcddX48c/ZzaY3IBAgAQLSpIMhRFBAECnKA1b0sQDyE1BUUBAFH8UGgopSxQdEpEnxQQQRpShSpSR0CCXUhISE9BBSd8/vj5mEBZPNkmRmduZ+3q/XvDJz7517z9yZ7Jw533IjM5EkSWo0TbUOQJIkqRJMciRJUkMyyZEkSQ3JJEeSJDUkkxxJktSQutU6AEmSVB17f6BPTp3WWpVjjX50/k2ZuU9VDrYMJjmSJBXE1Gmt3H/T+lU5VvM6zw6qyoE6YHOVJElqSFZyJEkqiATaaKt1GFVjJUeSJDUkKzmSJBVG0ppWciRJkuqalRxJkgqi1CenOBfmtpIjSZIakpUcSZIKxNFVkiRJdc5KjiRJBZEkrWmfHEmSpLpmJUeSpAJxdJUkSVKdM8mRJEkNyeYqSZIKIoFWm6skSZLqm5UcSZIKxI7HkiRJdc5KjiRJBZHgZICSJEmVFBE9I+L+iHgkIp6IiB+Wl28YEfdFxNiIuCoiupeX9yg/HlteP2x5xzDJkSSpQNqqdOuE+cAembktsB2wT0SMBE4DfpWZGwPTgcPK2x8GTC8v/1V5uw6Z5EiSpKrLktfLD1vKtwT2AP6vvPxi4MDy/QPKjymv3zMioqNj2CdHkqSCSLKa8+QMiohR7R6fn5nnt98gIpqB0cDGwLnAc8CMzFxU3mQ8MKR8fwgwDiAzF0XETGANYMqyAjDJkSRJlTAlM4d3tEFmtgLbRcRA4Fpg81UZgEmOJElFkdDaBQdXZeaMiLgNeC8wMCK6las5Q4FXypu9AqwHjI+IbsAAYGpH+7VPjiRJqrqIWLNcwSEiegF7AWOA24BPlDc7GLiufP/68mPK6/+Z2fF4eCs5kiQVRNLpkU/VsA5wcblfThNwdWbeEBFPAldGxE+Ah4ALy9tfCFwaEWOBacCnl3cAkxxJklR1mfkosP1Slj8PjFjK8nnAJ9/JMUxyJEkqjKCVDkddNxT75EiSpIZkkiNJkhqSzVWSJBVEAm1dcAh5pVjJUU1ERK+I+EtEzIyIP67Efj4bETevythqISL+FhEHL3/Ld7zfjIiNV/V+V4WuHFtnRMRvIuJ7FdjvDyLislW9X6mITHLUoYj474gYFRGvR8TE8pfx+1bBrj8BDAbWyMx31Fu+vcy8PDM/tArieYuI2L38JXzt25ZvW17+r07up1NfWJm5b2ZevLzt3rbvE8vvy+sRMS8iWts9fuKd7KuriYgtI+LmiJgWETMiYnRE7FfDeA6JiLvaL8vMIzPzx1WO4wflz9+n2i3rVl42rPz49+XHI9pts3FEFOj3uzrSWu58XOlbV2CSo2WKiG8CZwCnUEpI1gd+TekiaStrA+CZdtcn6YpeA94bEWu0W3Yw8MyqOkCUrND/w8w8JTP7ZmZf4Ejg34sfZ+aWqyrGcpzVbtr+C3ALsDawFvB1YFaVY+iqpgE/LM8t0tE2P6lSPFKXZZKjpYqIAcCPgKMy80+ZOSczF2bmXzLzW+VtekTEGRExoXw7IyJ6lNftHhHjI+LYiJhcrgIdWl73Q+D7wEHlqsNhb694RMSw8q/RbuXHh0TE8xExOyJeiIjPtlt+V7vn7RwRD5SbwR6IiJ3brftXRPw4Iu4u7+fmiBjUwWlYAPyZ8oRT5S+Vg4DL33auzoyIcRExq1xxeH95+T7Aie1e5yPt4jg5Iu4G3gA2Ki/7f+X150XENe32f1pE/COi46vtduCDEfFsuSJybvv9RMQXI2JMREyPiJsiYoN26zIijoqIZ4Fn272nx7d7Tw+MiP0i4ply1eXEds8fERH/Lh93YkScExHdlxds+T3ZELggMxeUb3dnZvv3+SMR8XB53/dExDbt1r0YEcdFxKPlz8FVEdFz8b4j4oby86ZFxJ2Lk8yI+E5EPFf+bDwZER8tL3838BtKCe/rETGjvPz3UZqsbPFxvxQRY8v7vT4i1n3buTxyWe9DB+eiJSKuiIhr2p27v1P6bH6ug6deDGwTEbst7xgqlsRKjgSl64f0pHTBtGX5LjAS2A7YltLkTf/Tbv3alK4tMgQ4DDg3IlbLzJMoVYeuKlcdLqQDEdEHOAvYNzP7ATsDDy9lu9WBv5a3XQP4JfDXeGsl5r+BQylVB7oDx3V0bOAS4Avl+3sDjwMT3rbNA5TOwerAH4A/RkTPzPz7217ntu2e83ngcKAf8NLb9ncssHU5gXs/pXN38PKmL+/AR4AdgW2AT5VfBxFxAKUk7GPAmsCdwBVve+6BwE7AFuXHa1P6XAyhlKheQOnL9j3A+4HvRcSG5W1bgW8Agyh9nvYEvtKJeKcCY4HLyknU4PYrI2J74HfAEZTe5/8Fro9ygl32KWAfSsnSNsAh5eXHUrqq8ZqUqpMnwpJLMj9Xfg0DgB+Wj79OZo7hrZWygW8POCL2AH5aPu46lN7TK9+22VLfh2WJ0jT3fwbmA5/KzAXlVQl8DzgpIlqW8fQ3KH32Tu7oGFKjM8nRsqxB6QqyHTUnfRb4UWZOzszXKH0xfL7d+oXl9Qsz80bgdWCzFYynDdgqInpl5sTMXFqfkw8Dz2bmpZm5KDOvAJ4C9m+3zUWZ+UxmzgWuppScLFNm3gOsHhGbUUp2LlnKNpdl5tTyMU8HerD81/n7zHyi/JyFb9vfG5TO4y+By4CvZeb45eyvI6dm5ozMfJnSNWEWv+YjgZ9m5pjy+3wKpasBb9DuuT/NzGnl8wWl9/TkcsxXUkpgzszM2eX35ElKCS+ZOToz7y2/xhcpJSPLrSyUk7kPAC8CpwMTI+KOiNikvMnhwP9m5n2Z2VruyzSfUsK92FmZOSEzp1Fq+lr8mhdSSkI2KH8u71ycPGbmH8vPacvMq4BnWcqsq8vwWeB3mflgZs4HTqBU+RnWbptlvQ9L059SxeY54NDylZrbn6PrKTWn/r8O9vG/wPoRsW8nX4MKoi2jKreuwCRHyzIVGBQd98VYl7dWIV4qL1uyj7clSW8Afd9pIJk5h1Iz0ZGUvvD+GhGbdyKexTENaff41RWI51Lgq5S+eP+jslVuGhlTbhqZQakS0FEzGMC4jlZm5n3A80BQSsZWxrJe8wbAmeXmkxmU+nEEbz1fb49zarsv3MWJz6R26+cu3n9EbFpuGno1ImZRSqKWd14AyMzxmfnVzHxXOc45vJlgbgAcuzjucuzr8dbP3rJe888pVYlujlLz53cWbxQRX2jXBDYD2Kqz8fK2z15mvk7p/9CKfvZGUqr4nNpBBe9/KFVTey5tZTnZ+nH5JhWSSY6W5d+Ufh0f2ME2Eyh94Sy2Pv/ZlNNZc4De7R6v3X5lZt6UmXtR+hX+FKVmkuXFszimV1YwpsUupdTMcmO5yrJEuTnpeErND6uVmzJmwpIG6WV9QXXY9BQRR1GqCE0o778SxgFHZObAdrde5epVp+JcjvMovVebZGZ/Sk1D7/jnXWaOA86llHQsjvvkt8Xdu1y5W96+ZmfmsZm5EfBfwDcjYs9y9eoCSsnsGuX38XGW/z4u9pbPXrmJdQ1W/LN3M6Xmr3+8vbmu3Wu5hVLC1lET4EXAQEpNkpJ9ciSAzJxJqc/FueV+Eb3LnSD3jYiflTe7AvifiFiz3Fn0+5SaV1bEw8CuEbF+lDo9n7B4RUQMjogDyl8c8yk1ey3tQro3AptGadh7t4g4iFJfkhtWMCYAMvMFSs0s313K6n7AIkpNB90i4vuUmhoWmwQMi3cwgioiNqU0MuZzlJqtjo+IDpvVVtBvgBMiYsvycQdExAoP51+KfpRGRL1errx9uTNPiojVIuKHURr23FT+bH0RuLe8yQXAkRGxU5T0iYgPR0S/Tuz7I+X9BqVktJXSZ6kPpb//r5W3O5Q3kyoovY9DY9kdp68ADo2I7cp9g04B7is3062QzPwZpT5e/4hld5D/Lh0kweVK6knAt1c0DqmemeRomcr9S75JqSz+GqVf0F+l1BkSSl/Eo4BHgceAB1nBYavlX6VXlfc1mrcmJk3lOCZQalLZjaV8YWbmVEqdO4+l1FRwPPCRzJyyIjG9bd93ZebSqlQ3Ueo78Qyl5op5vLWJZ/FEh1Mj4sHlHafcPHgZcFpmPpKZz1KqgFz6to61Ky0zrwVOA64sNyc9DqzK/hvHUeroPZtSYnJVJ5+3ABgG3EopSXqcUnJ7SDnuUcCXgHOA6ZSqGYd0ct+blPf7OqVq5a8z87bMfJJS/59/U0potgbubve8fwJPAK9GxH98njLzVkqdga8BJgLvojwqb2VkaR6ePwO3ljvWv3393cD9y9nNFeWYJJKglaaq3LqCWPEBG5IkqZ68e5seeckN61TlWCM2eGl0Zg6vysGWwWtXSZJUIF1l5FM1dI16kiRJ0ipmJUeSpIJYPLqqKKzkSJKkhtSlKjndm3plr27LHQWqlbHClz+SuphFrcvfRislc2kzNWhVmpdzWJDz/cNcIV0qyenVrR87r3lQrcNobN2Xdakbqb60TZlW6xAaXs6fX+sQGt69i26q8hGD1ixOI05xXqkkSSqULlXJkSRJlZNAW4HqG8V5pZIkqVCs5EiSVCAOIZckSapzVnIkSSqITEdXSZIk1T0rOZIkFUibfXIkSZLqm5UcSZIKonSBzuLUN4rzSiVJUqFYyZEkqTAcXSVJklT3rORIklQQXrtKkiSpAZjkSJKkhmRzlSRJBdKaTgYoSZJU16zkSJJUEEk4GaAkSVK9s5IjSVKBtDkZoCRJUn2zkiNJUkF4gU5JkqQGYCVHkqSCSMJ5ciRJkuqdlRxJkgrEC3RKkiTVOSs5kiQVRCa0Ok+OJElSfbOSI0lSYQRtOLpKkiSprpnkSJKkhmRzlSRJBZHY8ViSJKnuWcmRJKlAvECnJElSnbOSI0lSQSRBW4Eu0GmS00mDBs/l2B89xsDVF5AJf792Pa6/YgM+9+VnGbnbZLItmDG9O786aSumTelZ63Dr0qC15nLs9x9m4OrzS+f4uvW5/uqN+PaPRzN0/TkA9Om3kDmzW/jawbvWONr6tKxzvNEmMznq+Mfo3r2N1tbg17/YimeeXK3W4datb/x0LCM+MI0ZU1v48oe3B+B9+0zhc18fx3rvmssxH9+GZx/vW+MoG09TU3LWDWOYOqk7Jx26ca3DURdQ0SQnIvYBzgSagd9m5qmVPF4ltbY28dtfbc5zT/WnV+9FnHnZv3no3jW45pINuey8TQDY/9Mv8ZkvPce5P92yxtHWp9bW4LdnbcFzzwwoneOL7uSh+9fktO+9Z8k2h33tSd6YY26+opZ1jg89agx/uHBTRt+7FsPfO4lDjxrDCUftXOtw69Ytf1qT6y9dm+N+/uySZS8925sfH7U5X//xczWMrLEd+MXJjBvbk9792modSpdmn5xVICKagXOBfYEtgM9ExBaVOl6lTZ/Sg+ee6g/A3De6Me6FPqyx1jzmtvvC7dmrlSzQTJKr2vSpPXnumQFA+Ry/2Jc11pzXbovk/XtO4Pab161NgA1gWec4M+jdZxEAffoushq5kh5/YACzZ741GR/3XG9eeaFXjSJqfIPWXsCOe87k71cOqnUo6kIq+ZN4BDA2M58HiIgrgQOAJyt4zKpYa525bLT5bJ5+fCAAX/jKs+zx4QnMeb0bJxyxY42jawxrrf0GG206k6efGLhk2ZbbTWPGtB5MGG+Zf1Vof44vOGMLfnTGfRz2tSeJpuS4w3epdXjSO3LED8Zx4SlD6N3HKk5HEmhznpxVYggwrt3j8eVlbxERh0fEqIgYtaBtbgXDWTV69lrEd3/+MBf8YvMlVZxLfr0Jh3x4N/7193XY/6CXaxxh/evZaxHf/eloLjhjS+a+0bJk+W57TeD2W6zirApvP8f7fewlLjhzSw458INccOaWHHPio7UOUeq0EXvOYMaUFsY+1qfWoaiLqXk6l5nnZ+bwzBzevalrl3Kbu7Vx4s8f5ra/rcM9tw3+j/X/+ts67LzHpBpE1jiam9s48ZTR3HbTEO65fZ0ly5ua29h594nccatJzspa2jnec7/x3POvtQG46x/rsOkWM2oZovSObDl8DiP3msHFdz/Gd855nm13nsXxZ7xQ67C6qKC1SreuoJLNVa8A67V7PLS8rE4lR3/vCca90Ic/Xz5sydJ115vDhHGlXw8jd5vM+Bf9JbHikqO/+wjjXurLn6/c6C1rtt9xCuNf6svU17p2Itz1Lf0cT5vSk623n8pjDw1i2+FTl3ympXpw0WlDuOi0UkPBNiNn8/EjJvGzYzascVTqCiqZ5DwAbBIRG1JKbj4N/HcFj1dRW2w3gz0/MoEXnu3L2X+4B4CLz92EDx0wniEbvEEmTJ7Yi3NPqdu+1TW3xTbT2XPfV3hhbD/OvvgOAC7+zWaM+vdgdv3gBG6/5T9aO/UOLescn/XTbTjiG0/Q1NzGwgXNnH3q1jWOtL59+1fPsM2ImfRfbRGX3jmKS89cj9dnduPL33+BAasv5IcXjOH5MX34ny/690LVVbQ+OZGZldt5xH7AGZSGkP8uM0/uaPsB3dfKndc8qGLxCOjesvxtpDrQNmVarUNoeDl/fq1DaHj3LrqJWW3Tqta2M3SrAfn1q6szPcS3t/z76MwcXpWDLUNFJxzJzBuBGyt5DEmS1Hldpb9MNRSnZiVJkgrFqWMlSSqIzChUn5zivFJJklQoJjmSJKkh2VwlSVKBtNpcJUmSVN+s5EiSVBAJtDmEXJIkqb5ZyZEkqTDCPjmSJEmVFBHrRcRtEfFkRDwREUeXl/8gIl6JiIfLt/3aPeeEiBgbEU9HxN7LO4aVHEmSCqJ0gc4u0ydnEXBsZj4YEf2A0RFxS3ndrzLzF+03jogtKF3se0tgXeDWiNg0M1uXdQArOZIkqeoyc2JmPli+PxsYAwzp4CkHAFdm5vzMfAEYC4zo6BgmOZIkFUgrTVW5AYMiYlS72+HLiikihgHbA/eVF301Ih6NiN9FxGrlZUOAce2eNp6OkyKTHEmSVBFTMnN4u9v5S9soIvoC1wDHZOYs4DzgXcB2wETg9BUNwD45kiQVRBJdqU8OEdFCKcG5PDP/BJCZk9qtvwC4ofzwFWC9dk8fWl62TFZyJElS1UVEABcCYzLzl+2Wr9Nus48Cj5fvXw98OiJ6RMSGwCbA/R0dw0qOJEkF0tZ16hu7AJ8HHouIh8vLTgQ+ExHbURoM9iJwBEBmPhERVwNPUhqZdVRHI6vAJEeSJNVAZt4FS73GxI0dPOdk4OTOHsMkR5KkgsiE1i7UJ6fSukzNSpIkaVUyyZEkSQ3J5ipJkgqkKw0hrzQrOZIkqSFZyZEkqSBKkwEWp75RnFcqSZIKxUqOJEkF0rrUqWkak5UcSZLUkKzkSJJUEImjqyRJkuqelRxJkgrD0VWSJEl1z0qOJEkF0uboKkmSpPpmJUeSpILIhFZHV0mSJNU3KzmSJBWIo6skSZLqnEmOJElqSF2ruSqTXLCg1lE0tCl7b1jrEAph1ka1jqDxbXRJ1/rz1Yjannux1iE0vqz24cLLOkiSJNU7fwpJklQgTgYoSZJU56zkSJJUEAn2yZEkSap3VnIkSSoQJwOUJEmqc1ZyJEkqinSeHEmSpLpnJUeSpIJInCdHkiSp7lnJkSSpQOyTI0mSVOes5EiSVBDOeCxJktQATHIkSVJDsrlKkqQCsblKkiSpzlnJkSSpIBIv6yBJklT3rORIklQgXtZBkiSpzlnJkSSpKNLRVZIkSXXPSo4kSQXhZR0kSZIagJUcSZIKxEqOJElSnbOSI0lSQTjjsSRJUgOwkiNJUoGklRxJkqT6ZpIjSZIaks1VkiQViBfolCRJqnNWciRJKoj0Ap2SJEn1z0qOJEkF4hBySZKkOmclR5KkwvCyDpIkSXXPSk4nHfOjMYzYdSozpnXnKx8bAcB3fv4EQ4a9AUDffot4fXY3vvbJHWsZZt07aOdHOXDHMQTw5wfezZX3bMPJn76FDQbNAKBvr/m8PrcHnzvnk7UNtI6c/P7b2H39l5g6txf/9aeD3rLu0K0f4ds7/ZuRlx7MjPm9gOS7772bXYe+zLzWbpxw+wd4cuqatQm8TrV0b+VnZ99JS0sbzc3JXf9al8svejff+t4oNtlsBosWBc+MWY2zf7Edra3+zlwV1lx3Ad8682UGDloIGdx4+Rr8+UI/t8tSpD45FUtyIuJ3wEeAyZm5VaWOUy23XrcOf7liKMeePGbJslO/teWS+//vuLHMeb25FqE1jI0GT+PAHcdwyK8/xqLWZs485K/c9dQGfPfKvZZsc/S+9/D6/O41jLL+XPvsZlz+5Facuts/37J87T6vs8uQcbwyu++SZbsOfZkN+s9k7z9+hm3XnMxJu9zJQdd/rNoh17WFC5o44Zj3MW9uN5qb2/jFuXcy6r7B3HbLUH7+4/cAcPz3R7H3R17ixus2rHG0jaF1UXD+D9dl7OO96dWnlXP+/gwP3tGPl5/tWevQVGOV/Bnxe2CfCu6/qh4fPZDZM5eVEybv33syt984uKoxNZoN15zOE+MGM39hC61tTTz4wrp8YMvn222RfHDr57j5kY1rFmM9GvXqusyc3+M/lp8w8h5+fv/Ityzbc4MXue7ZTYHgkdcG07/7fNbsNadKkTaKYN7c0t+Kbt3aaO7WBgmj7l0bCKBUyRm05tyaRtlIpk1uYezjvQGYO6eZcc/2YNDaC2scVdeUlObJqcatK6hYkpOZdwDTKrX/rmSr98xkxtTuTHi5d61DqWvPTVqd7YZNZECvefRoWcgum73M4IFvfsFuP2wi017vzbipA2sYZWPYY/0XmDSnN09PG/SW5YP7zGHinDcrO6/O6cvgPiY571RTU3L2hf/kD9f9jYdGrcXTY1Zfsq65uY099h7H6PvXqmGEjWvw0Pm8a6u5PPWQf4/VBfrkRMThwOEAPZv6Lmfrrmm3fSfxrxv9g7WyXnxtNS65fTvO+uINzFvQwjMT16C17c1fAx/adiw3PWoVZ2X1bF7IEds9xGF/+3CtQ2lYbW3B1w7bgz59F/A/P7mfDTacxUsv9AfgqG8+wuOPrMETjw5azl70TvXs3cr3LniR35w0hDfsPrB0WZr1uChq3ustM8/PzOGZObx7U/21nzY1t7HzB1/jjptMclaF60e/m4PP/QRHXHAAs+b24OUpAwBobmpj9y1f4NZH31XjCOvf+v1nMbTfLK772B/5x0GXMbjPHP700WsY1OsNJs3pwzp9Xl+y7dp9XmfSnD41jLa+zXm9O48+NIj37DQJgP8+5CkGDJzPBedsXePIGk9zt+R7F7zIP69djbv/ZrVXJTVPcurd9iOnM/6F3kydVH8JWle0Wp9SP4XBA2bzgS1f4KZHNgFgx3eN56XXBjJ5Vn1W+7qSZ6avwS6XH8KeV32OPa/6HJPm9OFj136cKXN788+Xh3HAJs8AybZrTmL2gu68Ntck553oP2A+ffouAKB791a2H/4a41/qx94ffpEdRkzmtB/uWKjRLdWRfPP0lxk3tgd/Ot8fnMvTRlTl1hXUvLmqXhx/2hNss+MM+g9cyCW33sNl5w7j5mvXZdd97XC8Kp322Zvo33s+ra1N/Pz69/H6vFKH2Q9tM9YOxyvo9A/cyo7rTGC1nvP412cu5ezRw7nmmXcvddvbx63Pruu9zM2fuoJ5i7px4h27VzXWRrD6GvM49sQHaWpOIpI7bxvC/f9em7/88zomT+rF6efdDsA9d6zLFRdvXuNoG8OWO87hg5+YzvNP9uTXNz8FwEWnrssD/+xf48hUa5EVapyLiCuA3YFBwCTgpMy8sKPnDGhZM9870OGqlTRl/81qHUIhzNqo1hE0vo0uebXWITS81uderHUIDe++tluZldOqVvbos8k6uflZX6zKsR7c75TRmTm8KgdbhopVcjLzM5XatyRJeueSYk0GaJ8cSZLUkOyTI0lSYXSdifqqwUqOJElqSFZyJEkqECcDlCRJqnNWciRJKhBHV0mSJFVQRKwXEbdFxJMR8UREHF1evnpE3BIRz5b/Xa28PCLirIgYGxGPRsQOyzuGSY4kSQWRWarkVOPWCYuAYzNzC2AkcFREbAF8B/hHZm4C/KP8GGBfYJPy7XDgvOUdwCRHkiRVXWZOzMwHy/dnA2OAIcABwMXlzS4GDizfPwC4JEvuBQZGxDodHcM+OZIkFUgV58kZFBGj2j0+PzPPX9qGETEM2B64DxicmRPLq14FFl8gcggwrt3TxpeXTWQZTHIkSVIlTOnMtasioi9wDXBMZs6KeDMJy8yMiBUe9G6SI0lSgXSleXIiooVSgnN5Zv6pvHhSRKyTmRPLzVGTy8tfAdZr9/Sh5WXLZJ8cSZJUdVEq2VwIjMnMX7ZbdT1wcPn+wcB17ZZ/oTzKaiQws12z1lJZyZEkqUC60Dw5uwCfBx6LiIfLy04ETgWujojDgJeAT5XX3QjsB4wF3gAOXd4BTHIkSVLVZeZdwLIyrj2Xsn0CR72TY9hcJUmSGpKVHEmSCiLp9ER9DcFKjiRJakhWciRJKpAuNIK84qzkSJKkhmQlR5KkosguNYS84qzkSJKkhmQlR5KkIilQpxwrOZIkqSFZyZEkqUDskyNJklTnrORIklQgaZ8cSZKk+mYlR5KkgkjskyNJklT3rORIklQUCVjJkSRJqm8mOZIkqSHZXCVJUoE4hFySJKnOWcmRJKlIrORIkiTVNys5kiQVRhRqMsCuleS0JblgYa2jaGgDnptX6xAK4f5TLqp1CA1vl8eOqHUIDa/fuAm1DqHxzS9OwlELXSvJkSRJlWWfHEmSpPpmJUeSpKJIL9ApSZJU96zkSJJUJPbJkSRJqm9WciRJKhT75EiSJNU1KzmSJBWJfXIkSZLqm0mOJElqSDZXSZJUJDZXSZIk1TcrOZIkFUUCXtZBkiSpvlnJkSSpQNI+OZIkSfXNSo4kSUViJUeSJKm+WcmRJKlIHF0lSZJU38qELX0AACAASURBVKzkSJJUIFGgPjnLTHIi4mw66J6UmV+vSESSJEmrQEeVnFFVi0KSJFVeUqjRVctMcjLz4vaPI6J3Zr5R+ZAkSZJW3nI7HkfEeyPiSeCp8uNtI+LXFY9MkiStYlEaXVWNWxfQmdFVZwB7A1MBMvMRYNdKBiVJkrSyOjWEPDPHvW1RawVikSRJWmU6M4R8XETsDGREtABHA2MqG5YkSaqIAnU87kwl50jgKGAIMAHYrvxYkiSpy1puJSczpwCfrUIskiSp0qzkvCkiNoqIv0TEaxExOSKui4iNqhGcJEnSiupMc9UfgKuBdYB1gT8CV1QyKEmSVCFZpVsX0Jkkp3dmXpqZi8q3y4CelQ5MkiRpZXR07arVy3f/FhHfAa6klJsdBNxYhdgkSdKqlHSZifqqoaOOx6MpnY7FZ+OIdusSOKFSQUmSJK2sjq5dtWE1A5EkSZUXXaS/TDV0ZjJAImIrYAva9cXJzEsqFZQkSdLKWm6SExEnAbtTSnJuBPYF7gJMciRJqjcFquR0ZnTVJ4A9gVcz81BgW2BARaOSJElaSZ1prpqbmW0RsSgi+gOTgfUqHFeX841TnmHE7tOZMbWFL++/AwCHHf8CO31gGosWBhNf7skvT9iUObM71QKoZbj07D8yd14LbW1Ba2sTR524P+/aYCpHf+nfdG9ppbW1ibMuHMnTz61Z61DrxoJ5wbEf25iFC5poXQTv//BMvvCtV7nud4O49rdrMvHFHlz92GMMWOOt1919+uFeHLP/ppx43ou8/yMzaxR9fTpo90fZf+TTJPDchNU55Q+7sWBR6W/DMR+7mw+PfJq9jv9ibYNsIEM3mssJZz+35PHa683j0l8N5c8XrV3DqNQVdOYbeVREDAQuoDTi6nXg38t7UkSsR6lJazCl4tj5mXnmSsRaU7f8aTDXX7Yux532zJJlD909kItOH0Zba/DF417goCPG8btf2F97ZR33o32YNfvNqZi+9NnRXPp/2/HAw0MZsd14vvTZURz3o31rGGF9aemR/OyPz9GrTxuLFsI3D9yEHfeYxZY7zmGnvWZx/Mc3/o/ntLbChSevy3t2m12DiOvboAFz+MSuT/DZn36SBQu78aNDbuWDOzzHjfdvxubrvUa/3vNrHWLDGf98L4768FYANDUll937MPfcvFqNo1JXsNzmqsz8SmbOyMzfAHsBB5ebrZZnEXBsZm4BjASOiogtVi7c2nl81ABmz3xrTvjg3avR1loaYf/Uw/0YtPaCWoTW8BLo3WshAH16L2Dq9N61DajORECvPm0ALFoYtC4MImDjreey9npL/8xe97s1ed9+Mxk4aFE1Q20YzU1t9GhZRHNTGz27L2LKzD40RRtHHXAvv75+ZK3Da2jb7TKLiS/1YPIrPWodSpcVWZ1bV9DRZIA7dLQuMx/saMeZORGYWL4/OyLGULqS+ZMrGGuX9qGPT+L2v9mEsrKS4NTv3kxm8NdbN+XGf2zGeReP4Kcn3sLhn3uApiY4+nv71TrMutPaCl/dezMmvNid/Q+ZwuY7vLHMbadMbOGevw3gZ/83ll9+c/0qRtkYpszswxW3bcOffvAH5i/sxgNPDeX+p4fyyd0e467HN2DqLJP0StrtI1P511/WqHUY6iI6aq46vYN1CezR2YNExDBge+C+paw7HDgcoGf06ewuu5RPHzmO1tbgtutNclbWN76/L1On92Fg/7mc+j83M27CAN6/00ucd/GO3HX/MHYd+QLHHnk33/7J3rUOta40N8N5tz7N6zOb+eFhw3jxqZ4M23zeUrf9zUlDOOy7E2jqzLAE/Yd+vebz/q1e4pM//Ayz5/bgJ4fewj47PsMHtnuer529f63Da2jdWtoY+cEZXPTzwnUbfWec8Rgy8wOr4gAR0Re4BjgmM2ct5TjnA+cDDGge1EUKXJ33wY9OYsTu0zjhkK14c3Joraip00uJ7oxZvbj7/vXZ7F1T+NBuY/n170cAcMe9w/jmEffUMsS61ndAK9vu/DoP3NZvmUnOM4/04qdfHgbAzGnN3P+PfjQ3w8772vm4M4Zv9goTpvVjxpxeANz+6IYctu9oerQs4qr/uRKAnuX7B/3k07UMteEM330mY5/ozYwpLbUORV1ERYcCRUQLpQTn8sz8UyWPVQvvef90Pvn/xnP857Zh/rzmWodT93r2WEgEzJ3XQs8eC3nPNhO47JptmTq9N9ts8SqPPrkO2281kVde7V/rUOvKjKnNdOtWSnDmzw0evKMfnzpq8jK3v+S+MUvu/+KY9dnpgzNNcN6BSdP7stUGk+nRsoj5C5sZvukrXHXb1vzfnVst2eaWn/3OBKcCdt9/Kv+63qYqvaliSU5EBHAhMCYzf1mp41TLt09/im1GzKT/aou49Pb7ufTs9Tno8PG0dG/j5IseB+CpR/pxzkn/OVJFnTNwwDx+cNw/AWhuSm67e0NGPTKUX/5vC1855H6am9tYsKCZM85/b40jrS/TJrXwi6PXp60taGuDXfefwci9ZvHn3w7ij+etxbTJLRz5wc0ZsccsvnH6uFqHW/eefGktbntkQy761jW0tjXxzPg1uO6ed9c6rIbXo1crO7xvJmd9d1itQ+nakkJNBhiZlXm1EfE+4E7gMaCtvPjEzFzmFcwHNA/KkX3/qyLxqGTRdiZh1XDLVRfVOoSGt8vRRyx/I62Uftc/XOsQGt698//GrLapVevr0GO99XLIsd+oyrFe+MaxozNzeFUOtgyduaxDAJ8FNsrMH0XE+sDamXl/R8/LzLuwk4okSV1LgSo5nRk/8WvgvcBnyo9nA+dWLCJJkqRVoDN9cnbKzB0i4iGAzJweEd0rHJckSaqArjJRXzV0ppKzMCKaKRe4ImJN3uxjI0mS1CV1Jsk5C7gWWCsiTgbuAk6paFSSJKkyskq35YiI30XE5Ih4vN2yH0TEKxHxcPm2X7t1J0TE2Ih4OiI6NSPscpurMvPyiBgN7EmpI/GBmTlmOU+TJEnqyO+BcyhdzLu9X2XmL9ovKF/78tPAlsC6wK0RsWlmtnZ0gM6MrlofeAP4S/tlmflyZ16BJEnqQrpIn5zMvKN82afOOAC4MjPnAy9ExFhgBPDvjp7UmY7Hf6V0SgLoCWwIPE0pm5IkSVqaQRExqt3j88uXclqer0bEF4BRwLGZOZ3SBb7vbbfN+PKyDnWmuWrr9o/LVyf/SieClCRJXUhkVUdXTVmByQDPA35MqbjyY0oXC//iigbwjq8znJkPAjut6AElSZKWJjMnZWZrZrYBF1BqkgJ4BWh/efmh5WUd6kyfnG+2e9gE7ABM6HTEkiSp68iuezGCiFgnMyeWH34UWDzy6nrgDxHxS0odjzcBOrzyAnSuT06/dvcXUeqjc02nI5YkSXqbiLgC2J1S353xwEnA7hGxHaXmqheBIwAy84mIuBp4klIuctTyRlbBcpKc8iSA/TLzuJV4HZIkqavoOqOrPrOUxRd2sP3JwMnv5BjL7JMTEd3KWdIu72SHkiRJXUFHlZz7KfW/eTgirgf+CMxZvDIz/1Th2CRJklZYZ/rk9ASmAnvw5nw5CZjkSJJUZ4p0gc6Okpy1yiOrHufN5GaxAp0iSZJUjzpKcpqBvrw1uVnMJEeSpHpUoG/wjpKciZn5o6pFIkmStAp1lOR03dmCJEnSO1fdyzrUXEeXddizalFIkiStYsus5GTmtGoGIkmSqsBKjiRJUn3rzDw5kiSpUVjJkSRJqm9WciRJKhBHV0mSJNU5kxxJktSQTHIkSVJDsk+OJElFYp8cSZKk+maSI0mSGpLNVZIkFYUX6JQkSap/VnIkSSoSKzmSJEn1zUqOJElFYiVHkiSpvlnJkSSpIIJija7qUklOZhs5d26tw2hozfc+UesQCmG/XT9a6xAa3oDu02sdQuPr1bPWETS8WGiDSiV1qSRHkiRVWIEqOaaQkiSpIVnJkSSpKJzxWJIkqf5ZyZEkqUis5EiSJNU3KzmSJBWJlRxJkqT6ZpIjSZIaks1VkiQViEPIJUmS6pyVHEmSisRKjiRJUn2zkiNJUlEkVnIkSZLqnZUcSZIKxNFVkiRJdc5KjiRJRWIlR5Ikqb5ZyZEkqUDskyNJklTnrORIklQkVnIkSZLqm5UcSZKKwhmPJUmS6p9JjiRJakg2V0mSVBBRvhWFlRxJktSQrORIklQkdjyWJEmqb1ZyJEkqEC/rIEmSVOes5EiSVCRWciRJkuqblRxJkorESo4kSVJ9s5IjSVJRpKOrJEmS6p6VHEmSisRKjiRJUn2zkrMSmpqSs24Yw9RJ3Tnp0I1rHU7D6dN/Ecec9iLDNp1LAr/61oaMebBvrcOqay3dW/nZ2XfS0tJGc3Ny17/W5fKL3s3R336QTTabQQS8Mq4vv/zpDsyb65+HFdHS0srPfnXbm+f4jqFcfsmWbLvdZA474hG6dWtj7LOrccYvhtPW5u/MFXXMT55mxG7TmDGtha8cMPwt6z56yHi+dPzzfHrn9zJrRkuNIuy6itQnp2J/xSKiJ3AH0KN8nP/LzJMqdbxaOPCLkxk3tie9+7XVOpSGdORJLzP69gGc/OWN6dbSRo9enueVtXBBEycc8z7mze1Gc3Mbvzj3TkbdN5jzz96auW+Uvgy+dNRj7P+x5/nj5ZvWONr6tHBhEycctzvz5pXP8Rm38eCowXzz+Ps58Vu78cor/fjcwY/zwQ+9xM1/37DW4datW68dzF8uX5djT336LcsHrT2PHXaezuQJPWoUmbqSSv6MmA/skZnbAtsB+0TEyAoer6oGrb2AHfecyd+vHFTrUBpS736L2Hqn2UvO76KFTcyZZWVh5cWSCk23bm00d2uDZEmCA0n3Hq1kgX7prXrBvHlvPcdtbcGiRU288ko/AB4aPZhd3j++lkHWvcdHD2T2zP+s0hz+7ef53ekb+hkWUMFKTmYm8Hr5YUv51jAfuyN+MI4LTxlC7z5WFyph7fUWMHNqC8f+4gU23GIuYx/rzXk/WJ/5c5trHVrda2pKzrzgNtYdMocb/rwRT49ZHYBvfOdBho+cxMsv9uO3525V4yjrW1NTcuavb2HdIa9zw3Ub8/RTq9PcnGyy6TSefWZ13rfreNZc641ah9lwRu4xhamTu/PC0zZrd6hhvomXr6INwhHRHBEPA5OBWzLzvqVsc3hEjIqIUQtzfiXDWWVG7DmDGVNaGPtYn1qH0rCam5ONt5rDDZetxVf325J5bzRx0Fcm1jqshtDWFnztsD34wif2ZtPNp7PBhrMA+NWpO/D5j+3DuJf6seser9Q4yvrW1hZ87cgP8YVPf4RNN5/GBsNmcepPRvKlLz/Cr865lblzW2htjVqH2VB69GzloMPHcenZw2odirqQiiY5mdmamdsBQ4EREfEfPw8z8/zMHJ6Zw1uiPtpQtxw+h5F7zeDiux/jO+c8z7Y7z+L4M16odVgNZcqr3ZkysTtPP1z6RXbnjauz8Vb+8l2V5rzenUcfGsR7dpq0ZFlbW3DHP4ewy24TahhZ45gzpzuPPrwW79nxVZ4aswbHf+MDfOOrH+SxRwcxodx0pVVjnfXmMXjIPM69djQX3XIfgwbP56xrHmS1QQtqHVqXE1mdW1dQla79mTkDuA3YpxrHq7SLThvC53fahoN32ZpTv7oRj9zTn58dYwfCVWn6ay28NrE7QzeaC8D2u8zi5Wd71Tiq+td/wHz69C390e/evZXth7/G+Jf7ss6QxS3LyU67vMq4l/0CXlH9B8ynT5925/g9kxj/cj8GDJwHQLeWVj550NPc+Jd31TLMhvPis3347/e/l0P32olD99qJKZN68PWP78D0Kd1rHZpqqJKjq9YEFmbmjIjoBewFnFap46nx/PqkDTj+zOdpaUkmvtyDXx5nIrmyVl9jHsee+CBNzUlEcudtQ3jg32vz83PupHefRUDywnMDOOf0bWsdat1affW5HPvtB2hqKp/j29fj/vvW5YuHP8KInSbS1JT89S/v4pGH16p1qHXt+J+PYZsRM+k/cCGX/PNeLjtnA27+0zq1DqvrSwrVJyeyQl3QI2Ib4GKgmVLF6OrM/FFHz+nftHqO7LZ3ReJRWTgvRzU0bTCk1iE0vu7Of1JxEyYtfxutlH/Puo6Zi16rWget3muul5t//JtVOdZD//vN0Zk5fPlbVk4lR1c9Cmxfqf1LkqQVUKBKjj/rJUlSQzLJkSSpIIKuM7oqIn4XEZMj4vF2y1aPiFsi4tnyv6uVl0dEnBURYyPi0YjYoTOv1yRHkiTVwu/5z1HX3wH+kZmbAP8oPwbYF9ikfDscOK8zBzDJkSSpSLJKt+WFkXkHMO1tiw+gNGiJ8r8Htlt+SZbcCwyMiOUOpzPJkSRJlTBo8RUNyrfDO/GcwZm5eHr7V4HB5ftDgHHtthtfXtYhr3goSVKBRPWuXjplZYaQZ2ZGrNzcyVZyJElSVzFpcTNU+d/J5eWvAOu1225oeVmHTHIkSSqKavXHWfH6y/XAweX7BwPXtVv+hfIoq5HAzHbNWstkc5UkSaq6iLgC2J1S353xwEnAqcDVEXEY8BLwqfLmNwL7AWOBN4BDO3MMkxxJklR1mfmZZazacynbJnDUOz2GSY4kSQWycl1564t9ciRJUkOykiNJUpFYyZEkSapvVnIkSSoQ++RIkiTVOSs5kiQViZUcSZKk+mYlR5Kkokj75EiSJNU9KzmSJBWJlRxJkqT6ZiVHkqSCCOyTI0mSVPes5EiSVCRZnFKOlRxJktSQTHIkSVJDsrlKkqQCseOxJElSnbOSI0lSUSROBihJklTvrORIklQg0VbrCKrHSo4kSWpIVnIkSSoS++RIkiTVNys5kiQViPPkSJIk1TkrOZIkFUVSqAt0dq0kJyHbinPya6JtQa0jKITW51+udQgNL5qi1iE0vrDYX2nZVqDx3DXQtZIcSZJUUfbJkSRJqnNWciRJKhIrOZIkSfXNJEeSJDUkm6skSSqIwI7HkiRJdc9KjiRJRZFZqMkAreRIkqSGZCVHkqQCsU+OJElSnbOSI0lSkVjJkSRJqm9WciRJKhD75EiSJNU5KzmSJBVFAm3FKeVYyZEkSQ3JSo4kSUVSnEKOlRxJktSYrORIklQgjq6SJEmqcyY5kiSpIdlcJUlSkWRx2qus5EiSpIZkJUeSpAKx47EkSVKds5IjSVJRJE4GKEmSVO+s5EiSVBABhKOrJEmS6puVHEmSiqSt1gFUj5UcSZLUkKzkSJJUIPbJkSRJqnNWciRJKgrnyZEkSap/VnIkSSqM9CrkkiRJ9c5KjiRJBeJVyCVJkuqcSY4kSWpINletgJYebZx+zTO0dE+am5M7bxzIpaevW+uwGs7w3Wdx5I8n0NyU/O2K1bn6nMG1Dqmh+Dmunqam5KwbxjB1UndOOnTjWofTkC6+6xHemNNMWyu0tgZf33/LWofUdRWo43HFk5yIaAZGAa9k5kcqfbxqWDg/OP5TmzDvjWaauyW/vPZpHrhtAE892KfWoTWMpqbkqFNe4YRPb8SUiS2cfeOz3HvTAF5+tmetQ2sYfo6r58AvTmbc2J707legiwbVwLc/vRmzprfUOgx1IdVorjoaGFOF41RRMO+NZgC6dUuau2WREuOq2Gz7N5jwYndefbkHixY28a/rBvLevWfWOqwG4+e4GgatvYAd95zJ368cVOtQJEiIturcuoKKJjkRMRT4MPDbSh6nFpqakl/fNIarHnmUh+7sz9MP+et3VVpj7YW8NqH7ksdTJrYwaJ2FNYyoMfk5rrwjfjCOC08ZQrZFrUNpaAmcctkznH3DE+z7mcm1DkddRKWbq84Ajgf6LWuDiDgcOBygJ70rHM6q09YWfGXvd9On/yJO+u3zbLDZXF56uletw5LeET/HlTVizxnMmNLC2Mf6sM3I2bUOp6Ed+/F3M3VSdwassZCfXvY0457rxeP3L/Orp9gKVLKtWCUnIj4CTM7M0R1tl5nnZ+bwzBzeQo9KhVMxc2Z145F7+rHj7rNqHUpDmfpqC2uuu2DJ40HrLGTKRNvaK8XPcWVsOXwOI/eawcV3P8Z3znmebXeexfFnvFDrsBrS1Emlyu/MqS3cc9NqbLbd6zWOSF1BJZurdgH+KyJeBK4E9oiIyyp4vKoZsPpC+vRfBED3nm3s8P5ZjBtrh9hV6emHezNkwwUMXm8+3Vra2P2AGdx784Bah9VQ/BxX3kWnDeHzO23Dwbtszalf3YhH7unPz47ZsNZhNZwevVrp1ad1yf0ddp3Ji0/XT8tA1WWVbl1AxZqrMvME4ASAiNgdOC4zP1ep41XT6oMXctyvXqKpOWkKuOOG1bjvH34Br0ptrcG53x3CKX94nqZmuPnK1XnpGb+AVyU/x2oUqw1ayPfPHwtAc7fktuvWYPTtfpbrQbkQMhtoBRZl5vCIWB24ChgGvAh8KjOnr9D+swptc+2SnA6HkPeP1XOn5g9VPJ5Ca2utdQTF0NRc6wgaXjTZkbfiwvliK+3ehX9nVtvUqn2Y+/cdkiO3PrIqx7rl3u+PzszhHW1TTnKGZ+aUdst+BkzLzFMj4jvAapn57RWJoSqf4Mz8V6PMkSNJkirqAODi8v2LgQNXdEfOeCxJUpFUb3TVoIgY1e7x+Zl5/tujAW6OiAT+t7x+cGZOLK9/FVjh6e5NciRJUiVMWV5zFfC+zHwlItYCbomIp9qvzMwsJ0ArxCRHkqSiSKCLzEYMkJmvlP+dHBHXAiOASRGxTmZOjIh1gBWe3dFeZZIkqeoiok9E9Ft8H/gQ8DhwPXBwebODgetW9BhWciRJKoggia4z4/Fg4NqIgFI+8ofM/HtEPABcHRGHAS8Bn1rRA5jkSJKkqsvM54Ftl7J8KrDnqjiGzVWSJKkhWcmRJKlIuk5zVcVZyZEkSQ3JSo4kSUViJUeSJKm+WcmRJKkouthkgJVmJUeSJDUkKzmSJBVIF5oMsOKs5EiSpIZkJUeSpCKxkiNJklTfrORIklQYaSVHkiSp3lnJkSSpKBIrOZIkSfXOSo4kSUXijMeSJEn1zSRHkiQ1JJurJEkqEC/rIEmSVOes5EiSVCRWciRJkuqblRxJkooigTYrOZIkSXXNSo4kSYXhBTolSZLqnpUcSZKKxEqOJElSfbOSI0lSkVjJkSRJqm9WciRJKgrnyZEkSap/XaqSM5vpU25tveqlWsfxDgwCptQ6iAZXn+e4tdYBvGP1d549x/pP9XiON6ju4RKyrbqHrKEuleRk5pq1juGdiIhRmTm81nE0Ms9xdXieK89zXHmeY72dzVWSJKkhdalKjiRJqjCHkKuTzq91AAXgOa4Oz3PleY4rz3Ost7CSsxIy0/9QFeY5rg7Pc+V5jivPc9wJDiGXJEmqf1ZyJEkqEvvkaHkiYp+IeDoixkbEd2odT6OJiN9FxOSIeLzWsTSqiFgvIm6LiCcj4omIOLrWMTWiiOgZEfdHxCPl8/zDWsfUqCKiOSIeiogbah2LugaTnBUQEc3AucC+wBbAZyJii9pG1XB+D+xT6yAa3CLg2MzcAhgJHOXnuCLmA3tk5rbAdsA+ETGyxjE1qqOBMbUOosvLrM6tCzDJWTEjgLGZ+XxmLgCuBA6ocUwNJTPvAKbVOo5GlpkTM/PB8v3ZlL4chtQ2qsaTJa+XH7aUb13jG6CBRMRQ4MPAb2sdi7oOk5wVMwQY1+7xePxyUB2LiGHA9sB9tY2kMZWbUR4GJgO3ZKbnedU7AzgeKM41C1ZIlao4VnIkdQUR0Re4BjgmM2fVOp5GlJmtmbkdMBQYERFb1TqmRhIRHwEmZ+boWseirsXRVSvmFWC9do+HlpdJdSUiWiglOJdn5p9qHU+jy8wZEXEbpf5mdqpfdXYB/isi9gN6Av0j4rLM/FyN4+p6EmgrTrHLSs6KeQDYJCI2jIjuwKeB62sck/SOREQAFwJjMvOXtY6nUUXEmhExsHy/F7AX8FRto2osmXlCZg7NzGGU/h7/0wRHYJKzQjJzEfBV4CZKnTWvzswnahtVY4mIK+D/t3d3oZaVdRzHvz8nM5tiSEdDykDSNJGSmHwZaZiGilEJMZTC6CbDJlBB6KKrXrwKCrzpdRpEInrBrJgQ5kyaMmMkHRUV54QoTdQUROhUoxmS59/FejbuDsc5x5nt3vvs9f3Agr2e9fJ/9r45//N/nrUefgucm+RQkusn3acZdBnwKWBbkkfbdsWkOzWDzgDuS/I43T9Iv6oqH3HW5PRoTk5qSjoiSZJeWxtOPL02n3rNWGLt+du3H66qTWMJ9gqckyNJUp/0qLjhcJUkSZpJJjmSJGkmOVwlSVJvFCw6XCVJkrSmmeRIE5DkpfbI9hNJ7kzyxuO41x1Jrmmfdx1tkc0kW5NsPoYYf0yycbXtS8557mjHlzn/y0k+/2r7KGkVCqoWx7JNA5McaTJeqKoLq+oC4EVgx/DBJMc0lFxVn6mqhaOcshV41UmOJK1FJjnS5O0Hzm5Vlv1JdgMLbVHHryWZT/J4ks9C96biJN9I8mSSe4DTBzdKcn+STe3z9iSPJHksyb1tEc4dwC2tivSB9jbeu1qM+SSXtWtPTbI3yYEku4Cs9CWS/CLJw+2aG5Ycu62135vktNb2ziR72jX7k5w3ih9T0goWazzbFHDisTRBrWJzObCnNb0PuKCqDrZE4Z9V9f4kJwG/SbKXbrXwc4HzgbcCC8DtS+57GvA9YEu71ylV9WyS7wDPVdXX23k/BG6rqgeSvIPuLd7vBr4EPFBVtya5EljNG6c/3WKcDMwnuauqngHWAw9V1S1JvtjufSOwE9hRVU8luRj4FrDtGH5GSVqWSY40GScnebR93k+3htRm4HdVdbC1fwR4z2C+DbABOAfYAvyoql4C/prk18vc/xJg3+BeVfXsK/TjQ8D53TJWQLew4ZtajI+1a+9OcngV3+nmJFe3z2e2vj4DLAI/ae0/AH7WoKjM1gAAApxJREFUYmwG7hyKfdIqYkg6Xj16GaBJjjQZL1TVhcMN7Y/988NNwE1VNbfkvFGuL3UCcElV/WeZvqxakq10CdOlVfXvJPfTrQa9nGpx/7H0N5CkUXJOjjS95oDPJTkRIMm7kqwH9gEfb3N2zgA+uMy1DwJbkpzVrj2ltR8B3jx03l7gpsFOkkHSsQ+4rrVdDrxlhb5uAA63BOc8ukrSwAnAoBp1Hd0w2L+Ag0mubTGS5L0rxJB0vKpgcXE82xQwyZGm1y66+TaPJHkC+C5d9fXnwFPt2PfpVmv/P1X1d+AGuqGhx3h5uOiXwNWDicfAzcCmNrF5gZef8voKXZJ0gG7Y6k8r9HUP8Lokvwe+SpdkDTwPXNS+wzbg1tb+SeD61r8DwFWr+E0kadVchVySpJ7YsG5jXbr+o2OJNXfkjomvQm4lR5IkzSQnHkuS1CM1JfNlxsFKjiRJmklWciRJ6o3q1XtyrORIkqSZZJIjSZJmksNVkiT1RTE1i2eOg5UcSZI0k6zkSJLUJ+Uj5JIkSWualRxJknqigHJOjiRJ0tpmJUeSpL6ock6OJEnSWmclR5KkHnFOjiRJ0mssyfYkTyZ5OskXRn1/KzmSJPXJlMzJSbIO+CbwYeAQMJ9kd1UtjCqGlRxJkjQJFwFPV9UfqupF4MfAVaMMYCVHkqSeOMLhuXvqpxvHFO4NSR4a2t9ZVTuH9t8G/Hlo/xBw8Sg7YJIjSVJPVNX2SfdhnByukiRJk/AX4Myh/be3tpExyZEkSZMwD5yT5Kwkrwc+AeweZQCHqyRJ0thV1X+T3AjMAeuA26vqwChjpKo/LwWSJEn94XCVJEmaSSY5kiRpJpnkSJKkmWSSI0mSZpJJjiRJmkkmOZIkaSaZ5EiSpJn0P0nM0V76iYLjAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "confusion_Matrix = confusion_matrix(pred_knn, pred_rf)\n",
        "\n",
        "disp_train = ConfusionMatrixDisplay(confusion_matrix=confusion_Matrix)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
        "disp_train.plot()\n",
        "plt.title('Confusion Matrix Thermal Sensation kNN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkRNzXXv0607"
      },
      "outputs": [],
      "source": [
        "def Bagging_Classifier(nbr_est):\n",
        "  clf = BaggingClassifier(n_estimators= nbr_est)\n",
        "  clf.fit(X_train, y_train)\n",
        "  pred = clf.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, pred)*100\n",
        "\n",
        "  return accuracy\n",
        "  # print(f'Accuracy for activation for number of estimator  : %.4f' % accuracy)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "Bagging_Accuracy = []\n",
        "nbr_ests = np.arange(1,100,15)\n",
        "\n",
        "print(' Without Resampling \\n')\n",
        "for nbr_est in nbr_ests:\n",
        "  accuracy = Bagging_Classifier(nbr_est)\n",
        "  Bagging_Accuracy.append(accuracy)\n",
        "  print(f'Accuracy for {nbr_est} : %.4f' % (accuracy_score(y_test, pred_rf)*100))\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "Bagging_Accuracy = []\n",
        "\n",
        "print(' \\n With Resampling \\n')\n",
        "for nbr_est in nbr_ests:\n",
        "  accuracy = Bagging_Classifier(nbr_est)\n",
        "  Bagging_Accuracy.append(accuracy)\n",
        "  print(f'Accuracy for {nbr_est} : %.4f' % (accuracy_score(y_test, pred_rf)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_briswRXzqas"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machine\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "print(svm.score(X_train, y_train))\n",
        "print(svm.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mklkpz7vzysX"
      },
      "outputs": [],
      "source": [
        "# Bayesian regression\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def Bayes_reg(X_train, y_train,X_test, y_test):\n",
        "\n",
        "\n",
        "  model = GaussianNB().fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  MSE = mean_squared_error(y_test, y_pred)\n",
        "  RMSE = np.sqrt(MSE)\n",
        "  r2 = r2_score(y_pred, y_test)\n",
        "\n",
        "  sigma = model.sigma_\n",
        "  \n",
        "  print(\"RMSE Bayesian Regression = = %.3f \" %RMSE, '\\n' )\n",
        "  print(\"r2 Score Bayesian Regression = %.3f \" %r2, '% \\n' )\n",
        "  print('Accuracy : %.4f' % (accuracy_score(y_test, y_pred)*100))\n",
        "  print('f1 score : %.4f' % (f1_score(y_test, pred_rf, average='micro')))\n",
        "\n",
        "\n",
        "  return model\n",
        "\n",
        "model = Bayes_reg(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAd9NyNLzsgG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD7_ZPQ8zYgT"
      },
      "source": [
        "## Deep Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU-YnV96vfpk"
      },
      "source": [
        "### Data Deep Learning Mohamed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTvWAoA0vX_6"
      },
      "source": [
        "### Data Trout Jaime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqy1gjbvvu4k",
        "outputId": "e02728ac-7492-430a-902d-eae6f86695aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (5,35,36) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "<ipython-input-3-9978c5cf6f3f>:7: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  df_ashrae_mod = df_ashrae_mod.fillna(df_ashrae_mod.mean())\n"
          ]
        }
      ],
      "source": [
        "df_ashrae = pd.read_csv(\"/content/drive/MyDrive/WPI/Deep Learning/Project/db_measurements_v2.1.0.csv\")\n",
        "\n",
        "df_ashrae_mod = df_ashrae[['age', 'gender', 't_out', 'rh_out', 'ta', 'rh', 'vel', 'tr',  'thermal_sensation', \n",
        "                         'thermal_acceptability', 'thermal_preference', 'thermal_comfort', 'met', 'clo']]\n",
        "\n",
        "df_ashrae_mod = df_ashrae_mod.dropna(subset=['thermal_sensation'])\n",
        "df_ashrae_mod = df_ashrae_mod.fillna(df_ashrae_mod.mean())\n",
        "\n",
        "#Making the range from [-3,3] to[2,2]\n",
        "df_ashrae_mod['thermal_sensation'] = df_ashrae_mod['thermal_sensation'].apply(lambda x: -2 if x <= -2 else x)\n",
        "df_ashrae_mod['thermal_sensation'] = df_ashrae_mod['thermal_sensation'].apply(lambda x: 2 if x >= 2 else x)\n",
        "#Rounding off the values to make it categorical in nature \n",
        "df_ashrae_mod['thermal_sensation'] = df_ashrae_mod['thermal_sensation'].apply(lambda x: np.round(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxtMg2jDgn0c",
        "outputId": "d76e1884-c61e-4e8a-8f1d-2e3789a94f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15iwvrE_BO0s"
      },
      "outputs": [],
      "source": [
        "df = df_ashrae_mod.copy()\n",
        "df = pd.get_dummies(df, columns =['gender', 'thermal_acceptability' , 'thermal_preference'])\n",
        "\n",
        "train, validation, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
        "\n",
        "X_train = train.drop(['thermal_sensation'], axis = 1)\n",
        "y_train = train[ 'thermal_sensation']\n",
        "\n",
        "X_valid = validation.drop(['thermal_sensation'], axis = 1)\n",
        "y_valid = validation[ 'thermal_sensation']\n",
        "\n",
        "X_test = test.drop(['thermal_sensation'], axis = 1)\n",
        "y_test = test[ 'thermal_sensation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtuUz4Sw36hz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uGb5sLU3R_h"
      },
      "outputs": [],
      "source": [
        "y_train=np.asarray(y_train ,dtype=int)\n",
        "y_test = np.asarray(y_test ,dtype=int)\n",
        "y_valid = np.asarray(y_valid ,dtype=int)\n",
        "y_train = to_categorical(y_train, num_classes=5)\n",
        "y_test = to_categorical(y_test, num_classes=5)\n",
        "y_valid = to_categorical(y_valid, num_classes=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noSfW4ExxbEh"
      },
      "source": [
        "### Jaime MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI3or3luxaeX",
        "outputId": "4f1934cd-d2a9-477c-cd82-4ced3f2b68c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "996/996 [==============================] - 103s 102ms/step - loss: 1.3140 - accuracy: 0.4645 - val_loss: 1.1891 - val_accuracy: 0.5157\n",
            "Epoch 2/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.1590 - accuracy: 0.5317 - val_loss: 1.1379 - val_accuracy: 0.5473\n",
            "Epoch 3/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.1381 - accuracy: 0.5468 - val_loss: 1.1319 - val_accuracy: 0.5550\n",
            "Epoch 4/100\n",
            "996/996 [==============================] - 4s 5ms/step - loss: 1.1234 - accuracy: 0.5535 - val_loss: 1.1289 - val_accuracy: 0.5552\n",
            "Epoch 5/100\n",
            "996/996 [==============================] - 4s 4ms/step - loss: 1.1144 - accuracy: 0.5588 - val_loss: 1.0997 - val_accuracy: 0.5677\n",
            "Epoch 6/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.1049 - accuracy: 0.5614 - val_loss: 1.0902 - val_accuracy: 0.5705\n",
            "Epoch 7/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0979 - accuracy: 0.5652 - val_loss: 1.0937 - val_accuracy: 0.5713\n",
            "Epoch 8/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0916 - accuracy: 0.5662 - val_loss: 1.1035 - val_accuracy: 0.5663\n",
            "Epoch 9/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0875 - accuracy: 0.5685 - val_loss: 1.1209 - val_accuracy: 0.5620\n",
            "Epoch 10/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0805 - accuracy: 0.5689 - val_loss: 1.0995 - val_accuracy: 0.5716\n",
            "Epoch 11/100\n",
            "996/996 [==============================] - 4s 4ms/step - loss: 1.0753 - accuracy: 0.5720 - val_loss: 1.1076 - val_accuracy: 0.5597\n",
            "Epoch 12/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0717 - accuracy: 0.5732 - val_loss: 1.0847 - val_accuracy: 0.5766\n",
            "Epoch 13/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0691 - accuracy: 0.5749 - val_loss: 1.0735 - val_accuracy: 0.5751\n",
            "Epoch 14/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0635 - accuracy: 0.5757 - val_loss: 1.0651 - val_accuracy: 0.5817\n",
            "Epoch 15/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0605 - accuracy: 0.5781 - val_loss: 1.0635 - val_accuracy: 0.5810\n",
            "Epoch 16/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0579 - accuracy: 0.5789 - val_loss: 1.0702 - val_accuracy: 0.5820\n",
            "Epoch 17/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0545 - accuracy: 0.5815 - val_loss: 1.0594 - val_accuracy: 0.5867\n",
            "Epoch 18/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0522 - accuracy: 0.5825 - val_loss: 1.0771 - val_accuracy: 0.5717\n",
            "Epoch 19/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0484 - accuracy: 0.5812 - val_loss: 1.0678 - val_accuracy: 0.5804\n",
            "Epoch 20/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0455 - accuracy: 0.5822 - val_loss: 1.0619 - val_accuracy: 0.5845\n",
            "Epoch 21/100\n",
            "996/996 [==============================] - 4s 4ms/step - loss: 1.0441 - accuracy: 0.5818 - val_loss: 1.0780 - val_accuracy: 0.5717\n",
            "Epoch 22/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0406 - accuracy: 0.5847 - val_loss: 1.0541 - val_accuracy: 0.5851\n",
            "Epoch 23/100\n",
            "996/996 [==============================] - 4s 4ms/step - loss: 1.0377 - accuracy: 0.5856 - val_loss: 1.0514 - val_accuracy: 0.5826\n",
            "Epoch 24/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0362 - accuracy: 0.5862 - val_loss: 1.0507 - val_accuracy: 0.5846\n",
            "Epoch 25/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0312 - accuracy: 0.5873 - val_loss: 1.0441 - val_accuracy: 0.5867\n",
            "Epoch 26/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0299 - accuracy: 0.5871 - val_loss: 1.0517 - val_accuracy: 0.5874\n",
            "Epoch 27/100\n",
            "996/996 [==============================] - 4s 5ms/step - loss: 1.0276 - accuracy: 0.5892 - val_loss: 1.0539 - val_accuracy: 0.5803\n",
            "Epoch 28/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0268 - accuracy: 0.5896 - val_loss: 1.0381 - val_accuracy: 0.5857\n",
            "Epoch 29/100\n",
            "996/996 [==============================] - 4s 5ms/step - loss: 1.0227 - accuracy: 0.5909 - val_loss: 1.0496 - val_accuracy: 0.5885\n",
            "Epoch 30/100\n",
            "996/996 [==============================] - 4s 4ms/step - loss: 1.0225 - accuracy: 0.5903 - val_loss: 1.0454 - val_accuracy: 0.5909\n",
            "Epoch 31/100\n",
            "996/996 [==============================] - 4s 4ms/step - loss: 1.0178 - accuracy: 0.5916 - val_loss: 1.0356 - val_accuracy: 0.5900\n",
            "Epoch 32/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0147 - accuracy: 0.5928 - val_loss: 1.0395 - val_accuracy: 0.5888\n",
            "Epoch 33/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0136 - accuracy: 0.5933 - val_loss: 1.0427 - val_accuracy: 0.5875\n",
            "Epoch 34/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0119 - accuracy: 0.5939 - val_loss: 1.0366 - val_accuracy: 0.5929\n",
            "Epoch 35/100\n",
            "996/996 [==============================] - 4s 5ms/step - loss: 1.0098 - accuracy: 0.5943 - val_loss: 1.0434 - val_accuracy: 0.5888\n",
            "Epoch 36/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0074 - accuracy: 0.5956 - val_loss: 1.0460 - val_accuracy: 0.5889\n",
            "Epoch 37/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0075 - accuracy: 0.5954 - val_loss: 1.0464 - val_accuracy: 0.5889\n",
            "Epoch 38/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0029 - accuracy: 0.5958 - val_loss: 1.0302 - val_accuracy: 0.5951\n",
            "Epoch 39/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0026 - accuracy: 0.5960 - val_loss: 1.0440 - val_accuracy: 0.5908\n",
            "Epoch 40/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 1.0031 - accuracy: 0.5966 - val_loss: 1.0333 - val_accuracy: 0.5956\n",
            "Epoch 41/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9993 - accuracy: 0.5988 - val_loss: 1.0324 - val_accuracy: 0.5956\n",
            "Epoch 42/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9959 - accuracy: 0.6000 - val_loss: 1.0310 - val_accuracy: 0.5953\n",
            "Epoch 43/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9987 - accuracy: 0.5980 - val_loss: 1.0351 - val_accuracy: 0.5938\n",
            "Epoch 44/100\n",
            "996/996 [==============================] - 4s 4ms/step - loss: 0.9951 - accuracy: 0.6005 - val_loss: 1.0349 - val_accuracy: 0.5940\n",
            "Epoch 45/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9906 - accuracy: 0.6018 - val_loss: 1.0319 - val_accuracy: 0.5937\n",
            "Epoch 46/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9913 - accuracy: 0.6017 - val_loss: 1.0344 - val_accuracy: 0.5871\n",
            "Epoch 47/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9883 - accuracy: 0.6019 - val_loss: 1.0301 - val_accuracy: 0.5929\n",
            "Epoch 48/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9876 - accuracy: 0.6032 - val_loss: 1.0390 - val_accuracy: 0.5924\n",
            "Epoch 49/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9848 - accuracy: 0.6030 - val_loss: 1.0279 - val_accuracy: 0.5945\n",
            "Epoch 50/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9824 - accuracy: 0.6052 - val_loss: 1.0298 - val_accuracy: 0.5940\n",
            "Epoch 51/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9806 - accuracy: 0.6045 - val_loss: 1.0279 - val_accuracy: 0.5953\n",
            "Epoch 52/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9796 - accuracy: 0.6064 - val_loss: 1.0328 - val_accuracy: 0.5963\n",
            "Epoch 53/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9797 - accuracy: 0.6064 - val_loss: 1.0320 - val_accuracy: 0.5911\n",
            "Epoch 54/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9759 - accuracy: 0.6080 - val_loss: 1.0238 - val_accuracy: 0.5977\n",
            "Epoch 55/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9766 - accuracy: 0.6072 - val_loss: 1.0407 - val_accuracy: 0.5917\n",
            "Epoch 56/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9738 - accuracy: 0.6076 - val_loss: 1.0243 - val_accuracy: 0.5982\n",
            "Epoch 57/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9714 - accuracy: 0.6095 - val_loss: 1.0384 - val_accuracy: 0.5898\n",
            "Epoch 58/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9709 - accuracy: 0.6099 - val_loss: 1.0223 - val_accuracy: 0.5973\n",
            "Epoch 59/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9684 - accuracy: 0.6083 - val_loss: 1.0248 - val_accuracy: 0.5968\n",
            "Epoch 60/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9656 - accuracy: 0.6129 - val_loss: 1.0270 - val_accuracy: 0.5975\n",
            "Epoch 61/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9629 - accuracy: 0.6139 - val_loss: 1.0287 - val_accuracy: 0.5986\n",
            "Epoch 62/100\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.9650 - accuracy: 0.6131 - val_loss: 1.0288 - val_accuracy: 0.5938\n",
            "Epoch 63/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9617 - accuracy: 0.6118 - val_loss: 1.0254 - val_accuracy: 0.5967\n",
            "Epoch 64/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9582 - accuracy: 0.6132 - val_loss: 1.0204 - val_accuracy: 0.5981\n",
            "Epoch 65/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9591 - accuracy: 0.6141 - val_loss: 1.0269 - val_accuracy: 0.5971\n",
            "Epoch 66/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9552 - accuracy: 0.6159 - val_loss: 1.0347 - val_accuracy: 0.5921\n",
            "Epoch 67/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9524 - accuracy: 0.6167 - val_loss: 1.0253 - val_accuracy: 0.5975\n",
            "Epoch 68/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9519 - accuracy: 0.6182 - val_loss: 1.0234 - val_accuracy: 0.5982\n",
            "Epoch 69/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9504 - accuracy: 0.6178 - val_loss: 1.0269 - val_accuracy: 0.5960\n",
            "Epoch 70/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9515 - accuracy: 0.6169 - val_loss: 1.0381 - val_accuracy: 0.5900\n",
            "Epoch 71/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9479 - accuracy: 0.6204 - val_loss: 1.0350 - val_accuracy: 0.5916\n",
            "Epoch 72/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9460 - accuracy: 0.6175 - val_loss: 1.0360 - val_accuracy: 0.5935\n",
            "Epoch 73/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9439 - accuracy: 0.6196 - val_loss: 1.0280 - val_accuracy: 0.5961\n",
            "Epoch 74/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9440 - accuracy: 0.6189 - val_loss: 1.0349 - val_accuracy: 0.5972\n",
            "Epoch 75/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9423 - accuracy: 0.6199 - val_loss: 1.0329 - val_accuracy: 0.5994\n",
            "Epoch 76/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9412 - accuracy: 0.6207 - val_loss: 1.0373 - val_accuracy: 0.5926\n",
            "Epoch 77/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9416 - accuracy: 0.6196 - val_loss: 1.0261 - val_accuracy: 0.5995\n",
            "Epoch 78/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9373 - accuracy: 0.6221 - val_loss: 1.0344 - val_accuracy: 0.5981\n",
            "Epoch 79/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9369 - accuracy: 0.6202 - val_loss: 1.0291 - val_accuracy: 0.5950\n",
            "Epoch 80/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9372 - accuracy: 0.6231 - val_loss: 1.0323 - val_accuracy: 0.5959\n",
            "Epoch 81/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9301 - accuracy: 0.6245 - val_loss: 1.0203 - val_accuracy: 0.6002\n",
            "Epoch 82/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9306 - accuracy: 0.6253 - val_loss: 1.0305 - val_accuracy: 0.5983\n",
            "Epoch 83/100\n",
            "996/996 [==============================] - 4s 5ms/step - loss: 0.9293 - accuracy: 0.6257 - val_loss: 1.0391 - val_accuracy: 0.5932\n",
            "Epoch 84/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9299 - accuracy: 0.6231 - val_loss: 1.0370 - val_accuracy: 0.5947\n",
            "Epoch 85/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9263 - accuracy: 0.6270 - val_loss: 1.0377 - val_accuracy: 0.5902\n",
            "Epoch 86/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9226 - accuracy: 0.6265 - val_loss: 1.0355 - val_accuracy: 0.5980\n",
            "Epoch 87/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9251 - accuracy: 0.6273 - val_loss: 1.0320 - val_accuracy: 0.5970\n",
            "Epoch 88/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9213 - accuracy: 0.6281 - val_loss: 1.0274 - val_accuracy: 0.5973\n",
            "Epoch 89/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9177 - accuracy: 0.6295 - val_loss: 1.0284 - val_accuracy: 0.5979\n",
            "Epoch 90/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9151 - accuracy: 0.6289 - val_loss: 1.0465 - val_accuracy: 0.5967\n",
            "Epoch 91/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9186 - accuracy: 0.6283 - val_loss: 1.0519 - val_accuracy: 0.5901\n",
            "Epoch 92/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9130 - accuracy: 0.6313 - val_loss: 1.0292 - val_accuracy: 0.5966\n",
            "Epoch 93/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9153 - accuracy: 0.6296 - val_loss: 1.0360 - val_accuracy: 0.5961\n",
            "Epoch 94/100\n",
            "996/996 [==============================] - 4s 5ms/step - loss: 0.9096 - accuracy: 0.6328 - val_loss: 1.0338 - val_accuracy: 0.5967\n",
            "Epoch 95/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9099 - accuracy: 0.6300 - val_loss: 1.0420 - val_accuracy: 0.5926\n",
            "Epoch 96/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9064 - accuracy: 0.6333 - val_loss: 1.0437 - val_accuracy: 0.5944\n",
            "Epoch 97/100\n",
            "996/996 [==============================] - 4s 5ms/step - loss: 0.9082 - accuracy: 0.6338 - val_loss: 1.0447 - val_accuracy: 0.5959\n",
            "Epoch 98/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9020 - accuracy: 0.6347 - val_loss: 1.0429 - val_accuracy: 0.5948\n",
            "Epoch 99/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9014 - accuracy: 0.6362 - val_loss: 1.0393 - val_accuracy: 0.5988\n",
            "Epoch 100/100\n",
            "996/996 [==============================] - 5s 5ms/step - loss: 0.9012 - accuracy: 0.6367 - val_loss: 1.0346 - val_accuracy: 0.6003\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f299825acd0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "# Multi Layer Perceptron\n",
        "\n",
        "y_train=np.asarray(y_train ,dtype=int)\n",
        "MLP_model = Sequential()\n",
        "MLP_model.add(Dense(1024, activation='relu',  input_dim = 18 ))\n",
        "MLP_model.add(Dense(512, activation='relu'))\n",
        "MLP_model.add(Dense(256,activation='relu'))\n",
        "MLP_model.add(Dense(128,activation='relu'))\n",
        "MLP_model.add(Dense(64,activation='relu'))\n",
        "MLP_model.add(Dropout(0.3))\n",
        "MLP_model.add(Dense(32,activation='relu'))\n",
        "MLP_model.add(Dense(16,activation='relu'))\n",
        "MLP_model.add(Dense(8,activation='relu'))\n",
        "MLP_model.add(Dense(5,activation='softmax'))\n",
        "\n",
        "MLP_model.compile(optimizer=Adam(learning_rate=1e-3), loss= 'categorical_crossentropy',  \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "MLP_model.fit(X_train, y_train, validation_data = (X_valid,y_valid), epochs= 100, batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJHSEkQ_ZhMU"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'JB_MLP_NN_Model_Thermal_Comfort.pt'\n",
        "path = f\"/content/drive/MyDrive/WPI/Deep Learning/Project/Models Trained/Thermal_Comfort/{model_save_name}\" \n",
        "MLP_model.save(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4YIAFk31K2k"
      },
      "source": [
        "### Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tA1QGJ8unBS",
        "outputId": "743160e9-f31b-4165-ce9e-5e9dd7b0d5f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "82/82 [==============================] - 2s 13ms/step - loss: 1.5586 - accuracy: 0.2935 - recall_m: 0.0223 - precision_m: 0.2307 - f1_m: 0.0369 - val_loss: 1.5137 - val_accuracy: 0.3328 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.4758 - accuracy: 0.3588 - recall_m: 0.0411 - precision_m: 0.4675 - f1_m: 0.0729 - val_loss: 1.3332 - val_accuracy: 0.4912 - val_recall_m: 0.1780 - val_precision_m: 0.7414 - val_f1_m: 0.2833\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.3226 - accuracy: 0.4632 - recall_m: 0.1763 - precision_m: 0.7132 - f1_m: 0.2710 - val_loss: 1.2011 - val_accuracy: 0.5065 - val_recall_m: 0.1624 - val_precision_m: 0.8268 - val_f1_m: 0.2681\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.2048 - accuracy: 0.4943 - recall_m: 0.2231 - precision_m: 0.7041 - f1_m: 0.3348 - val_loss: 1.1332 - val_accuracy: 0.5104 - val_recall_m: 0.2807 - val_precision_m: 0.7197 - val_f1_m: 0.4012\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.1666 - accuracy: 0.5062 - recall_m: 0.2581 - precision_m: 0.6875 - f1_m: 0.3705 - val_loss: 1.1210 - val_accuracy: 0.5119 - val_recall_m: 0.2897 - val_precision_m: 0.6930 - val_f1_m: 0.4061\n",
            "Epoch 6/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.1547 - accuracy: 0.5122 - recall_m: 0.2636 - precision_m: 0.6896 - f1_m: 0.3767 - val_loss: 1.1039 - val_accuracy: 0.5288 - val_recall_m: 0.2666 - val_precision_m: 0.7774 - val_f1_m: 0.3936\n",
            "Epoch 7/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.1360 - accuracy: 0.5160 - recall_m: 0.2920 - precision_m: 0.6748 - f1_m: 0.4029 - val_loss: 1.0860 - val_accuracy: 0.5619 - val_recall_m: 0.2718 - val_precision_m: 0.7564 - val_f1_m: 0.3975\n",
            "Epoch 8/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.1461 - accuracy: 0.5228 - recall_m: 0.2914 - precision_m: 0.6595 - f1_m: 0.3995 - val_loss: 1.0964 - val_accuracy: 0.5480 - val_recall_m: 0.3351 - val_precision_m: 0.7332 - val_f1_m: 0.4582\n",
            "Epoch 9/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.1102 - accuracy: 0.5468 - recall_m: 0.2953 - precision_m: 0.6830 - f1_m: 0.4070 - val_loss: 1.0606 - val_accuracy: 0.5757 - val_recall_m: 0.3090 - val_precision_m: 0.7282 - val_f1_m: 0.4311\n",
            "Epoch 10/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.1004 - accuracy: 0.5545 - recall_m: 0.3308 - precision_m: 0.6565 - f1_m: 0.4350 - val_loss: 1.0744 - val_accuracy: 0.5626 - val_recall_m: 0.3739 - val_precision_m: 0.6864 - val_f1_m: 0.4819\n",
            "Epoch 11/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.1116 - accuracy: 0.5533 - recall_m: 0.3278 - precision_m: 0.6684 - f1_m: 0.4339 - val_loss: 1.0795 - val_accuracy: 0.5788 - val_recall_m: 0.2882 - val_precision_m: 0.7535 - val_f1_m: 0.4143\n",
            "Epoch 12/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.1179 - accuracy: 0.5501 - recall_m: 0.3078 - precision_m: 0.6537 - f1_m: 0.4153 - val_loss: 1.0828 - val_accuracy: 0.5803 - val_recall_m: 0.2889 - val_precision_m: 0.7077 - val_f1_m: 0.4078\n",
            "Epoch 13/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0903 - accuracy: 0.5639 - recall_m: 0.3489 - precision_m: 0.6499 - f1_m: 0.4511 - val_loss: 1.0750 - val_accuracy: 0.5826 - val_recall_m: 0.3411 - val_precision_m: 0.6827 - val_f1_m: 0.4527\n",
            "Epoch 14/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0778 - accuracy: 0.5618 - recall_m: 0.3649 - precision_m: 0.6660 - f1_m: 0.4684 - val_loss: 1.0800 - val_accuracy: 0.5442 - val_recall_m: 0.3373 - val_precision_m: 0.6524 - val_f1_m: 0.4430\n",
            "Epoch 15/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0862 - accuracy: 0.5631 - recall_m: 0.3501 - precision_m: 0.6634 - f1_m: 0.4513 - val_loss: 1.0676 - val_accuracy: 0.5565 - val_recall_m: 0.3389 - val_precision_m: 0.6893 - val_f1_m: 0.4519\n",
            "Epoch 16/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0731 - accuracy: 0.5610 - recall_m: 0.3456 - precision_m: 0.6701 - f1_m: 0.4497 - val_loss: 1.0485 - val_accuracy: 0.5726 - val_recall_m: 0.3061 - val_precision_m: 0.6824 - val_f1_m: 0.4201\n",
            "Epoch 17/100\n",
            "82/82 [==============================] - 1s 7ms/step - loss: 1.0749 - accuracy: 0.5702 - recall_m: 0.3720 - precision_m: 0.6745 - f1_m: 0.4745 - val_loss: 1.0347 - val_accuracy: 0.5719 - val_recall_m: 0.3776 - val_precision_m: 0.6728 - val_f1_m: 0.4823\n",
            "Epoch 18/100\n",
            "82/82 [==============================] - 0s 6ms/step - loss: 1.0615 - accuracy: 0.5710 - recall_m: 0.3761 - precision_m: 0.6706 - f1_m: 0.4778 - val_loss: 1.0336 - val_accuracy: 0.5842 - val_recall_m: 0.4818 - val_precision_m: 0.6316 - val_f1_m: 0.5456\n",
            "Epoch 19/100\n",
            "82/82 [==============================] - 0s 6ms/step - loss: 1.0643 - accuracy: 0.5670 - recall_m: 0.3801 - precision_m: 0.6596 - f1_m: 0.4773 - val_loss: 1.0305 - val_accuracy: 0.5803 - val_recall_m: 0.3954 - val_precision_m: 0.6682 - val_f1_m: 0.4956\n",
            "Epoch 20/100\n",
            "82/82 [==============================] - 1s 7ms/step - loss: 1.0491 - accuracy: 0.5760 - recall_m: 0.3848 - precision_m: 0.6742 - f1_m: 0.4873 - val_loss: 1.0394 - val_accuracy: 0.5711 - val_recall_m: 0.3411 - val_precision_m: 0.6997 - val_f1_m: 0.4564\n",
            "Epoch 21/100\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 1.0456 - accuracy: 0.5814 - recall_m: 0.3877 - precision_m: 0.6844 - f1_m: 0.4899 - val_loss: 1.0462 - val_accuracy: 0.5665 - val_recall_m: 0.3560 - val_precision_m: 0.7059 - val_f1_m: 0.4714\n",
            "Epoch 22/100\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 1.0676 - accuracy: 0.5687 - recall_m: 0.3700 - precision_m: 0.6765 - f1_m: 0.4704 - val_loss: 1.0593 - val_accuracy: 0.5765 - val_recall_m: 0.4006 - val_precision_m: 0.6660 - val_f1_m: 0.4981\n",
            "Epoch 23/100\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 1.0422 - accuracy: 0.5747 - recall_m: 0.3910 - precision_m: 0.6728 - f1_m: 0.4920 - val_loss: 1.0218 - val_accuracy: 0.5903 - val_recall_m: 0.4640 - val_precision_m: 0.6504 - val_f1_m: 0.5404\n",
            "Epoch 24/100\n",
            "82/82 [==============================] - 1s 7ms/step - loss: 1.0426 - accuracy: 0.5766 - recall_m: 0.3988 - precision_m: 0.6694 - f1_m: 0.4968 - val_loss: 1.0191 - val_accuracy: 0.5811 - val_recall_m: 0.3910 - val_precision_m: 0.6933 - val_f1_m: 0.4978\n",
            "Epoch 25/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0300 - accuracy: 0.5791 - recall_m: 0.4001 - precision_m: 0.6816 - f1_m: 0.5012 - val_loss: 1.0247 - val_accuracy: 0.5842 - val_recall_m: 0.4132 - val_precision_m: 0.6712 - val_f1_m: 0.5100\n",
            "Epoch 26/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0282 - accuracy: 0.5768 - recall_m: 0.4050 - precision_m: 0.6763 - f1_m: 0.5041 - val_loss: 1.0439 - val_accuracy: 0.5657 - val_recall_m: 0.3924 - val_precision_m: 0.6775 - val_f1_m: 0.4959\n",
            "Epoch 27/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0331 - accuracy: 0.5816 - recall_m: 0.4062 - precision_m: 0.6703 - f1_m: 0.5018 - val_loss: 1.0311 - val_accuracy: 0.5895 - val_recall_m: 0.4103 - val_precision_m: 0.6669 - val_f1_m: 0.5063\n",
            "Epoch 28/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0254 - accuracy: 0.5781 - recall_m: 0.3978 - precision_m: 0.6862 - f1_m: 0.5010 - val_loss: 1.0116 - val_accuracy: 0.5857 - val_recall_m: 0.3866 - val_precision_m: 0.6804 - val_f1_m: 0.4919\n",
            "Epoch 29/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0181 - accuracy: 0.5789 - recall_m: 0.4093 - precision_m: 0.6834 - f1_m: 0.5097 - val_loss: 1.0361 - val_accuracy: 0.5650 - val_recall_m: 0.3113 - val_precision_m: 0.6971 - val_f1_m: 0.4285\n",
            "Epoch 30/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0188 - accuracy: 0.5847 - recall_m: 0.4160 - precision_m: 0.6875 - f1_m: 0.5147 - val_loss: 1.0164 - val_accuracy: 0.5742 - val_recall_m: 0.3433 - val_precision_m: 0.6854 - val_f1_m: 0.4560\n",
            "Epoch 31/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0089 - accuracy: 0.5850 - recall_m: 0.4160 - precision_m: 0.6852 - f1_m: 0.5160 - val_loss: 1.0079 - val_accuracy: 0.5796 - val_recall_m: 0.3731 - val_precision_m: 0.7018 - val_f1_m: 0.4855\n",
            "Epoch 32/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0147 - accuracy: 0.5810 - recall_m: 0.3982 - precision_m: 0.6865 - f1_m: 0.4997 - val_loss: 1.0315 - val_accuracy: 0.5696 - val_recall_m: 0.4736 - val_precision_m: 0.6190 - val_f1_m: 0.5358\n",
            "Epoch 33/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 1.0270 - accuracy: 0.5760 - recall_m: 0.3878 - precision_m: 0.6833 - f1_m: 0.4912 - val_loss: 1.0214 - val_accuracy: 0.5780 - val_recall_m: 0.4535 - val_precision_m: 0.6343 - val_f1_m: 0.5277\n",
            "Epoch 34/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9985 - accuracy: 0.5885 - recall_m: 0.4305 - precision_m: 0.6927 - f1_m: 0.5285 - val_loss: 0.9903 - val_accuracy: 0.5788 - val_recall_m: 0.4222 - val_precision_m: 0.6761 - val_f1_m: 0.5184\n",
            "Epoch 35/100\n",
            "82/82 [==============================] - 1s 7ms/step - loss: 0.9891 - accuracy: 0.5885 - recall_m: 0.4153 - precision_m: 0.7031 - f1_m: 0.5196 - val_loss: 1.0096 - val_accuracy: 0.5749 - val_recall_m: 0.3902 - val_precision_m: 0.6890 - val_f1_m: 0.4973\n",
            "Epoch 36/100\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 1.0000 - accuracy: 0.5883 - recall_m: 0.4187 - precision_m: 0.6836 - f1_m: 0.5156 - val_loss: 1.0047 - val_accuracy: 0.5726 - val_recall_m: 0.3642 - val_precision_m: 0.7100 - val_f1_m: 0.4800\n",
            "Epoch 37/100\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.9869 - accuracy: 0.5916 - recall_m: 0.4210 - precision_m: 0.6965 - f1_m: 0.5206 - val_loss: 1.0178 - val_accuracy: 0.5680 - val_recall_m: 0.4268 - val_precision_m: 0.6647 - val_f1_m: 0.5184\n",
            "Epoch 38/100\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.9821 - accuracy: 0.5875 - recall_m: 0.4252 - precision_m: 0.6996 - f1_m: 0.5274 - val_loss: 0.9802 - val_accuracy: 0.5919 - val_recall_m: 0.4245 - val_precision_m: 0.6820 - val_f1_m: 0.5223\n",
            "Epoch 39/100\n",
            "82/82 [==============================] - 1s 6ms/step - loss: 0.9701 - accuracy: 0.6022 - recall_m: 0.4389 - precision_m: 0.6895 - f1_m: 0.5340 - val_loss: 1.0211 - val_accuracy: 0.5703 - val_recall_m: 0.3485 - val_precision_m: 0.6709 - val_f1_m: 0.4578\n",
            "Epoch 40/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9747 - accuracy: 0.6033 - recall_m: 0.4305 - precision_m: 0.7038 - f1_m: 0.5316 - val_loss: 0.9852 - val_accuracy: 0.5926 - val_recall_m: 0.3954 - val_precision_m: 0.6932 - val_f1_m: 0.5024\n",
            "Epoch 41/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9638 - accuracy: 0.5993 - recall_m: 0.4375 - precision_m: 0.6966 - f1_m: 0.5354 - val_loss: 1.0132 - val_accuracy: 0.5749 - val_recall_m: 0.3880 - val_precision_m: 0.6907 - val_f1_m: 0.4948\n",
            "Epoch 42/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9733 - accuracy: 0.5998 - recall_m: 0.4404 - precision_m: 0.6994 - f1_m: 0.5384 - val_loss: 0.9920 - val_accuracy: 0.5696 - val_recall_m: 0.3612 - val_precision_m: 0.6801 - val_f1_m: 0.4697\n",
            "Epoch 43/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9712 - accuracy: 0.5960 - recall_m: 0.4345 - precision_m: 0.7011 - f1_m: 0.5346 - val_loss: 0.9792 - val_accuracy: 0.5811 - val_recall_m: 0.3970 - val_precision_m: 0.6721 - val_f1_m: 0.4970\n",
            "Epoch 44/100\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.9640 - accuracy: 0.5960 - recall_m: 0.4477 - precision_m: 0.6917 - f1_m: 0.5417 - val_loss: 0.9726 - val_accuracy: 0.5919 - val_recall_m: 0.4572 - val_precision_m: 0.6700 - val_f1_m: 0.5429\n",
            "Epoch 45/100\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.9728 - accuracy: 0.5962 - recall_m: 0.4358 - precision_m: 0.7000 - f1_m: 0.5334 - val_loss: 0.9883 - val_accuracy: 0.5919 - val_recall_m: 0.3962 - val_precision_m: 0.6832 - val_f1_m: 0.5000\n",
            "Epoch 46/100\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.9576 - accuracy: 0.6058 - recall_m: 0.4452 - precision_m: 0.6980 - f1_m: 0.5405 - val_loss: 0.9813 - val_accuracy: 0.5980 - val_recall_m: 0.4640 - val_precision_m: 0.6798 - val_f1_m: 0.5493\n",
            "Epoch 47/100\n",
            "82/82 [==============================] - 1s 6ms/step - loss: 0.9509 - accuracy: 0.6062 - recall_m: 0.4454 - precision_m: 0.7005 - f1_m: 0.5402 - val_loss: 1.0039 - val_accuracy: 0.5803 - val_recall_m: 0.4498 - val_precision_m: 0.6571 - val_f1_m: 0.5326\n",
            "Epoch 48/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9432 - accuracy: 0.6075 - recall_m: 0.4653 - precision_m: 0.6954 - f1_m: 0.5551 - val_loss: 0.9693 - val_accuracy: 0.5857 - val_recall_m: 0.4148 - val_precision_m: 0.7071 - val_f1_m: 0.5210\n",
            "Epoch 49/100\n",
            "82/82 [==============================] - 0s 6ms/step - loss: 0.9287 - accuracy: 0.6148 - recall_m: 0.4620 - precision_m: 0.7167 - f1_m: 0.5600 - val_loss: 0.9605 - val_accuracy: 0.5788 - val_recall_m: 0.4304 - val_precision_m: 0.6751 - val_f1_m: 0.5246\n",
            "Epoch 50/100\n",
            "82/82 [==============================] - 1s 7ms/step - loss: 0.9377 - accuracy: 0.6106 - recall_m: 0.4655 - precision_m: 0.7128 - f1_m: 0.5615 - val_loss: 0.9782 - val_accuracy: 0.5949 - val_recall_m: 0.4424 - val_precision_m: 0.6713 - val_f1_m: 0.5319\n",
            "Epoch 51/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9160 - accuracy: 0.6177 - recall_m: 0.4724 - precision_m: 0.7205 - f1_m: 0.5692 - val_loss: 0.9633 - val_accuracy: 0.5919 - val_recall_m: 0.4595 - val_precision_m: 0.6863 - val_f1_m: 0.5496\n",
            "Epoch 52/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9431 - accuracy: 0.6100 - recall_m: 0.4642 - precision_m: 0.7024 - f1_m: 0.5564 - val_loss: 1.0132 - val_accuracy: 0.5895 - val_recall_m: 0.4595 - val_precision_m: 0.6584 - val_f1_m: 0.5402\n",
            "Epoch 53/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9247 - accuracy: 0.6121 - recall_m: 0.4669 - precision_m: 0.7090 - f1_m: 0.5612 - val_loss: 0.9727 - val_accuracy: 0.5942 - val_recall_m: 0.4796 - val_precision_m: 0.6719 - val_f1_m: 0.5587\n",
            "Epoch 54/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9078 - accuracy: 0.6196 - recall_m: 0.4886 - precision_m: 0.7123 - f1_m: 0.5781 - val_loss: 0.9656 - val_accuracy: 0.6034 - val_recall_m: 0.4721 - val_precision_m: 0.6890 - val_f1_m: 0.5589\n",
            "Epoch 55/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9069 - accuracy: 0.6212 - recall_m: 0.4790 - precision_m: 0.7131 - f1_m: 0.5715 - val_loss: 0.9759 - val_accuracy: 0.5865 - val_recall_m: 0.4394 - val_precision_m: 0.6675 - val_f1_m: 0.5289\n",
            "Epoch 56/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.9053 - accuracy: 0.6154 - recall_m: 0.4756 - precision_m: 0.7165 - f1_m: 0.5701 - val_loss: 0.9528 - val_accuracy: 0.5965 - val_recall_m: 0.4580 - val_precision_m: 0.6849 - val_f1_m: 0.5474\n",
            "Epoch 57/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8961 - accuracy: 0.6208 - recall_m: 0.4736 - precision_m: 0.7230 - f1_m: 0.5695 - val_loss: 0.9529 - val_accuracy: 0.5980 - val_recall_m: 0.4825 - val_precision_m: 0.6662 - val_f1_m: 0.5587\n",
            "Epoch 58/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8775 - accuracy: 0.6291 - recall_m: 0.4913 - precision_m: 0.7239 - f1_m: 0.5838 - val_loss: 0.9536 - val_accuracy: 0.6088 - val_recall_m: 0.5049 - val_precision_m: 0.6818 - val_f1_m: 0.5793\n",
            "Epoch 59/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8797 - accuracy: 0.6289 - recall_m: 0.4952 - precision_m: 0.7304 - f1_m: 0.5889 - val_loss: 0.9505 - val_accuracy: 0.6088 - val_recall_m: 0.4773 - val_precision_m: 0.6840 - val_f1_m: 0.5613\n",
            "Epoch 60/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8697 - accuracy: 0.6331 - recall_m: 0.4934 - precision_m: 0.7276 - f1_m: 0.5869 - val_loss: 0.9709 - val_accuracy: 0.6003 - val_recall_m: 0.4886 - val_precision_m: 0.6575 - val_f1_m: 0.5599\n",
            "Epoch 61/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8593 - accuracy: 0.6394 - recall_m: 0.5064 - precision_m: 0.7318 - f1_m: 0.5971 - val_loss: 0.9739 - val_accuracy: 0.5696 - val_recall_m: 0.4208 - val_precision_m: 0.6626 - val_f1_m: 0.5137\n",
            "Epoch 62/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8592 - accuracy: 0.6410 - recall_m: 0.5059 - precision_m: 0.7431 - f1_m: 0.6005 - val_loss: 0.9771 - val_accuracy: 0.6034 - val_recall_m: 0.5094 - val_precision_m: 0.6653 - val_f1_m: 0.5762\n",
            "Epoch 63/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8570 - accuracy: 0.6366 - recall_m: 0.5109 - precision_m: 0.7239 - f1_m: 0.5974 - val_loss: 0.9491 - val_accuracy: 0.6034 - val_recall_m: 0.4714 - val_precision_m: 0.7016 - val_f1_m: 0.5631\n",
            "Epoch 64/100\n",
            "82/82 [==============================] - 0s 6ms/step - loss: 0.8579 - accuracy: 0.6358 - recall_m: 0.5077 - precision_m: 0.7337 - f1_m: 0.5979 - val_loss: 0.9673 - val_accuracy: 0.6065 - val_recall_m: 0.4877 - val_precision_m: 0.6626 - val_f1_m: 0.5608\n",
            "Epoch 65/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8437 - accuracy: 0.6433 - recall_m: 0.5075 - precision_m: 0.7302 - f1_m: 0.5975 - val_loss: 0.9373 - val_accuracy: 0.6057 - val_recall_m: 0.4811 - val_precision_m: 0.6778 - val_f1_m: 0.5618\n",
            "Epoch 66/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8282 - accuracy: 0.6489 - recall_m: 0.5210 - precision_m: 0.7571 - f1_m: 0.6149 - val_loss: 0.9459 - val_accuracy: 0.6149 - val_recall_m: 0.4774 - val_precision_m: 0.7051 - val_f1_m: 0.5680\n",
            "Epoch 67/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8404 - accuracy: 0.6450 - recall_m: 0.5116 - precision_m: 0.7440 - f1_m: 0.6049 - val_loss: 0.9234 - val_accuracy: 0.6149 - val_recall_m: 0.5019 - val_precision_m: 0.6751 - val_f1_m: 0.5750\n",
            "Epoch 68/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8410 - accuracy: 0.6429 - recall_m: 0.5120 - precision_m: 0.7372 - f1_m: 0.6028 - val_loss: 0.9336 - val_accuracy: 0.6241 - val_recall_m: 0.5004 - val_precision_m: 0.7071 - val_f1_m: 0.5850\n",
            "Epoch 69/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8346 - accuracy: 0.6529 - recall_m: 0.5092 - precision_m: 0.7446 - f1_m: 0.6032 - val_loss: 0.9494 - val_accuracy: 0.6072 - val_recall_m: 0.4892 - val_precision_m: 0.6943 - val_f1_m: 0.5731\n",
            "Epoch 70/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8314 - accuracy: 0.6537 - recall_m: 0.5284 - precision_m: 0.7435 - f1_m: 0.6164 - val_loss: 0.9718 - val_accuracy: 0.6180 - val_recall_m: 0.4952 - val_precision_m: 0.6784 - val_f1_m: 0.5715\n",
            "Epoch 71/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8185 - accuracy: 0.6581 - recall_m: 0.5299 - precision_m: 0.7566 - f1_m: 0.6221 - val_loss: 0.9429 - val_accuracy: 0.6218 - val_recall_m: 0.5056 - val_precision_m: 0.6877 - val_f1_m: 0.5821\n",
            "Epoch 72/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8017 - accuracy: 0.6635 - recall_m: 0.5462 - precision_m: 0.7539 - f1_m: 0.6314 - val_loss: 0.9440 - val_accuracy: 0.5949 - val_recall_m: 0.4825 - val_precision_m: 0.6638 - val_f1_m: 0.5580\n",
            "Epoch 73/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7988 - accuracy: 0.6604 - recall_m: 0.5380 - precision_m: 0.7514 - f1_m: 0.6255 - val_loss: 1.0193 - val_accuracy: 0.5872 - val_recall_m: 0.5071 - val_precision_m: 0.6606 - val_f1_m: 0.5731\n",
            "Epoch 74/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.8009 - accuracy: 0.6590 - recall_m: 0.5355 - precision_m: 0.7520 - f1_m: 0.6247 - val_loss: 0.9262 - val_accuracy: 0.6257 - val_recall_m: 0.5421 - val_precision_m: 0.6825 - val_f1_m: 0.6036\n",
            "Epoch 75/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7896 - accuracy: 0.6694 - recall_m: 0.5524 - precision_m: 0.7554 - f1_m: 0.6371 - val_loss: 0.9353 - val_accuracy: 0.6126 - val_recall_m: 0.5138 - val_precision_m: 0.6848 - val_f1_m: 0.5862\n",
            "Epoch 76/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7795 - accuracy: 0.6758 - recall_m: 0.5539 - precision_m: 0.7617 - f1_m: 0.6404 - val_loss: 0.9850 - val_accuracy: 0.6049 - val_recall_m: 0.4974 - val_precision_m: 0.6851 - val_f1_m: 0.5754\n",
            "Epoch 77/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7780 - accuracy: 0.6746 - recall_m: 0.5607 - precision_m: 0.7650 - f1_m: 0.6459 - val_loss: 0.9295 - val_accuracy: 0.6295 - val_recall_m: 0.5339 - val_precision_m: 0.6864 - val_f1_m: 0.5999\n",
            "Epoch 78/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7611 - accuracy: 0.6854 - recall_m: 0.5714 - precision_m: 0.7626 - f1_m: 0.6517 - val_loss: 0.9395 - val_accuracy: 0.6003 - val_recall_m: 0.4549 - val_precision_m: 0.7006 - val_f1_m: 0.5509\n",
            "Epoch 79/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7813 - accuracy: 0.6777 - recall_m: 0.5575 - precision_m: 0.7573 - f1_m: 0.6406 - val_loss: 0.9562 - val_accuracy: 0.6203 - val_recall_m: 0.4646 - val_precision_m: 0.6902 - val_f1_m: 0.5540\n",
            "Epoch 80/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7440 - accuracy: 0.6904 - recall_m: 0.5871 - precision_m: 0.7723 - f1_m: 0.6663 - val_loss: 0.9368 - val_accuracy: 0.6188 - val_recall_m: 0.5213 - val_precision_m: 0.6878 - val_f1_m: 0.5922\n",
            "Epoch 81/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7615 - accuracy: 0.6794 - recall_m: 0.5682 - precision_m: 0.7694 - f1_m: 0.6529 - val_loss: 0.9383 - val_accuracy: 0.6195 - val_recall_m: 0.5324 - val_precision_m: 0.6725 - val_f1_m: 0.5939\n",
            "Epoch 82/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7433 - accuracy: 0.6913 - recall_m: 0.5778 - precision_m: 0.7662 - f1_m: 0.6575 - val_loss: 1.0459 - val_accuracy: 0.5980 - val_recall_m: 0.5264 - val_precision_m: 0.6587 - val_f1_m: 0.5844\n",
            "Epoch 83/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7661 - accuracy: 0.6756 - recall_m: 0.5709 - precision_m: 0.7554 - f1_m: 0.6494 - val_loss: 0.9427 - val_accuracy: 0.6218 - val_recall_m: 0.5220 - val_precision_m: 0.6915 - val_f1_m: 0.5942\n",
            "Epoch 84/100\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.7271 - accuracy: 0.6919 - recall_m: 0.5910 - precision_m: 0.7780 - f1_m: 0.6704 - val_loss: 1.0192 - val_accuracy: 0.5988 - val_recall_m: 0.4983 - val_precision_m: 0.6830 - val_f1_m: 0.5756\n",
            "Epoch 85/100\n",
            "82/82 [==============================] - 1s 8ms/step - loss: 0.7472 - accuracy: 0.6844 - recall_m: 0.5773 - precision_m: 0.7670 - f1_m: 0.6575 - val_loss: 0.9794 - val_accuracy: 0.6195 - val_recall_m: 0.4915 - val_precision_m: 0.6928 - val_f1_m: 0.5742\n",
            "Epoch 86/100\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.7370 - accuracy: 0.6836 - recall_m: 0.5887 - precision_m: 0.7686 - f1_m: 0.6655 - val_loss: 0.9650 - val_accuracy: 0.6234 - val_recall_m: 0.5235 - val_precision_m: 0.6914 - val_f1_m: 0.5948\n",
            "Epoch 87/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7114 - accuracy: 0.6994 - recall_m: 0.5981 - precision_m: 0.7767 - f1_m: 0.6746 - val_loss: 0.9745 - val_accuracy: 0.6410 - val_recall_m: 0.5622 - val_precision_m: 0.6892 - val_f1_m: 0.6187\n",
            "Epoch 88/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7122 - accuracy: 0.6994 - recall_m: 0.6062 - precision_m: 0.7739 - f1_m: 0.6789 - val_loss: 1.0101 - val_accuracy: 0.5834 - val_recall_m: 0.4878 - val_precision_m: 0.6625 - val_f1_m: 0.5612\n",
            "Epoch 89/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7314 - accuracy: 0.7006 - recall_m: 0.5945 - precision_m: 0.7779 - f1_m: 0.6730 - val_loss: 0.9757 - val_accuracy: 0.6234 - val_recall_m: 0.5443 - val_precision_m: 0.6689 - val_f1_m: 0.5992\n",
            "Epoch 90/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7029 - accuracy: 0.7061 - recall_m: 0.6068 - precision_m: 0.7929 - f1_m: 0.6865 - val_loss: 0.9905 - val_accuracy: 0.6218 - val_recall_m: 0.5518 - val_precision_m: 0.6671 - val_f1_m: 0.6034\n",
            "Epoch 91/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7084 - accuracy: 0.7015 - recall_m: 0.6191 - precision_m: 0.7791 - f1_m: 0.6893 - val_loss: 0.9923 - val_accuracy: 0.6264 - val_recall_m: 0.5392 - val_precision_m: 0.6877 - val_f1_m: 0.6039\n",
            "Epoch 92/100\n",
            "82/82 [==============================] - 0s 6ms/step - loss: 0.7034 - accuracy: 0.7048 - recall_m: 0.5996 - precision_m: 0.7836 - f1_m: 0.6780 - val_loss: 0.9397 - val_accuracy: 0.6372 - val_recall_m: 0.5592 - val_precision_m: 0.6950 - val_f1_m: 0.6193\n",
            "Epoch 93/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.7119 - recall_m: 0.6259 - precision_m: 0.7895 - f1_m: 0.6973 - val_loss: 0.9838 - val_accuracy: 0.6095 - val_recall_m: 0.5138 - val_precision_m: 0.6871 - val_f1_m: 0.5871\n",
            "Epoch 94/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.7150 - recall_m: 0.6106 - precision_m: 0.7918 - f1_m: 0.6885 - val_loss: 1.0517 - val_accuracy: 0.6049 - val_recall_m: 0.5235 - val_precision_m: 0.6630 - val_f1_m: 0.5844\n",
            "Epoch 95/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.6997 - accuracy: 0.7063 - recall_m: 0.6165 - precision_m: 0.7835 - f1_m: 0.6890 - val_loss: 0.9686 - val_accuracy: 0.6434 - val_recall_m: 0.5436 - val_precision_m: 0.7031 - val_f1_m: 0.6127\n",
            "Epoch 96/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.6679 - accuracy: 0.7107 - recall_m: 0.6254 - precision_m: 0.7882 - f1_m: 0.6967 - val_loss: 1.0313 - val_accuracy: 0.6280 - val_recall_m: 0.5354 - val_precision_m: 0.6888 - val_f1_m: 0.6017\n",
            "Epoch 97/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.6800 - accuracy: 0.7180 - recall_m: 0.6255 - precision_m: 0.7906 - f1_m: 0.6975 - val_loss: 1.0443 - val_accuracy: 0.5888 - val_recall_m: 0.4937 - val_precision_m: 0.6633 - val_f1_m: 0.5648\n",
            "Epoch 98/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.7139 - accuracy: 0.7094 - recall_m: 0.6122 - precision_m: 0.7869 - f1_m: 0.6876 - val_loss: 0.9975 - val_accuracy: 0.6234 - val_recall_m: 0.5443 - val_precision_m: 0.6932 - val_f1_m: 0.6090\n",
            "Epoch 99/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.6413 - accuracy: 0.7390 - recall_m: 0.6556 - precision_m: 0.8049 - f1_m: 0.7219 - val_loss: 1.0054 - val_accuracy: 0.6218 - val_recall_m: 0.5257 - val_precision_m: 0.6817 - val_f1_m: 0.5926\n",
            "Epoch 100/100\n",
            "82/82 [==============================] - 0s 5ms/step - loss: 0.6222 - accuracy: 0.7392 - recall_m: 0.6593 - precision_m: 0.8032 - f1_m: 0.7232 - val_loss: 1.0463 - val_accuracy: 0.6149 - val_recall_m: 0.5413 - val_precision_m: 0.6784 - val_f1_m: 0.6016\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f11146383d0>"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "# Multi Layer Perceptron\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=5)\n",
        "y_test = to_categorical(y_test, num_classes=5)\n",
        "\n",
        "y_train=np.asarray(y_train ,dtype=int)\n",
        "MLP_model = Sequential()\n",
        "MLP_model.add(Dense(1024, activation='relu',  input_dim = 16 ))\n",
        "MLP_model.add(Dense(512, activation='relu'))\n",
        "MLP_model.add(Dense(256,activation='relu'))\n",
        "MLP_model.add(Dense(128,activation='relu'))\n",
        "MLP_model.add(Dense(64,activation='relu'))\n",
        "MLP_model.add(Dropout(0.3))\n",
        "MLP_model.add(Dense(32,activation='relu'))\n",
        "MLP_model.add(Dense(16,activation='relu'))\n",
        "MLP_model.add(Dense(8,activation='relu'))\n",
        "MLP_model.add(Dense(5,activation='softmax'))\n",
        "\n",
        "MLP_model.compile(optimizer=Adam(learning_rate=1e-3), loss= 'categorical_crossentropy',  \n",
        "              metrics=['accuracy', recall_m, precision_m, f1_m])\n",
        "\n",
        "MLP_model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs= 100, batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RWinHyRxsV3B",
        "outputId": "633d71a1-0969-48f8-afab-0d5b4f0a721f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "996/996 [==============================] - 56s 54ms/step - loss: 0.9860 - accuracy: 0.4578 - mse: 0.9860 - f1_m: 0.6183 - precision_m: 592369.5000 - recall_m: 0.5785 - weighted_accuracy: 0.4578 - weighted_mse: 0.9860 - weighted_f1_m: 0.6183 - weighted_precision_m: 592369.5000 - weighted_recall_m: 0.5785 - val_loss: 0.9322 - val_accuracy: 0.4621 - val_mse: 0.9322 - val_f1_m: 0.7170 - val_precision_m: 0.6751 - val_recall_m: 0.7752 - val_weighted_accuracy: 0.4621 - val_weighted_mse: 0.9322 - val_weighted_f1_m: 0.7170 - val_weighted_precision_m: 0.6751 - val_weighted_recall_m: 0.7752\n",
            "Epoch 2/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.9186 - accuracy: 0.4731 - mse: 0.9186 - f1_m: 0.7186 - precision_m: 0.7750 - recall_m: 0.6897 - weighted_accuracy: 0.4731 - weighted_mse: 0.9186 - weighted_f1_m: 0.7186 - weighted_precision_m: 0.7750 - weighted_recall_m: 0.6897 - val_loss: 0.9127 - val_accuracy: 0.4776 - val_mse: 0.9127 - val_f1_m: 0.7237 - val_precision_m: 0.8199 - val_recall_m: 0.6577 - val_weighted_accuracy: 0.4776 - val_weighted_mse: 0.9127 - val_weighted_f1_m: 0.7237 - val_weighted_precision_m: 0.8199 - val_weighted_recall_m: 0.6577\n",
            "Epoch 3/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.9154 - accuracy: 0.4747 - mse: 0.9154 - f1_m: 0.7245 - precision_m: 0.7876 - recall_m: 0.6913 - weighted_accuracy: 0.4747 - weighted_mse: 0.9154 - weighted_f1_m: 0.7245 - weighted_precision_m: 0.7876 - weighted_recall_m: 0.6913 - val_loss: 0.9239 - val_accuracy: 0.4747 - val_mse: 0.9239 - val_f1_m: 0.6852 - val_precision_m: 0.8325 - val_recall_m: 0.5926 - val_weighted_accuracy: 0.4747 - val_weighted_mse: 0.9239 - val_weighted_f1_m: 0.6852 - val_weighted_precision_m: 0.8325 - val_weighted_recall_m: 0.5926\n",
            "Epoch 4/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.9133 - accuracy: 0.4750 - mse: 0.9133 - f1_m: 0.7247 - precision_m: 0.7799 - recall_m: 0.6943 - weighted_accuracy: 0.4750 - weighted_mse: 0.9133 - weighted_f1_m: 0.7247 - weighted_precision_m: 0.7799 - weighted_recall_m: 0.6943 - val_loss: 0.9023 - val_accuracy: 0.4750 - val_mse: 0.9023 - val_f1_m: 0.7319 - val_precision_m: 0.7794 - val_recall_m: 0.6996 - val_weighted_accuracy: 0.4750 - val_weighted_mse: 0.9023 - val_weighted_f1_m: 0.7319 - val_weighted_precision_m: 0.7794 - val_weighted_recall_m: 0.6996\n",
            "Epoch 5/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.9102 - accuracy: 0.4754 - mse: 0.9102 - f1_m: 0.7308 - precision_m: 0.8077 - recall_m: 0.6850 - weighted_accuracy: 0.4754 - weighted_mse: 0.9102 - weighted_f1_m: 0.7308 - weighted_precision_m: 0.8077 - weighted_recall_m: 0.6850 - val_loss: 0.9012 - val_accuracy: 0.4799 - val_mse: 0.9012 - val_f1_m: 0.7369 - val_precision_m: 0.8239 - val_recall_m: 0.6760 - val_weighted_accuracy: 0.4799 - val_weighted_mse: 0.9012 - val_weighted_f1_m: 0.7369 - val_weighted_precision_m: 0.8239 - val_weighted_recall_m: 0.6760\n",
            "Epoch 6/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.9086 - accuracy: 0.4759 - mse: 0.9086 - f1_m: 0.7283 - precision_m: 0.8022 - recall_m: 0.6873 - weighted_accuracy: 0.4759 - weighted_mse: 0.9086 - weighted_f1_m: 0.7283 - weighted_precision_m: 0.8022 - weighted_recall_m: 0.6873 - val_loss: 0.9054 - val_accuracy: 0.4774 - val_mse: 0.9054 - val_f1_m: 0.7348 - val_precision_m: 0.7766 - val_recall_m: 0.7076 - val_weighted_accuracy: 0.4774 - val_weighted_mse: 0.9054 - val_weighted_f1_m: 0.7348 - val_weighted_precision_m: 0.7766 - val_weighted_recall_m: 0.7076\n",
            "Epoch 7/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.9042 - accuracy: 0.4768 - mse: 0.9042 - f1_m: 0.7316 - precision_m: 0.8153 - recall_m: 0.6814 - weighted_accuracy: 0.4768 - weighted_mse: 0.9042 - weighted_f1_m: 0.7316 - weighted_precision_m: 0.8153 - weighted_recall_m: 0.6814 - val_loss: 0.8948 - val_accuracy: 0.4781 - val_mse: 0.8948 - val_f1_m: 0.7338 - val_precision_m: 0.7639 - val_recall_m: 0.7158 - val_weighted_accuracy: 0.4781 - val_weighted_mse: 0.8948 - val_weighted_f1_m: 0.7338 - val_weighted_precision_m: 0.7639 - val_weighted_recall_m: 0.7158\n",
            "Epoch 8/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.9013 - accuracy: 0.4778 - mse: 0.9013 - f1_m: 0.7317 - precision_m: 0.7928 - recall_m: 0.6966 - weighted_accuracy: 0.4778 - weighted_mse: 0.9013 - weighted_f1_m: 0.7317 - weighted_precision_m: 0.7928 - weighted_recall_m: 0.6966 - val_loss: 0.9169 - val_accuracy: 0.4745 - val_mse: 0.9169 - val_f1_m: 0.6819 - val_precision_m: 0.8698 - val_recall_m: 0.5700 - val_weighted_accuracy: 0.4745 - val_weighted_mse: 0.9169 - val_weighted_f1_m: 0.6819 - val_weighted_precision_m: 0.8698 - val_weighted_recall_m: 0.5700\n",
            "Epoch 9/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8996 - accuracy: 0.4784 - mse: 0.8996 - f1_m: 0.7331 - precision_m: 0.8313 - recall_m: 0.6746 - weighted_accuracy: 0.4784 - weighted_mse: 0.8996 - weighted_f1_m: 0.7331 - weighted_precision_m: 0.8313 - weighted_recall_m: 0.6746 - val_loss: 0.8923 - val_accuracy: 0.4823 - val_mse: 0.8923 - val_f1_m: 0.7392 - val_precision_m: 0.8176 - val_recall_m: 0.6841 - val_weighted_accuracy: 0.4823 - val_weighted_mse: 0.8923 - val_weighted_f1_m: 0.7392 - val_weighted_precision_m: 0.8176 - val_weighted_recall_m: 0.6841\n",
            "Epoch 10/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8956 - accuracy: 0.4796 - mse: 0.8956 - f1_m: 0.7348 - precision_m: 0.8163 - recall_m: 0.6842 - weighted_accuracy: 0.4796 - weighted_mse: 0.8956 - weighted_f1_m: 0.7348 - weighted_precision_m: 0.8163 - weighted_recall_m: 0.6842 - val_loss: 0.8922 - val_accuracy: 0.4791 - val_mse: 0.8922 - val_f1_m: 0.7315 - val_precision_m: 0.8696 - val_recall_m: 0.6413 - val_weighted_accuracy: 0.4791 - val_weighted_mse: 0.8922 - val_weighted_f1_m: 0.7315 - val_weighted_precision_m: 0.8696 - val_weighted_recall_m: 0.6413\n",
            "Epoch 11/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8939 - accuracy: 0.4787 - mse: 0.8939 - f1_m: 0.7360 - precision_m: 0.8153 - recall_m: 0.6866 - weighted_accuracy: 0.4787 - weighted_mse: 0.8939 - weighted_f1_m: 0.7360 - weighted_precision_m: 0.8153 - weighted_recall_m: 0.6866 - val_loss: 0.8947 - val_accuracy: 0.4772 - val_mse: 0.8947 - val_f1_m: 0.7343 - val_precision_m: 0.7355 - val_recall_m: 0.7434 - val_weighted_accuracy: 0.4772 - val_weighted_mse: 0.8947 - val_weighted_f1_m: 0.7343 - val_weighted_precision_m: 0.7355 - val_weighted_recall_m: 0.7434\n",
            "Epoch 12/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8934 - accuracy: 0.4788 - mse: 0.8934 - f1_m: 0.7342 - precision_m: 0.8025 - recall_m: 0.6918 - weighted_accuracy: 0.4788 - weighted_mse: 0.8934 - weighted_f1_m: 0.7342 - weighted_precision_m: 0.8025 - weighted_recall_m: 0.6918 - val_loss: 0.8948 - val_accuracy: 0.4829 - val_mse: 0.8948 - val_f1_m: 0.7218 - val_precision_m: 0.8707 - val_recall_m: 0.6257 - val_weighted_accuracy: 0.4829 - val_weighted_mse: 0.8948 - val_weighted_f1_m: 0.7218 - val_weighted_precision_m: 0.8707 - val_weighted_recall_m: 0.6257\n",
            "Epoch 13/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8909 - accuracy: 0.4794 - mse: 0.8909 - f1_m: 0.7340 - precision_m: 0.7949 - recall_m: 0.6960 - weighted_accuracy: 0.4794 - weighted_mse: 0.8909 - weighted_f1_m: 0.7340 - weighted_precision_m: 0.7949 - weighted_recall_m: 0.6960 - val_loss: 0.8874 - val_accuracy: 0.4812 - val_mse: 0.8874 - val_f1_m: 0.7289 - val_precision_m: 0.8500 - val_recall_m: 0.6469 - val_weighted_accuracy: 0.4812 - val_weighted_mse: 0.8874 - val_weighted_f1_m: 0.7289 - val_weighted_precision_m: 0.8500 - val_weighted_recall_m: 0.6469\n",
            "Epoch 14/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8899 - accuracy: 0.4801 - mse: 0.8899 - f1_m: 0.7339 - precision_m: 0.8046 - recall_m: 0.6894 - weighted_accuracy: 0.4801 - weighted_mse: 0.8899 - weighted_f1_m: 0.7339 - weighted_precision_m: 0.8046 - weighted_recall_m: 0.6894 - val_loss: 0.8854 - val_accuracy: 0.4808 - val_mse: 0.8854 - val_f1_m: 0.7391 - val_precision_m: 0.8186 - val_recall_m: 0.6835 - val_weighted_accuracy: 0.4808 - val_weighted_mse: 0.8854 - val_weighted_f1_m: 0.7391 - val_weighted_precision_m: 0.8186 - val_weighted_recall_m: 0.6835\n",
            "Epoch 15/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8876 - accuracy: 0.4806 - mse: 0.8876 - f1_m: 0.7333 - precision_m: 0.8076 - recall_m: 0.6857 - weighted_accuracy: 0.4806 - weighted_mse: 0.8876 - weighted_f1_m: 0.7333 - weighted_precision_m: 0.8076 - weighted_recall_m: 0.6857 - val_loss: 0.8873 - val_accuracy: 0.4831 - val_mse: 0.8873 - val_f1_m: 0.7320 - val_precision_m: 0.8505 - val_recall_m: 0.6521 - val_weighted_accuracy: 0.4831 - val_weighted_mse: 0.8873 - val_weighted_f1_m: 0.7320 - val_weighted_precision_m: 0.8505 - val_weighted_recall_m: 0.6521\n",
            "Epoch 16/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8881 - accuracy: 0.4810 - mse: 0.8881 - f1_m: 0.7361 - precision_m: 0.8110 - recall_m: 0.6888 - weighted_accuracy: 0.4810 - weighted_mse: 0.8881 - weighted_f1_m: 0.7361 - weighted_precision_m: 0.8110 - weighted_recall_m: 0.6888 - val_loss: 0.8943 - val_accuracy: 0.4803 - val_mse: 0.8943 - val_f1_m: 0.7409 - val_precision_m: 0.7399 - val_recall_m: 0.7522 - val_weighted_accuracy: 0.4803 - val_weighted_mse: 0.8943 - val_weighted_f1_m: 0.7409 - val_weighted_precision_m: 0.7399 - val_weighted_recall_m: 0.7522\n",
            "Epoch 17/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8859 - accuracy: 0.4829 - mse: 0.8859 - f1_m: 0.7392 - precision_m: 0.8141 - recall_m: 0.6895 - weighted_accuracy: 0.4829 - weighted_mse: 0.8859 - weighted_f1_m: 0.7392 - weighted_precision_m: 0.8141 - weighted_recall_m: 0.6895 - val_loss: 0.8877 - val_accuracy: 0.4779 - val_mse: 0.8877 - val_f1_m: 0.7341 - val_precision_m: 0.7645 - val_recall_m: 0.7153 - val_weighted_accuracy: 0.4779 - val_weighted_mse: 0.8877 - val_weighted_f1_m: 0.7341 - val_weighted_precision_m: 0.7645 - val_weighted_recall_m: 0.7153\n",
            "Epoch 18/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8850 - accuracy: 0.4819 - mse: 0.8850 - f1_m: 0.7373 - precision_m: 0.8002 - recall_m: 0.6976 - weighted_accuracy: 0.4819 - weighted_mse: 0.8850 - weighted_f1_m: 0.7373 - weighted_precision_m: 0.8002 - weighted_recall_m: 0.6976 - val_loss: 0.8864 - val_accuracy: 0.4809 - val_mse: 0.8864 - val_f1_m: 0.7251 - val_precision_m: 0.8253 - val_recall_m: 0.6569 - val_weighted_accuracy: 0.4809 - val_weighted_mse: 0.8864 - val_weighted_f1_m: 0.7251 - val_weighted_precision_m: 0.8253 - val_weighted_recall_m: 0.6569\n",
            "Epoch 19/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8842 - accuracy: 0.4802 - mse: 0.8842 - f1_m: 0.7347 - precision_m: 0.8089 - recall_m: 0.6862 - weighted_accuracy: 0.4802 - weighted_mse: 0.8842 - weighted_f1_m: 0.7347 - weighted_precision_m: 0.8089 - weighted_recall_m: 0.6862 - val_loss: 0.8862 - val_accuracy: 0.4785 - val_mse: 0.8862 - val_f1_m: 0.7345 - val_precision_m: 0.7785 - val_recall_m: 0.7046 - val_weighted_accuracy: 0.4785 - val_weighted_mse: 0.8862 - val_weighted_f1_m: 0.7345 - val_weighted_precision_m: 0.7785 - val_weighted_recall_m: 0.7046\n",
            "Epoch 20/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8853 - accuracy: 0.4824 - mse: 0.8853 - f1_m: 0.7406 - precision_m: 0.8293 - recall_m: 0.6816 - weighted_accuracy: 0.4824 - weighted_mse: 0.8853 - weighted_f1_m: 0.7406 - weighted_precision_m: 0.8293 - weighted_recall_m: 0.6816 - val_loss: 0.8854 - val_accuracy: 0.4815 - val_mse: 0.8854 - val_f1_m: 0.7402 - val_precision_m: 0.8680 - val_recall_m: 0.6552 - val_weighted_accuracy: 0.4815 - val_weighted_mse: 0.8854 - val_weighted_f1_m: 0.7402 - val_weighted_precision_m: 0.8680 - val_weighted_recall_m: 0.6552\n",
            "Epoch 21/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8839 - accuracy: 0.4817 - mse: 0.8839 - f1_m: 0.7406 - precision_m: 0.8304 - recall_m: 0.6812 - weighted_accuracy: 0.4817 - weighted_mse: 0.8839 - weighted_f1_m: 0.7406 - weighted_precision_m: 0.8304 - weighted_recall_m: 0.6812 - val_loss: 0.8816 - val_accuracy: 0.4820 - val_mse: 0.8816 - val_f1_m: 0.7401 - val_precision_m: 0.8340 - val_recall_m: 0.6744 - val_weighted_accuracy: 0.4820 - val_weighted_mse: 0.8816 - val_weighted_f1_m: 0.7401 - val_weighted_precision_m: 0.8340 - val_weighted_recall_m: 0.6744\n",
            "Epoch 22/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8822 - accuracy: 0.4821 - mse: 0.8822 - f1_m: 0.7376 - precision_m: 0.8063 - recall_m: 0.6927 - weighted_accuracy: 0.4821 - weighted_mse: 0.8822 - weighted_f1_m: 0.7376 - weighted_precision_m: 0.8063 - weighted_recall_m: 0.6927 - val_loss: 0.8853 - val_accuracy: 0.4804 - val_mse: 0.8853 - val_f1_m: 0.7401 - val_precision_m: 0.7633 - val_recall_m: 0.7286 - val_weighted_accuracy: 0.4804 - val_weighted_mse: 0.8853 - val_weighted_f1_m: 0.7401 - val_weighted_precision_m: 0.7633 - val_weighted_recall_m: 0.7286\n",
            "Epoch 23/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8823 - accuracy: 0.4817 - mse: 0.8823 - f1_m: 0.7387 - precision_m: 0.8111 - recall_m: 0.6911 - weighted_accuracy: 0.4817 - weighted_mse: 0.8823 - weighted_f1_m: 0.7387 - weighted_precision_m: 0.8111 - weighted_recall_m: 0.6911 - val_loss: 0.8869 - val_accuracy: 0.4800 - val_mse: 0.8869 - val_f1_m: 0.7223 - val_precision_m: 0.8292 - val_recall_m: 0.6496 - val_weighted_accuracy: 0.4800 - val_weighted_mse: 0.8869 - val_weighted_f1_m: 0.7223 - val_weighted_precision_m: 0.8292 - val_weighted_recall_m: 0.6496\n",
            "Epoch 24/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8798 - accuracy: 0.4823 - mse: 0.8798 - f1_m: 0.7391 - precision_m: 0.8165 - recall_m: 0.6872 - weighted_accuracy: 0.4823 - weighted_mse: 0.8798 - weighted_f1_m: 0.7391 - weighted_precision_m: 0.8165 - weighted_recall_m: 0.6872 - val_loss: 0.8804 - val_accuracy: 0.4811 - val_mse: 0.8804 - val_f1_m: 0.7389 - val_precision_m: 0.7774 - val_recall_m: 0.7137 - val_weighted_accuracy: 0.4811 - val_weighted_mse: 0.8804 - val_weighted_f1_m: 0.7389 - val_weighted_precision_m: 0.7774 - val_weighted_recall_m: 0.7137\n",
            "Epoch 25/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8823 - accuracy: 0.4819 - mse: 0.8823 - f1_m: 0.7391 - precision_m: 0.8318 - recall_m: 0.6784 - weighted_accuracy: 0.4819 - weighted_mse: 0.8823 - weighted_f1_m: 0.7391 - weighted_precision_m: 0.8318 - weighted_recall_m: 0.6784 - val_loss: 0.8801 - val_accuracy: 0.4854 - val_mse: 0.8801 - val_f1_m: 0.7399 - val_precision_m: 0.8288 - val_recall_m: 0.6773 - val_weighted_accuracy: 0.4854 - val_weighted_mse: 0.8801 - val_weighted_f1_m: 0.7399 - val_weighted_precision_m: 0.8288 - val_weighted_recall_m: 0.6773\n",
            "Epoch 26/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8789 - accuracy: 0.4827 - mse: 0.8789 - f1_m: 0.7428 - precision_m: 0.8271 - recall_m: 0.6870 - weighted_accuracy: 0.4827 - weighted_mse: 0.8789 - weighted_f1_m: 0.7428 - weighted_precision_m: 0.8271 - weighted_recall_m: 0.6870 - val_loss: 0.8777 - val_accuracy: 0.4830 - val_mse: 0.8777 - val_f1_m: 0.7415 - val_precision_m: 0.8553 - val_recall_m: 0.6643 - val_weighted_accuracy: 0.4830 - val_weighted_mse: 0.8777 - val_weighted_f1_m: 0.7415 - val_weighted_precision_m: 0.8553 - val_weighted_recall_m: 0.6643\n",
            "Epoch 27/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8779 - accuracy: 0.4828 - mse: 0.8779 - f1_m: 0.7424 - precision_m: 0.8179 - recall_m: 0.6926 - weighted_accuracy: 0.4828 - weighted_mse: 0.8779 - weighted_f1_m: 0.7424 - weighted_precision_m: 0.8179 - weighted_recall_m: 0.6926 - val_loss: 0.8844 - val_accuracy: 0.4817 - val_mse: 0.8844 - val_f1_m: 0.7450 - val_precision_m: 0.8236 - val_recall_m: 0.6902 - val_weighted_accuracy: 0.4817 - val_weighted_mse: 0.8844 - val_weighted_f1_m: 0.7450 - val_weighted_precision_m: 0.8236 - val_weighted_recall_m: 0.6902\n",
            "Epoch 28/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8785 - accuracy: 0.4827 - mse: 0.8785 - f1_m: 0.7426 - precision_m: 0.8295 - recall_m: 0.6843 - weighted_accuracy: 0.4827 - weighted_mse: 0.8785 - weighted_f1_m: 0.7426 - weighted_precision_m: 0.8295 - weighted_recall_m: 0.6843 - val_loss: 0.8770 - val_accuracy: 0.4843 - val_mse: 0.8770 - val_f1_m: 0.7409 - val_precision_m: 0.8364 - val_recall_m: 0.6741 - val_weighted_accuracy: 0.4843 - val_weighted_mse: 0.8770 - val_weighted_f1_m: 0.7409 - val_weighted_precision_m: 0.8364 - val_weighted_recall_m: 0.6741\n",
            "Epoch 29/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8756 - accuracy: 0.4830 - mse: 0.8756 - f1_m: 0.7433 - precision_m: 0.8192 - recall_m: 0.6921 - weighted_accuracy: 0.4830 - weighted_mse: 0.8756 - weighted_f1_m: 0.7433 - weighted_precision_m: 0.8192 - weighted_recall_m: 0.6921 - val_loss: 0.8845 - val_accuracy: 0.4812 - val_mse: 0.8845 - val_f1_m: 0.7374 - val_precision_m: 0.7636 - val_recall_m: 0.7223 - val_weighted_accuracy: 0.4812 - val_weighted_mse: 0.8845 - val_weighted_f1_m: 0.7374 - val_weighted_precision_m: 0.7636 - val_weighted_recall_m: 0.7223\n",
            "Epoch 30/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8899 - accuracy: 0.4811 - mse: 0.8899 - f1_m: 0.7346 - precision_m: 0.8133 - recall_m: 0.6851 - weighted_accuracy: 0.4811 - weighted_mse: 0.8899 - weighted_f1_m: 0.7346 - weighted_precision_m: 0.8133 - weighted_recall_m: 0.6851 - val_loss: 0.8918 - val_accuracy: 0.4824 - val_mse: 0.8918 - val_f1_m: 0.7291 - val_precision_m: 0.7950 - val_recall_m: 0.6829 - val_weighted_accuracy: 0.4824 - val_weighted_mse: 0.8918 - val_weighted_f1_m: 0.7291 - val_weighted_precision_m: 0.7950 - val_weighted_recall_m: 0.6829\n",
            "Epoch 31/300\n",
            "996/996 [==============================] - 5s 6ms/step - loss: 0.8764 - accuracy: 0.4823 - mse: 0.8764 - f1_m: 0.7427 - precision_m: 0.8139 - recall_m: 0.6946 - weighted_accuracy: 0.4823 - weighted_mse: 0.8764 - weighted_f1_m: 0.7427 - weighted_precision_m: 0.8139 - weighted_recall_m: 0.6946 - val_loss: 0.9002 - val_accuracy: 0.4811 - val_mse: 0.9002 - val_f1_m: 0.6988 - val_precision_m: 0.8800 - val_recall_m: 0.5883 - val_weighted_accuracy: 0.4811 - val_weighted_mse: 0.9002 - val_weighted_f1_m: 0.6988 - val_weighted_precision_m: 0.8800 - val_weighted_recall_m: 0.5883\n",
            "Epoch 32/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8758 - accuracy: 0.4838 - mse: 0.8758 - f1_m: 0.7435 - precision_m: 0.8169 - recall_m: 0.6923 - weighted_accuracy: 0.4838 - weighted_mse: 0.8758 - weighted_f1_m: 0.7435 - weighted_precision_m: 0.8169 - weighted_recall_m: 0.6923 - val_loss: 0.8802 - val_accuracy: 0.4846 - val_mse: 0.8802 - val_f1_m: 0.7285 - val_precision_m: 0.8272 - val_recall_m: 0.6599 - val_weighted_accuracy: 0.4846 - val_weighted_mse: 0.8802 - val_weighted_f1_m: 0.7285 - val_weighted_precision_m: 0.8272 - val_weighted_recall_m: 0.6599\n",
            "Epoch 33/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8754 - accuracy: 0.4830 - mse: 0.8754 - f1_m: 0.7431 - precision_m: 0.8156 - recall_m: 0.6942 - weighted_accuracy: 0.4830 - weighted_mse: 0.8754 - weighted_f1_m: 0.7431 - weighted_precision_m: 0.8156 - weighted_recall_m: 0.6942 - val_loss: 0.8773 - val_accuracy: 0.4826 - val_mse: 0.8773 - val_f1_m: 0.7427 - val_precision_m: 0.8063 - val_recall_m: 0.6976 - val_weighted_accuracy: 0.4826 - val_weighted_mse: 0.8773 - val_weighted_f1_m: 0.7427 - val_weighted_precision_m: 0.8063 - val_weighted_recall_m: 0.6976\n",
            "Epoch 34/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8757 - accuracy: 0.4828 - mse: 0.8757 - f1_m: 0.7426 - precision_m: 0.8219 - recall_m: 0.6892 - weighted_accuracy: 0.4828 - weighted_mse: 0.8757 - weighted_f1_m: 0.7426 - weighted_precision_m: 0.8219 - weighted_recall_m: 0.6892 - val_loss: 0.8819 - val_accuracy: 0.4831 - val_mse: 0.8819 - val_f1_m: 0.7260 - val_precision_m: 0.8455 - val_recall_m: 0.6455 - val_weighted_accuracy: 0.4831 - val_weighted_mse: 0.8819 - val_weighted_f1_m: 0.7260 - val_weighted_precision_m: 0.8455 - val_weighted_recall_m: 0.6455\n",
            "Epoch 35/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8755 - accuracy: 0.4831 - mse: 0.8755 - f1_m: 0.7425 - precision_m: 0.8113 - recall_m: 0.6966 - weighted_accuracy: 0.4831 - weighted_mse: 0.8755 - weighted_f1_m: 0.7425 - weighted_precision_m: 0.8113 - weighted_recall_m: 0.6966 - val_loss: 0.8818 - val_accuracy: 0.4837 - val_mse: 0.8818 - val_f1_m: 0.7318 - val_precision_m: 0.8607 - val_recall_m: 0.6455 - val_weighted_accuracy: 0.4837 - val_weighted_mse: 0.8818 - val_weighted_f1_m: 0.7318 - val_weighted_precision_m: 0.8607 - val_weighted_recall_m: 0.6455\n",
            "Epoch 36/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8730 - accuracy: 0.4844 - mse: 0.8730 - f1_m: 0.7450 - precision_m: 0.8142 - recall_m: 0.6971 - weighted_accuracy: 0.4844 - weighted_mse: 0.8730 - weighted_f1_m: 0.7450 - weighted_precision_m: 0.8142 - weighted_recall_m: 0.6971 - val_loss: 0.8826 - val_accuracy: 0.4820 - val_mse: 0.8826 - val_f1_m: 0.7247 - val_precision_m: 0.8441 - val_recall_m: 0.6445 - val_weighted_accuracy: 0.4820 - val_weighted_mse: 0.8826 - val_weighted_f1_m: 0.7247 - val_weighted_precision_m: 0.8441 - val_weighted_recall_m: 0.6445\n",
            "Epoch 37/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8803 - accuracy: 0.4829 - mse: 0.8803 - f1_m: 0.7392 - precision_m: 0.8278 - recall_m: 0.6796 - weighted_accuracy: 0.4829 - weighted_mse: 0.8803 - weighted_f1_m: 0.7392 - weighted_precision_m: 0.8278 - weighted_recall_m: 0.6796 - val_loss: 0.8943 - val_accuracy: 0.4795 - val_mse: 0.8943 - val_f1_m: 0.7375 - val_precision_m: 0.7809 - val_recall_m: 0.7086 - val_weighted_accuracy: 0.4795 - val_weighted_mse: 0.8943 - val_weighted_f1_m: 0.7375 - val_weighted_precision_m: 0.7809 - val_weighted_recall_m: 0.7086\n",
            "Epoch 38/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8780 - accuracy: 0.4834 - mse: 0.8780 - f1_m: 0.7433 - precision_m: 0.8270 - recall_m: 0.6861 - weighted_accuracy: 0.4834 - weighted_mse: 0.8780 - weighted_f1_m: 0.7433 - weighted_precision_m: 0.8270 - weighted_recall_m: 0.6861 - val_loss: 0.8803 - val_accuracy: 0.4849 - val_mse: 0.8803 - val_f1_m: 0.7441 - val_precision_m: 0.7974 - val_recall_m: 0.7072 - val_weighted_accuracy: 0.4849 - val_weighted_mse: 0.8803 - val_weighted_f1_m: 0.7441 - val_weighted_precision_m: 0.7974 - val_weighted_recall_m: 0.7072\n",
            "Epoch 39/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8735 - accuracy: 0.4842 - mse: 0.8735 - f1_m: 0.7441 - precision_m: 0.8237 - recall_m: 0.6898 - weighted_accuracy: 0.4842 - weighted_mse: 0.8735 - weighted_f1_m: 0.7441 - weighted_precision_m: 0.8237 - weighted_recall_m: 0.6898 - val_loss: 0.8761 - val_accuracy: 0.4869 - val_mse: 0.8761 - val_f1_m: 0.7414 - val_precision_m: 0.8506 - val_recall_m: 0.6662 - val_weighted_accuracy: 0.4869 - val_weighted_mse: 0.8761 - val_weighted_f1_m: 0.7414 - val_weighted_precision_m: 0.8506 - val_weighted_recall_m: 0.6662\n",
            "Epoch 40/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8734 - accuracy: 0.4846 - mse: 0.8734 - f1_m: 0.7448 - precision_m: 0.8238 - recall_m: 0.6923 - weighted_accuracy: 0.4846 - weighted_mse: 0.8734 - weighted_f1_m: 0.7448 - weighted_precision_m: 0.8238 - weighted_recall_m: 0.6923 - val_loss: 0.8938 - val_accuracy: 0.4824 - val_mse: 0.8938 - val_f1_m: 0.7373 - val_precision_m: 0.7838 - val_recall_m: 0.7049 - val_weighted_accuracy: 0.4824 - val_weighted_mse: 0.8938 - val_weighted_f1_m: 0.7373 - val_weighted_precision_m: 0.7838 - val_weighted_recall_m: 0.7049\n",
            "Epoch 41/300\n",
            "996/996 [==============================] - 8s 8ms/step - loss: 0.8726 - accuracy: 0.4845 - mse: 0.8726 - f1_m: 0.7462 - precision_m: 0.8281 - recall_m: 0.6909 - weighted_accuracy: 0.4845 - weighted_mse: 0.8726 - weighted_f1_m: 0.7462 - weighted_precision_m: 0.8281 - weighted_recall_m: 0.6909 - val_loss: 0.8756 - val_accuracy: 0.4855 - val_mse: 0.8756 - val_f1_m: 0.7457 - val_precision_m: 0.8222 - val_recall_m: 0.6915 - val_weighted_accuracy: 0.4855 - val_weighted_mse: 0.8756 - val_weighted_f1_m: 0.7457 - val_weighted_precision_m: 0.8222 - val_weighted_recall_m: 0.6915\n",
            "Epoch 42/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8730 - accuracy: 0.4841 - mse: 0.8730 - f1_m: 0.7461 - precision_m: 0.8300 - recall_m: 0.6892 - weighted_accuracy: 0.4841 - weighted_mse: 0.8730 - weighted_f1_m: 0.7461 - weighted_precision_m: 0.8300 - weighted_recall_m: 0.6892 - val_loss: 0.8771 - val_accuracy: 0.4822 - val_mse: 0.8771 - val_f1_m: 0.7474 - val_precision_m: 0.8163 - val_recall_m: 0.6985 - val_weighted_accuracy: 0.4822 - val_weighted_mse: 0.8771 - val_weighted_f1_m: 0.7474 - val_weighted_precision_m: 0.8163 - val_weighted_recall_m: 0.6985\n",
            "Epoch 43/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8725 - accuracy: 0.4842 - mse: 0.8725 - f1_m: 0.7470 - precision_m: 0.8214 - recall_m: 0.6967 - weighted_accuracy: 0.4842 - weighted_mse: 0.8725 - weighted_f1_m: 0.7470 - weighted_precision_m: 0.8214 - weighted_recall_m: 0.6967 - val_loss: 0.8783 - val_accuracy: 0.4815 - val_mse: 0.8783 - val_f1_m: 0.7332 - val_precision_m: 0.8080 - val_recall_m: 0.6806 - val_weighted_accuracy: 0.4815 - val_weighted_mse: 0.8783 - val_weighted_f1_m: 0.7332 - val_weighted_precision_m: 0.8080 - val_weighted_recall_m: 0.6806\n",
            "Epoch 44/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8719 - accuracy: 0.4842 - mse: 0.8719 - f1_m: 0.7462 - precision_m: 0.8258 - recall_m: 0.6923 - weighted_accuracy: 0.4842 - weighted_mse: 0.8719 - weighted_f1_m: 0.7462 - weighted_precision_m: 0.8258 - weighted_recall_m: 0.6923 - val_loss: 0.8775 - val_accuracy: 0.4852 - val_mse: 0.8775 - val_f1_m: 0.7381 - val_precision_m: 0.8384 - val_recall_m: 0.6684 - val_weighted_accuracy: 0.4852 - val_weighted_mse: 0.8775 - val_weighted_f1_m: 0.7381 - val_weighted_precision_m: 0.8384 - val_weighted_recall_m: 0.6684\n",
            "Epoch 45/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8715 - accuracy: 0.4843 - mse: 0.8715 - f1_m: 0.7467 - precision_m: 0.8188 - recall_m: 0.6979 - weighted_accuracy: 0.4843 - weighted_mse: 0.8715 - weighted_f1_m: 0.7467 - weighted_precision_m: 0.8188 - weighted_recall_m: 0.6979 - val_loss: 0.8823 - val_accuracy: 0.4804 - val_mse: 0.8823 - val_f1_m: 0.7385 - val_precision_m: 0.8000 - val_recall_m: 0.6954 - val_weighted_accuracy: 0.4804 - val_weighted_mse: 0.8823 - val_weighted_f1_m: 0.7385 - val_weighted_precision_m: 0.8000 - val_weighted_recall_m: 0.6954\n",
            "Epoch 46/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8709 - accuracy: 0.4844 - mse: 0.8709 - f1_m: 0.7469 - precision_m: 0.8170 - recall_m: 0.6987 - weighted_accuracy: 0.4844 - weighted_mse: 0.8709 - weighted_f1_m: 0.7469 - weighted_precision_m: 0.8170 - weighted_recall_m: 0.6987 - val_loss: 0.8788 - val_accuracy: 0.4843 - val_mse: 0.8788 - val_f1_m: 0.7351 - val_precision_m: 0.7945 - val_recall_m: 0.6926 - val_weighted_accuracy: 0.4843 - val_weighted_mse: 0.8788 - val_weighted_f1_m: 0.7351 - val_weighted_precision_m: 0.7945 - val_weighted_recall_m: 0.6926\n",
            "Epoch 47/300\n",
            "996/996 [==============================] - 8s 8ms/step - loss: 0.8711 - accuracy: 0.4855 - mse: 0.8711 - f1_m: 0.7454 - precision_m: 0.8158 - recall_m: 0.6976 - weighted_accuracy: 0.4855 - weighted_mse: 0.8711 - weighted_f1_m: 0.7454 - weighted_precision_m: 0.8158 - weighted_recall_m: 0.6976 - val_loss: 0.8748 - val_accuracy: 0.4866 - val_mse: 0.8748 - val_f1_m: 0.7463 - val_precision_m: 0.8165 - val_recall_m: 0.6961 - val_weighted_accuracy: 0.4866 - val_weighted_mse: 0.8748 - val_weighted_f1_m: 0.7463 - val_weighted_precision_m: 0.8165 - val_weighted_recall_m: 0.6961\n",
            "Epoch 48/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8739 - accuracy: 0.4845 - mse: 0.8739 - f1_m: 0.7452 - precision_m: 0.8239 - recall_m: 0.6911 - weighted_accuracy: 0.4845 - weighted_mse: 0.8739 - weighted_f1_m: 0.7452 - weighted_precision_m: 0.8239 - weighted_recall_m: 0.6911 - val_loss: 0.8737 - val_accuracy: 0.4845 - val_mse: 0.8737 - val_f1_m: 0.7464 - val_precision_m: 0.8359 - val_recall_m: 0.6834 - val_weighted_accuracy: 0.4845 - val_weighted_mse: 0.8737 - val_weighted_f1_m: 0.7464 - val_weighted_precision_m: 0.8359 - val_weighted_recall_m: 0.6834\n",
            "Epoch 49/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8723 - accuracy: 0.4835 - mse: 0.8723 - f1_m: 0.7429 - precision_m: 0.8218 - recall_m: 0.6900 - weighted_accuracy: 0.4835 - weighted_mse: 0.8723 - weighted_f1_m: 0.7429 - weighted_precision_m: 0.8218 - weighted_recall_m: 0.6900 - val_loss: 0.8955 - val_accuracy: 0.4818 - val_mse: 0.8955 - val_f1_m: 0.7054 - val_precision_m: 0.9003 - val_recall_m: 0.5889 - val_weighted_accuracy: 0.4818 - val_weighted_mse: 0.8955 - val_weighted_f1_m: 0.7054 - val_weighted_precision_m: 0.9003 - val_weighted_recall_m: 0.5889\n",
            "Epoch 50/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8760 - accuracy: 0.4835 - mse: 0.8760 - f1_m: 0.7437 - precision_m: 0.8299 - recall_m: 0.6855 - weighted_accuracy: 0.4835 - weighted_mse: 0.8760 - weighted_f1_m: 0.7437 - weighted_precision_m: 0.8299 - weighted_recall_m: 0.6855 - val_loss: 0.8785 - val_accuracy: 0.4857 - val_mse: 0.8785 - val_f1_m: 0.7479 - val_precision_m: 0.8217 - val_recall_m: 0.6952 - val_weighted_accuracy: 0.4857 - val_weighted_mse: 0.8785 - val_weighted_f1_m: 0.7479 - val_weighted_precision_m: 0.8217 - val_weighted_recall_m: 0.6952\n",
            "Epoch 51/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8707 - accuracy: 0.4841 - mse: 0.8707 - f1_m: 0.7478 - precision_m: 0.8247 - recall_m: 0.6958 - weighted_accuracy: 0.4841 - weighted_mse: 0.8707 - weighted_f1_m: 0.7478 - weighted_precision_m: 0.8247 - weighted_recall_m: 0.6958 - val_loss: 0.8761 - val_accuracy: 0.4840 - val_mse: 0.8761 - val_f1_m: 0.7398 - val_precision_m: 0.7911 - val_recall_m: 0.7035 - val_weighted_accuracy: 0.4840 - val_weighted_mse: 0.8761 - val_weighted_f1_m: 0.7398 - val_weighted_precision_m: 0.7911 - val_weighted_recall_m: 0.7035\n",
            "Epoch 52/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8686 - accuracy: 0.4835 - mse: 0.8686 - f1_m: 0.7452 - precision_m: 0.8111 - recall_m: 0.6999 - weighted_accuracy: 0.4835 - weighted_mse: 0.8686 - weighted_f1_m: 0.7452 - weighted_precision_m: 0.8111 - weighted_recall_m: 0.6999 - val_loss: 0.8737 - val_accuracy: 0.4860 - val_mse: 0.8737 - val_f1_m: 0.7418 - val_precision_m: 0.8081 - val_recall_m: 0.6944 - val_weighted_accuracy: 0.4860 - val_weighted_mse: 0.8737 - val_weighted_f1_m: 0.7418 - val_weighted_precision_m: 0.8081 - val_weighted_recall_m: 0.6944\n",
            "Epoch 53/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8701 - accuracy: 0.4854 - mse: 0.8701 - f1_m: 0.7475 - precision_m: 0.8300 - recall_m: 0.6914 - weighted_accuracy: 0.4854 - weighted_mse: 0.8701 - weighted_f1_m: 0.7475 - weighted_precision_m: 0.8300 - weighted_recall_m: 0.6914 - val_loss: 0.8823 - val_accuracy: 0.4811 - val_mse: 0.8823 - val_f1_m: 0.7409 - val_precision_m: 0.8198 - val_recall_m: 0.6851 - val_weighted_accuracy: 0.4811 - val_weighted_mse: 0.8823 - val_weighted_f1_m: 0.7409 - val_weighted_precision_m: 0.8198 - val_weighted_recall_m: 0.6851\n",
            "Epoch 54/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8734 - accuracy: 0.4838 - mse: 0.8734 - f1_m: 0.7467 - precision_m: 0.8265 - recall_m: 0.6919 - weighted_accuracy: 0.4838 - weighted_mse: 0.8734 - weighted_f1_m: 0.7467 - weighted_precision_m: 0.8265 - weighted_recall_m: 0.6919 - val_loss: 0.8933 - val_accuracy: 0.4843 - val_mse: 0.8933 - val_f1_m: 0.7152 - val_precision_m: 0.8293 - val_recall_m: 0.6377 - val_weighted_accuracy: 0.4843 - val_weighted_mse: 0.8933 - val_weighted_f1_m: 0.7152 - val_weighted_precision_m: 0.8293 - val_weighted_recall_m: 0.6377\n",
            "Epoch 55/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8685 - accuracy: 0.4843 - mse: 0.8685 - f1_m: 0.7476 - precision_m: 0.8122 - recall_m: 0.7027 - weighted_accuracy: 0.4843 - weighted_mse: 0.8685 - weighted_f1_m: 0.7476 - weighted_precision_m: 0.8122 - weighted_recall_m: 0.7027 - val_loss: 0.8850 - val_accuracy: 0.4834 - val_mse: 0.8850 - val_f1_m: 0.7265 - val_precision_m: 0.8430 - val_recall_m: 0.6471 - val_weighted_accuracy: 0.4834 - val_weighted_mse: 0.8850 - val_weighted_f1_m: 0.7265 - val_weighted_precision_m: 0.8430 - val_weighted_recall_m: 0.6471\n",
            "Epoch 56/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8751 - accuracy: 0.4834 - mse: 0.8751 - f1_m: 0.7425 - precision_m: 0.8225 - recall_m: 0.6891 - weighted_accuracy: 0.4834 - weighted_mse: 0.8751 - weighted_f1_m: 0.7425 - weighted_precision_m: 0.8225 - weighted_recall_m: 0.6891 - val_loss: 0.8834 - val_accuracy: 0.4843 - val_mse: 0.8834 - val_f1_m: 0.7400 - val_precision_m: 0.8171 - val_recall_m: 0.6852 - val_weighted_accuracy: 0.4843 - val_weighted_mse: 0.8834 - val_weighted_f1_m: 0.7400 - val_weighted_precision_m: 0.8171 - val_weighted_recall_m: 0.6852\n",
            "Epoch 57/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8690 - accuracy: 0.4859 - mse: 0.8690 - f1_m: 0.7486 - precision_m: 0.8239 - recall_m: 0.6960 - weighted_accuracy: 0.4859 - weighted_mse: 0.8690 - weighted_f1_m: 0.7486 - weighted_precision_m: 0.8239 - weighted_recall_m: 0.6960 - val_loss: 0.8922 - val_accuracy: 0.4782 - val_mse: 0.8922 - val_f1_m: 0.7377 - val_precision_m: 0.7493 - val_recall_m: 0.7367 - val_weighted_accuracy: 0.4782 - val_weighted_mse: 0.8922 - val_weighted_f1_m: 0.7377 - val_weighted_precision_m: 0.7493 - val_weighted_recall_m: 0.7367\n",
            "Epoch 58/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8782 - accuracy: 0.4819 - mse: 0.8782 - f1_m: 0.7401 - precision_m: 0.8231 - recall_m: 0.6855 - weighted_accuracy: 0.4819 - weighted_mse: 0.8782 - weighted_f1_m: 0.7401 - weighted_precision_m: 0.8231 - weighted_recall_m: 0.6855 - val_loss: 0.8841 - val_accuracy: 0.4815 - val_mse: 0.8841 - val_f1_m: 0.7461 - val_precision_m: 0.7901 - val_recall_m: 0.7168 - val_weighted_accuracy: 0.4815 - val_weighted_mse: 0.8841 - val_weighted_f1_m: 0.7461 - val_weighted_precision_m: 0.7901 - val_weighted_recall_m: 0.7168\n",
            "Epoch 59/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8768 - accuracy: 0.4828 - mse: 0.8768 - f1_m: 0.7403 - precision_m: 0.8173 - recall_m: 0.6876 - weighted_accuracy: 0.4828 - weighted_mse: 0.8768 - weighted_f1_m: 0.7403 - weighted_precision_m: 0.8173 - weighted_recall_m: 0.6876 - val_loss: 0.8821 - val_accuracy: 0.4869 - val_mse: 0.8821 - val_f1_m: 0.7295 - val_precision_m: 0.8406 - val_recall_m: 0.6531 - val_weighted_accuracy: 0.4869 - val_weighted_mse: 0.8821 - val_weighted_f1_m: 0.7295 - val_weighted_precision_m: 0.8406 - val_weighted_recall_m: 0.6531\n",
            "Epoch 60/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8708 - accuracy: 0.4851 - mse: 0.8708 - f1_m: 0.7463 - precision_m: 0.8230 - recall_m: 0.6930 - weighted_accuracy: 0.4851 - weighted_mse: 0.8708 - weighted_f1_m: 0.7463 - weighted_precision_m: 0.8230 - weighted_recall_m: 0.6930 - val_loss: 0.8802 - val_accuracy: 0.4813 - val_mse: 0.8802 - val_f1_m: 0.7433 - val_precision_m: 0.7735 - val_recall_m: 0.7247 - val_weighted_accuracy: 0.4813 - val_weighted_mse: 0.8802 - val_weighted_f1_m: 0.7433 - val_weighted_precision_m: 0.7735 - val_weighted_recall_m: 0.7247\n",
            "Epoch 61/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8703 - accuracy: 0.4855 - mse: 0.8703 - f1_m: 0.7467 - precision_m: 0.8227 - recall_m: 0.6949 - weighted_accuracy: 0.4855 - weighted_mse: 0.8703 - weighted_f1_m: 0.7467 - weighted_precision_m: 0.8227 - weighted_recall_m: 0.6949 - val_loss: 0.8715 - val_accuracy: 0.4862 - val_mse: 0.8715 - val_f1_m: 0.7495 - val_precision_m: 0.8188 - val_recall_m: 0.7000 - val_weighted_accuracy: 0.4862 - val_weighted_mse: 0.8715 - val_weighted_f1_m: 0.7495 - val_weighted_precision_m: 0.8188 - val_weighted_recall_m: 0.7000\n",
            "Epoch 62/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8720 - accuracy: 0.4841 - mse: 0.8720 - f1_m: 0.7460 - precision_m: 0.8154 - recall_m: 0.6992 - weighted_accuracy: 0.4841 - weighted_mse: 0.8720 - weighted_f1_m: 0.7460 - weighted_precision_m: 0.8154 - weighted_recall_m: 0.6992 - val_loss: 0.8741 - val_accuracy: 0.4831 - val_mse: 0.8741 - val_f1_m: 0.7334 - val_precision_m: 0.8157 - val_recall_m: 0.6759 - val_weighted_accuracy: 0.4831 - val_weighted_mse: 0.8741 - val_weighted_f1_m: 0.7334 - val_weighted_precision_m: 0.8157 - val_weighted_recall_m: 0.6759\n",
            "Epoch 63/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8703 - accuracy: 0.4853 - mse: 0.8703 - f1_m: 0.7469 - precision_m: 0.8233 - recall_m: 0.6943 - weighted_accuracy: 0.4853 - weighted_mse: 0.8703 - weighted_f1_m: 0.7469 - weighted_precision_m: 0.8233 - weighted_recall_m: 0.6943 - val_loss: 0.8750 - val_accuracy: 0.4839 - val_mse: 0.8750 - val_f1_m: 0.7514 - val_precision_m: 0.8112 - val_recall_m: 0.7089 - val_weighted_accuracy: 0.4839 - val_weighted_mse: 0.8750 - val_weighted_f1_m: 0.7514 - val_weighted_precision_m: 0.8112 - val_weighted_recall_m: 0.7089\n",
            "Epoch 64/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8699 - accuracy: 0.4843 - mse: 0.8699 - f1_m: 0.7476 - precision_m: 0.8204 - recall_m: 0.6985 - weighted_accuracy: 0.4843 - weighted_mse: 0.8699 - weighted_f1_m: 0.7476 - weighted_precision_m: 0.8204 - weighted_recall_m: 0.6985 - val_loss: 0.8753 - val_accuracy: 0.4855 - val_mse: 0.8753 - val_f1_m: 0.7339 - val_precision_m: 0.8335 - val_recall_m: 0.6645 - val_weighted_accuracy: 0.4855 - val_weighted_mse: 0.8753 - val_weighted_f1_m: 0.7339 - val_weighted_precision_m: 0.8335 - val_weighted_recall_m: 0.6645\n",
            "Epoch 65/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8700 - accuracy: 0.4857 - mse: 0.8700 - f1_m: 0.7436 - precision_m: 0.8165 - recall_m: 0.6944 - weighted_accuracy: 0.4857 - weighted_mse: 0.8700 - weighted_f1_m: 0.7436 - weighted_precision_m: 0.8165 - weighted_recall_m: 0.6944 - val_loss: 0.8810 - val_accuracy: 0.4829 - val_mse: 0.8810 - val_f1_m: 0.7493 - val_precision_m: 0.7754 - val_recall_m: 0.7342 - val_weighted_accuracy: 0.4829 - val_weighted_mse: 0.8810 - val_weighted_f1_m: 0.7493 - val_weighted_precision_m: 0.7754 - val_weighted_recall_m: 0.7342\n",
            "Epoch 66/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8675 - accuracy: 0.4846 - mse: 0.8675 - f1_m: 0.7457 - precision_m: 0.8122 - recall_m: 0.7005 - weighted_accuracy: 0.4846 - weighted_mse: 0.8675 - weighted_f1_m: 0.7457 - weighted_precision_m: 0.8122 - weighted_recall_m: 0.7005 - val_loss: 0.8738 - val_accuracy: 0.4848 - val_mse: 0.8738 - val_f1_m: 0.7390 - val_precision_m: 0.8456 - val_recall_m: 0.6652 - val_weighted_accuracy: 0.4848 - val_weighted_mse: 0.8738 - val_weighted_f1_m: 0.7390 - val_weighted_precision_m: 0.8456 - val_weighted_recall_m: 0.6652\n",
            "Epoch 67/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8699 - accuracy: 0.4849 - mse: 0.8699 - f1_m: 0.7485 - precision_m: 0.8242 - recall_m: 0.6965 - weighted_accuracy: 0.4849 - weighted_mse: 0.8699 - weighted_f1_m: 0.7485 - weighted_precision_m: 0.8242 - weighted_recall_m: 0.6965 - val_loss: 0.8756 - val_accuracy: 0.4846 - val_mse: 0.8756 - val_f1_m: 0.7478 - val_precision_m: 0.7974 - val_recall_m: 0.7131 - val_weighted_accuracy: 0.4846 - val_weighted_mse: 0.8756 - val_weighted_f1_m: 0.7478 - val_weighted_precision_m: 0.7974 - val_weighted_recall_m: 0.7131\n",
            "Epoch 68/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8700 - accuracy: 0.4842 - mse: 0.8700 - f1_m: 0.7444 - precision_m: 0.8280 - recall_m: 0.6891 - weighted_accuracy: 0.4842 - weighted_mse: 0.8700 - weighted_f1_m: 0.7444 - weighted_precision_m: 0.8280 - weighted_recall_m: 0.6891 - val_loss: 0.8983 - val_accuracy: 0.4768 - val_mse: 0.8983 - val_f1_m: 0.7254 - val_precision_m: 0.7874 - val_recall_m: 0.6828 - val_weighted_accuracy: 0.4768 - val_weighted_mse: 0.8983 - val_weighted_f1_m: 0.7254 - val_weighted_precision_m: 0.7874 - val_weighted_recall_m: 0.6828\n",
            "Epoch 69/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8684 - accuracy: 0.4851 - mse: 0.8684 - f1_m: 0.7484 - precision_m: 0.8121 - recall_m: 0.7041 - weighted_accuracy: 0.4851 - weighted_mse: 0.8684 - weighted_f1_m: 0.7484 - weighted_precision_m: 0.8121 - weighted_recall_m: 0.7041 - val_loss: 0.8762 - val_accuracy: 0.4859 - val_mse: 0.8762 - val_f1_m: 0.7374 - val_precision_m: 0.8381 - val_recall_m: 0.6672 - val_weighted_accuracy: 0.4859 - val_weighted_mse: 0.8762 - val_weighted_f1_m: 0.7374 - val_weighted_precision_m: 0.8381 - val_weighted_recall_m: 0.6672\n",
            "Epoch 70/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8661 - accuracy: 0.4845 - mse: 0.8661 - f1_m: 0.7496 - precision_m: 0.8174 - recall_m: 0.7026 - weighted_accuracy: 0.4845 - weighted_mse: 0.8661 - weighted_f1_m: 0.7496 - weighted_precision_m: 0.8174 - weighted_recall_m: 0.7026 - val_loss: 0.8743 - val_accuracy: 0.4839 - val_mse: 0.8743 - val_f1_m: 0.7481 - val_precision_m: 0.7987 - val_recall_m: 0.7128 - val_weighted_accuracy: 0.4839 - val_weighted_mse: 0.8743 - val_weighted_f1_m: 0.7481 - val_weighted_precision_m: 0.7987 - val_weighted_recall_m: 0.7128\n",
            "Epoch 71/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8693 - accuracy: 0.4843 - mse: 0.8693 - f1_m: 0.7468 - precision_m: 0.8148 - recall_m: 0.6992 - weighted_accuracy: 0.4843 - weighted_mse: 0.8693 - weighted_f1_m: 0.7468 - weighted_precision_m: 0.8148 - weighted_recall_m: 0.6992 - val_loss: 0.8718 - val_accuracy: 0.4857 - val_mse: 0.8718 - val_f1_m: 0.7448 - val_precision_m: 0.8174 - val_recall_m: 0.6932 - val_weighted_accuracy: 0.4857 - val_weighted_mse: 0.8718 - val_weighted_f1_m: 0.7448 - val_weighted_precision_m: 0.8174 - val_weighted_recall_m: 0.6932\n",
            "Epoch 72/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8652 - accuracy: 0.4855 - mse: 0.8652 - f1_m: 0.7509 - precision_m: 0.8220 - recall_m: 0.7001 - weighted_accuracy: 0.4855 - weighted_mse: 0.8652 - weighted_f1_m: 0.7509 - weighted_precision_m: 0.8220 - weighted_recall_m: 0.7001 - val_loss: 0.8762 - val_accuracy: 0.4850 - val_mse: 0.8762 - val_f1_m: 0.7348 - val_precision_m: 0.8363 - val_recall_m: 0.6645 - val_weighted_accuracy: 0.4850 - val_weighted_mse: 0.8762 - val_weighted_f1_m: 0.7348 - val_weighted_precision_m: 0.8363 - val_weighted_recall_m: 0.6645\n",
            "Epoch 73/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8770 - accuracy: 0.4838 - mse: 0.8770 - f1_m: 0.7406 - precision_m: 0.8205 - recall_m: 0.6872 - weighted_accuracy: 0.4838 - weighted_mse: 0.8770 - weighted_f1_m: 0.7406 - weighted_precision_m: 0.8205 - weighted_recall_m: 0.6872 - val_loss: 0.8782 - val_accuracy: 0.4859 - val_mse: 0.8782 - val_f1_m: 0.7457 - val_precision_m: 0.8163 - val_recall_m: 0.6959 - val_weighted_accuracy: 0.4859 - val_weighted_mse: 0.8782 - val_weighted_f1_m: 0.7457 - val_weighted_precision_m: 0.8163 - val_weighted_recall_m: 0.6959\n",
            "Epoch 74/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8814 - accuracy: 0.4829 - mse: 0.8814 - f1_m: 0.7442 - precision_m: 0.8084 - recall_m: 0.7023 - weighted_accuracy: 0.4829 - weighted_mse: 0.8814 - weighted_f1_m: 0.7442 - weighted_precision_m: 0.8084 - weighted_recall_m: 0.7023 - val_loss: 0.8813 - val_accuracy: 0.4830 - val_mse: 0.8813 - val_f1_m: 0.7465 - val_precision_m: 0.8036 - val_recall_m: 0.7068 - val_weighted_accuracy: 0.4830 - val_weighted_mse: 0.8813 - val_weighted_f1_m: 0.7465 - val_weighted_precision_m: 0.8036 - val_weighted_recall_m: 0.7068\n",
            "Epoch 75/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8737 - accuracy: 0.4838 - mse: 0.8737 - f1_m: 0.7426 - precision_m: 0.8060 - recall_m: 0.7008 - weighted_accuracy: 0.4838 - weighted_mse: 0.8737 - weighted_f1_m: 0.7426 - weighted_precision_m: 0.8060 - weighted_recall_m: 0.7008 - val_loss: 0.8767 - val_accuracy: 0.4843 - val_mse: 0.8767 - val_f1_m: 0.7390 - val_precision_m: 0.8051 - val_recall_m: 0.6929 - val_weighted_accuracy: 0.4843 - val_weighted_mse: 0.8767 - val_weighted_f1_m: 0.7390 - val_weighted_precision_m: 0.8051 - val_weighted_recall_m: 0.6929\n",
            "Epoch 76/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8678 - accuracy: 0.4861 - mse: 0.8678 - f1_m: 0.7473 - precision_m: 0.8213 - recall_m: 0.6955 - weighted_accuracy: 0.4861 - weighted_mse: 0.8678 - weighted_f1_m: 0.7473 - weighted_precision_m: 0.8213 - weighted_recall_m: 0.6955 - val_loss: 0.8784 - val_accuracy: 0.4837 - val_mse: 0.8784 - val_f1_m: 0.7471 - val_precision_m: 0.7806 - val_recall_m: 0.7269 - val_weighted_accuracy: 0.4837 - val_weighted_mse: 0.8784 - val_weighted_f1_m: 0.7471 - val_weighted_precision_m: 0.7806 - val_weighted_recall_m: 0.7269\n",
            "Epoch 77/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8682 - accuracy: 0.4848 - mse: 0.8682 - f1_m: 0.7448 - precision_m: 0.8190 - recall_m: 0.6950 - weighted_accuracy: 0.4848 - weighted_mse: 0.8682 - weighted_f1_m: 0.7448 - weighted_precision_m: 0.8190 - weighted_recall_m: 0.6950 - val_loss: 0.8787 - val_accuracy: 0.4841 - val_mse: 0.8787 - val_f1_m: 0.7475 - val_precision_m: 0.7897 - val_recall_m: 0.7190 - val_weighted_accuracy: 0.4841 - val_weighted_mse: 0.8787 - val_weighted_f1_m: 0.7475 - val_weighted_precision_m: 0.7897 - val_weighted_recall_m: 0.7190\n",
            "Epoch 78/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8689 - accuracy: 0.4853 - mse: 0.8689 - f1_m: 0.7485 - precision_m: 0.8158 - recall_m: 0.7029 - weighted_accuracy: 0.4853 - weighted_mse: 0.8689 - weighted_f1_m: 0.7485 - weighted_precision_m: 0.8158 - weighted_recall_m: 0.7029 - val_loss: 0.8853 - val_accuracy: 0.4862 - val_mse: 0.8853 - val_f1_m: 0.7222 - val_precision_m: 0.8315 - val_recall_m: 0.6470 - val_weighted_accuracy: 0.4862 - val_weighted_mse: 0.8853 - val_weighted_f1_m: 0.7222 - val_weighted_precision_m: 0.8315 - val_weighted_recall_m: 0.6470\n",
            "Epoch 79/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8659 - accuracy: 0.4859 - mse: 0.8659 - f1_m: 0.7489 - precision_m: 0.8205 - recall_m: 0.6998 - weighted_accuracy: 0.4859 - weighted_mse: 0.8659 - weighted_f1_m: 0.7489 - weighted_precision_m: 0.8205 - weighted_recall_m: 0.6998 - val_loss: 0.8814 - val_accuracy: 0.4856 - val_mse: 0.8814 - val_f1_m: 0.7217 - val_precision_m: 0.8406 - val_recall_m: 0.6412 - val_weighted_accuracy: 0.4856 - val_weighted_mse: 0.8814 - val_weighted_f1_m: 0.7217 - val_weighted_precision_m: 0.8406 - val_weighted_recall_m: 0.6412\n",
            "Epoch 80/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8686 - accuracy: 0.4840 - mse: 0.8686 - f1_m: 0.7447 - precision_m: 0.8046 - recall_m: 0.7047 - weighted_accuracy: 0.4840 - weighted_mse: 0.8686 - weighted_f1_m: 0.7447 - weighted_precision_m: 0.8046 - weighted_recall_m: 0.7047 - val_loss: 0.8888 - val_accuracy: 0.4781 - val_mse: 0.8888 - val_f1_m: 0.7307 - val_precision_m: 0.7581 - val_recall_m: 0.7150 - val_weighted_accuracy: 0.4781 - val_weighted_mse: 0.8888 - val_weighted_f1_m: 0.7307 - val_weighted_precision_m: 0.7581 - val_weighted_recall_m: 0.7150\n",
            "Epoch 81/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8686 - accuracy: 0.4852 - mse: 0.8686 - f1_m: 0.7477 - precision_m: 0.8107 - recall_m: 0.7039 - weighted_accuracy: 0.4852 - weighted_mse: 0.8686 - weighted_f1_m: 0.7477 - weighted_precision_m: 0.8107 - weighted_recall_m: 0.7039 - val_loss: 0.8786 - val_accuracy: 0.4825 - val_mse: 0.8786 - val_f1_m: 0.7420 - val_precision_m: 0.8077 - val_recall_m: 0.6959 - val_weighted_accuracy: 0.4825 - val_weighted_mse: 0.8786 - val_weighted_f1_m: 0.7420 - val_weighted_precision_m: 0.8077 - val_weighted_recall_m: 0.6959\n",
            "Epoch 82/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8695 - accuracy: 0.4850 - mse: 0.8695 - f1_m: 0.7468 - precision_m: 0.8163 - recall_m: 0.6992 - weighted_accuracy: 0.4850 - weighted_mse: 0.8695 - weighted_f1_m: 0.7468 - weighted_precision_m: 0.8163 - weighted_recall_m: 0.6992 - val_loss: 0.8728 - val_accuracy: 0.4857 - val_mse: 0.8728 - val_f1_m: 0.7495 - val_precision_m: 0.8021 - val_recall_m: 0.7127 - val_weighted_accuracy: 0.4857 - val_weighted_mse: 0.8728 - val_weighted_f1_m: 0.7495 - val_weighted_precision_m: 0.8021 - val_weighted_recall_m: 0.7127\n",
            "Epoch 83/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8690 - accuracy: 0.4854 - mse: 0.8690 - f1_m: 0.7500 - precision_m: 0.8279 - recall_m: 0.6970 - weighted_accuracy: 0.4854 - weighted_mse: 0.8690 - weighted_f1_m: 0.7500 - weighted_precision_m: 0.8279 - weighted_recall_m: 0.6970 - val_loss: 0.8808 - val_accuracy: 0.4864 - val_mse: 0.8808 - val_f1_m: 0.7284 - val_precision_m: 0.8287 - val_recall_m: 0.6585 - val_weighted_accuracy: 0.4864 - val_weighted_mse: 0.8808 - val_weighted_f1_m: 0.7284 - val_weighted_precision_m: 0.8287 - val_weighted_recall_m: 0.6585\n",
            "Epoch 84/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8656 - accuracy: 0.4867 - mse: 0.8656 - f1_m: 0.7507 - precision_m: 0.8185 - recall_m: 0.7035 - weighted_accuracy: 0.4867 - weighted_mse: 0.8656 - weighted_f1_m: 0.7507 - weighted_precision_m: 0.8185 - weighted_recall_m: 0.7035 - val_loss: 0.8741 - val_accuracy: 0.4866 - val_mse: 0.8741 - val_f1_m: 0.7488 - val_precision_m: 0.7988 - val_recall_m: 0.7139 - val_weighted_accuracy: 0.4866 - val_weighted_mse: 0.8741 - val_weighted_f1_m: 0.7488 - val_weighted_precision_m: 0.7988 - val_weighted_recall_m: 0.7139\n",
            "Epoch 85/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8640 - accuracy: 0.4862 - mse: 0.8640 - f1_m: 0.7496 - precision_m: 0.8139 - recall_m: 0.7069 - weighted_accuracy: 0.4862 - weighted_mse: 0.8640 - weighted_f1_m: 0.7496 - weighted_precision_m: 0.8139 - weighted_recall_m: 0.7069 - val_loss: 0.8784 - val_accuracy: 0.4873 - val_mse: 0.8784 - val_f1_m: 0.7298 - val_precision_m: 0.8496 - val_recall_m: 0.6482 - val_weighted_accuracy: 0.4873 - val_weighted_mse: 0.8784 - val_weighted_f1_m: 0.7298 - val_weighted_precision_m: 0.8496 - val_weighted_recall_m: 0.6482\n",
            "Epoch 86/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8666 - accuracy: 0.4853 - mse: 0.8666 - f1_m: 0.7490 - precision_m: 0.8264 - recall_m: 0.6959 - weighted_accuracy: 0.4853 - weighted_mse: 0.8666 - weighted_f1_m: 0.7490 - weighted_precision_m: 0.8264 - weighted_recall_m: 0.6959 - val_loss: 0.8743 - val_accuracy: 0.4854 - val_mse: 0.8743 - val_f1_m: 0.7552 - val_precision_m: 0.8338 - val_recall_m: 0.6995 - val_weighted_accuracy: 0.4854 - val_weighted_mse: 0.8743 - val_weighted_f1_m: 0.7552 - val_weighted_precision_m: 0.8338 - val_weighted_recall_m: 0.6995\n",
            "Epoch 87/300\n",
            "996/996 [==============================] - 6s 7ms/step - loss: 0.8630 - accuracy: 0.4862 - mse: 0.8630 - f1_m: 0.7528 - precision_m: 0.8193 - recall_m: 0.7065 - weighted_accuracy: 0.4862 - weighted_mse: 0.8630 - weighted_f1_m: 0.7528 - weighted_precision_m: 0.8193 - weighted_recall_m: 0.7065 - val_loss: 0.8719 - val_accuracy: 0.4844 - val_mse: 0.8719 - val_f1_m: 0.7441 - val_precision_m: 0.8084 - val_recall_m: 0.6986 - val_weighted_accuracy: 0.4844 - val_weighted_mse: 0.8719 - val_weighted_f1_m: 0.7441 - val_weighted_precision_m: 0.8084 - val_weighted_recall_m: 0.6986\n",
            "Epoch 88/300\n",
            "996/996 [==============================] - 8s 8ms/step - loss: 0.8624 - accuracy: 0.4856 - mse: 0.8624 - f1_m: 0.7514 - precision_m: 0.8216 - recall_m: 0.7024 - weighted_accuracy: 0.4856 - weighted_mse: 0.8624 - weighted_f1_m: 0.7514 - weighted_precision_m: 0.8216 - weighted_recall_m: 0.7024 - val_loss: 0.8736 - val_accuracy: 0.4857 - val_mse: 0.8736 - val_f1_m: 0.7382 - val_precision_m: 0.8374 - val_recall_m: 0.6687 - val_weighted_accuracy: 0.4857 - val_weighted_mse: 0.8736 - val_weighted_f1_m: 0.7382 - val_weighted_precision_m: 0.8374 - val_weighted_recall_m: 0.6687\n",
            "Epoch 89/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8631 - accuracy: 0.4862 - mse: 0.8631 - f1_m: 0.7532 - precision_m: 0.8199 - recall_m: 0.7059 - weighted_accuracy: 0.4862 - weighted_mse: 0.8631 - weighted_f1_m: 0.7532 - weighted_precision_m: 0.8199 - weighted_recall_m: 0.7059 - val_loss: 0.8812 - val_accuracy: 0.4815 - val_mse: 0.8812 - val_f1_m: 0.7291 - val_precision_m: 0.8493 - val_recall_m: 0.6474 - val_weighted_accuracy: 0.4815 - val_weighted_mse: 0.8812 - val_weighted_f1_m: 0.7291 - val_weighted_precision_m: 0.8493 - val_weighted_recall_m: 0.6474\n",
            "Epoch 90/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8657 - accuracy: 0.4853 - mse: 0.8657 - f1_m: 0.7499 - precision_m: 0.8247 - recall_m: 0.6986 - weighted_accuracy: 0.4853 - weighted_mse: 0.8657 - weighted_f1_m: 0.7499 - weighted_precision_m: 0.8247 - weighted_recall_m: 0.6986 - val_loss: 0.8782 - val_accuracy: 0.4827 - val_mse: 0.8782 - val_f1_m: 0.7447 - val_precision_m: 0.8019 - val_recall_m: 0.7044 - val_weighted_accuracy: 0.4827 - val_weighted_mse: 0.8782 - val_weighted_f1_m: 0.7447 - val_weighted_precision_m: 0.8019 - val_weighted_recall_m: 0.7044\n",
            "Epoch 91/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8653 - accuracy: 0.4855 - mse: 0.8653 - f1_m: 0.7493 - precision_m: 0.8117 - recall_m: 0.7060 - weighted_accuracy: 0.4855 - weighted_mse: 0.8653 - weighted_f1_m: 0.7493 - weighted_precision_m: 0.8117 - weighted_recall_m: 0.7060 - val_loss: 0.8805 - val_accuracy: 0.4815 - val_mse: 0.8805 - val_f1_m: 0.7447 - val_precision_m: 0.7613 - val_recall_m: 0.7391 - val_weighted_accuracy: 0.4815 - val_weighted_mse: 0.8805 - val_weighted_f1_m: 0.7447 - val_weighted_precision_m: 0.7613 - val_weighted_recall_m: 0.7391\n",
            "Epoch 92/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8622 - accuracy: 0.4856 - mse: 0.8622 - f1_m: 0.7505 - precision_m: 0.8200 - recall_m: 0.7023 - weighted_accuracy: 0.4856 - weighted_mse: 0.8622 - weighted_f1_m: 0.7505 - weighted_precision_m: 0.8200 - weighted_recall_m: 0.7023 - val_loss: 0.8972 - val_accuracy: 0.4799 - val_mse: 0.8972 - val_f1_m: 0.7459 - val_precision_m: 0.7408 - val_recall_m: 0.7610 - val_weighted_accuracy: 0.4799 - val_weighted_mse: 0.8972 - val_weighted_f1_m: 0.7459 - val_weighted_precision_m: 0.7408 - val_weighted_recall_m: 0.7610\n",
            "Epoch 93/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8679 - accuracy: 0.4856 - mse: 0.8679 - f1_m: 0.7504 - precision_m: 0.8186 - recall_m: 0.7045 - weighted_accuracy: 0.4856 - weighted_mse: 0.8679 - weighted_f1_m: 0.7504 - weighted_precision_m: 0.8186 - weighted_recall_m: 0.7045 - val_loss: 0.8732 - val_accuracy: 0.4855 - val_mse: 0.8732 - val_f1_m: 0.7387 - val_precision_m: 0.8228 - val_recall_m: 0.6787 - val_weighted_accuracy: 0.4855 - val_weighted_mse: 0.8732 - val_weighted_f1_m: 0.7387 - val_weighted_precision_m: 0.8228 - val_weighted_recall_m: 0.6787\n",
            "Epoch 94/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8628 - accuracy: 0.4861 - mse: 0.8628 - f1_m: 0.7517 - precision_m: 0.8169 - recall_m: 0.7065 - weighted_accuracy: 0.4861 - weighted_mse: 0.8628 - weighted_f1_m: 0.7517 - weighted_precision_m: 0.8169 - weighted_recall_m: 0.7065 - val_loss: 0.8738 - val_accuracy: 0.4868 - val_mse: 0.8738 - val_f1_m: 0.7516 - val_precision_m: 0.8041 - val_recall_m: 0.7147 - val_weighted_accuracy: 0.4868 - val_weighted_mse: 0.8738 - val_weighted_f1_m: 0.7516 - val_weighted_precision_m: 0.8041 - val_weighted_recall_m: 0.7147\n",
            "Epoch 95/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8631 - accuracy: 0.4860 - mse: 0.8631 - f1_m: 0.7490 - precision_m: 0.8095 - recall_m: 0.7070 - weighted_accuracy: 0.4860 - weighted_mse: 0.8631 - weighted_f1_m: 0.7490 - weighted_precision_m: 0.8095 - weighted_recall_m: 0.7070 - val_loss: 0.8732 - val_accuracy: 0.4839 - val_mse: 0.8732 - val_f1_m: 0.7484 - val_precision_m: 0.8017 - val_recall_m: 0.7104 - val_weighted_accuracy: 0.4839 - val_weighted_mse: 0.8732 - val_weighted_f1_m: 0.7484 - val_weighted_precision_m: 0.8017 - val_weighted_recall_m: 0.7104\n",
            "Epoch 96/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8625 - accuracy: 0.4857 - mse: 0.8625 - f1_m: 0.7514 - precision_m: 0.8151 - recall_m: 0.7067 - weighted_accuracy: 0.4857 - weighted_mse: 0.8625 - weighted_f1_m: 0.7514 - weighted_precision_m: 0.8151 - weighted_recall_m: 0.7067 - val_loss: 0.8703 - val_accuracy: 0.4874 - val_mse: 0.8703 - val_f1_m: 0.7420 - val_precision_m: 0.8171 - val_recall_m: 0.6887 - val_weighted_accuracy: 0.4874 - val_weighted_mse: 0.8703 - val_weighted_f1_m: 0.7420 - val_weighted_precision_m: 0.8171 - val_weighted_recall_m: 0.6887\n",
            "Epoch 97/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8632 - accuracy: 0.4861 - mse: 0.8632 - f1_m: 0.7535 - precision_m: 0.8122 - recall_m: 0.7131 - weighted_accuracy: 0.4861 - weighted_mse: 0.8632 - weighted_f1_m: 0.7535 - weighted_precision_m: 0.8122 - weighted_recall_m: 0.7131 - val_loss: 0.8741 - val_accuracy: 0.4826 - val_mse: 0.8741 - val_f1_m: 0.7401 - val_precision_m: 0.7807 - val_recall_m: 0.7132 - val_weighted_accuracy: 0.4826 - val_weighted_mse: 0.8741 - val_weighted_f1_m: 0.7401 - val_weighted_precision_m: 0.7807 - val_weighted_recall_m: 0.7132\n",
            "Epoch 98/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8629 - accuracy: 0.4855 - mse: 0.8629 - f1_m: 0.7501 - precision_m: 0.8190 - recall_m: 0.7033 - weighted_accuracy: 0.4855 - weighted_mse: 0.8629 - weighted_f1_m: 0.7501 - weighted_precision_m: 0.8190 - weighted_recall_m: 0.7033 - val_loss: 0.8813 - val_accuracy: 0.4835 - val_mse: 0.8813 - val_f1_m: 0.7429 - val_precision_m: 0.7843 - val_recall_m: 0.7145 - val_weighted_accuracy: 0.4835 - val_weighted_mse: 0.8813 - val_weighted_f1_m: 0.7429 - val_weighted_precision_m: 0.7843 - val_weighted_recall_m: 0.7145\n",
            "Epoch 99/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8657 - accuracy: 0.4853 - mse: 0.8657 - f1_m: 0.7493 - precision_m: 0.8101 - recall_m: 0.7081 - weighted_accuracy: 0.4853 - weighted_mse: 0.8657 - weighted_f1_m: 0.7493 - weighted_precision_m: 0.8101 - weighted_recall_m: 0.7081 - val_loss: 0.8705 - val_accuracy: 0.4864 - val_mse: 0.8705 - val_f1_m: 0.7473 - val_precision_m: 0.8168 - val_recall_m: 0.6976 - val_weighted_accuracy: 0.4864 - val_weighted_mse: 0.8705 - val_weighted_f1_m: 0.7473 - val_weighted_precision_m: 0.8168 - val_weighted_recall_m: 0.6976\n",
            "Epoch 100/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8615 - accuracy: 0.4862 - mse: 0.8615 - f1_m: 0.7539 - precision_m: 0.8194 - recall_m: 0.7089 - weighted_accuracy: 0.4862 - weighted_mse: 0.8615 - weighted_f1_m: 0.7539 - weighted_precision_m: 0.8194 - weighted_recall_m: 0.7089 - val_loss: 0.8724 - val_accuracy: 0.4850 - val_mse: 0.8724 - val_f1_m: 0.7436 - val_precision_m: 0.8012 - val_recall_m: 0.7033 - val_weighted_accuracy: 0.4850 - val_weighted_mse: 0.8724 - val_weighted_f1_m: 0.7436 - val_weighted_precision_m: 0.8012 - val_weighted_recall_m: 0.7033\n",
            "Epoch 101/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8627 - accuracy: 0.4846 - mse: 0.8627 - f1_m: 0.7519 - precision_m: 0.7981 - recall_m: 0.7219 - weighted_accuracy: 0.4846 - weighted_mse: 0.8627 - weighted_f1_m: 0.7519 - weighted_precision_m: 0.7981 - weighted_recall_m: 0.7219 - val_loss: 0.8840 - val_accuracy: 0.4805 - val_mse: 0.8840 - val_f1_m: 0.7267 - val_precision_m: 0.7799 - val_recall_m: 0.6896 - val_weighted_accuracy: 0.4805 - val_weighted_mse: 0.8840 - val_weighted_f1_m: 0.7267 - val_weighted_precision_m: 0.7799 - val_weighted_recall_m: 0.6896\n",
            "Epoch 102/300\n",
            "996/996 [==============================] - 6s 7ms/step - loss: 0.8638 - accuracy: 0.4853 - mse: 0.8638 - f1_m: 0.7503 - precision_m: 0.8153 - recall_m: 0.7072 - weighted_accuracy: 0.4853 - weighted_mse: 0.8638 - weighted_f1_m: 0.7503 - weighted_precision_m: 0.8153 - weighted_recall_m: 0.7072 - val_loss: 0.8723 - val_accuracy: 0.4843 - val_mse: 0.8723 - val_f1_m: 0.7401 - val_precision_m: 0.8241 - val_recall_m: 0.6802 - val_weighted_accuracy: 0.4843 - val_weighted_mse: 0.8723 - val_weighted_f1_m: 0.7401 - val_weighted_precision_m: 0.8241 - val_weighted_recall_m: 0.6802\n",
            "Epoch 103/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8642 - accuracy: 0.4855 - mse: 0.8642 - f1_m: 0.7519 - precision_m: 0.8195 - recall_m: 0.7059 - weighted_accuracy: 0.4855 - weighted_mse: 0.8642 - weighted_f1_m: 0.7519 - weighted_precision_m: 0.8195 - weighted_recall_m: 0.7059 - val_loss: 0.8796 - val_accuracy: 0.4817 - val_mse: 0.8796 - val_f1_m: 0.7412 - val_precision_m: 0.7994 - val_recall_m: 0.7009 - val_weighted_accuracy: 0.4817 - val_weighted_mse: 0.8796 - val_weighted_f1_m: 0.7412 - val_weighted_precision_m: 0.7994 - val_weighted_recall_m: 0.7009\n",
            "Epoch 104/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8646 - accuracy: 0.4859 - mse: 0.8646 - f1_m: 0.7539 - precision_m: 0.8180 - recall_m: 0.7088 - weighted_accuracy: 0.4859 - weighted_mse: 0.8646 - weighted_f1_m: 0.7539 - weighted_precision_m: 0.8180 - weighted_recall_m: 0.7088 - val_loss: 0.8991 - val_accuracy: 0.4771 - val_mse: 0.8991 - val_f1_m: 0.7424 - val_precision_m: 0.7314 - val_recall_m: 0.7634 - val_weighted_accuracy: 0.4771 - val_weighted_mse: 0.8991 - val_weighted_f1_m: 0.7424 - val_weighted_precision_m: 0.7314 - val_weighted_recall_m: 0.7634\n",
            "Epoch 105/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8759 - accuracy: 0.4841 - mse: 0.8759 - f1_m: 0.7475 - precision_m: 0.8091 - recall_m: 0.7059 - weighted_accuracy: 0.4841 - weighted_mse: 0.8759 - weighted_f1_m: 0.7475 - weighted_precision_m: 0.8091 - weighted_recall_m: 0.7059 - val_loss: 0.8733 - val_accuracy: 0.4857 - val_mse: 0.8733 - val_f1_m: 0.7362 - val_precision_m: 0.8405 - val_recall_m: 0.6641 - val_weighted_accuracy: 0.4857 - val_weighted_mse: 0.8733 - val_weighted_f1_m: 0.7362 - val_weighted_precision_m: 0.8405 - val_weighted_recall_m: 0.6641\n",
            "Epoch 106/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8608 - accuracy: 0.4872 - mse: 0.8608 - f1_m: 0.7549 - precision_m: 0.8281 - recall_m: 0.7040 - weighted_accuracy: 0.4872 - weighted_mse: 0.8608 - weighted_f1_m: 0.7549 - weighted_precision_m: 0.8281 - weighted_recall_m: 0.7040 - val_loss: 0.8703 - val_accuracy: 0.4870 - val_mse: 0.8703 - val_f1_m: 0.7538 - val_precision_m: 0.8077 - val_recall_m: 0.7159 - val_weighted_accuracy: 0.4870 - val_weighted_mse: 0.8703 - val_weighted_f1_m: 0.7538 - val_weighted_precision_m: 0.8077 - val_weighted_recall_m: 0.7159\n",
            "Epoch 107/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8606 - accuracy: 0.4870 - mse: 0.8606 - f1_m: 0.7529 - precision_m: 0.8267 - recall_m: 0.7015 - weighted_accuracy: 0.4870 - weighted_mse: 0.8606 - weighted_f1_m: 0.7529 - weighted_precision_m: 0.8267 - weighted_recall_m: 0.7015 - val_loss: 0.8732 - val_accuracy: 0.4849 - val_mse: 0.8732 - val_f1_m: 0.7414 - val_precision_m: 0.8204 - val_recall_m: 0.6852 - val_weighted_accuracy: 0.4849 - val_weighted_mse: 0.8732 - val_weighted_f1_m: 0.7414 - val_weighted_precision_m: 0.8204 - val_weighted_recall_m: 0.6852\n",
            "Epoch 108/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8634 - accuracy: 0.4855 - mse: 0.8634 - f1_m: 0.7502 - precision_m: 0.8222 - recall_m: 0.7001 - weighted_accuracy: 0.4855 - weighted_mse: 0.8634 - weighted_f1_m: 0.7502 - weighted_precision_m: 0.8222 - weighted_recall_m: 0.7001 - val_loss: 0.8856 - val_accuracy: 0.4842 - val_mse: 0.8856 - val_f1_m: 0.7352 - val_precision_m: 0.8516 - val_recall_m: 0.6555 - val_weighted_accuracy: 0.4842 - val_weighted_mse: 0.8856 - val_weighted_f1_m: 0.7352 - val_weighted_precision_m: 0.8516 - val_weighted_recall_m: 0.6555\n",
            "Epoch 109/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8608 - accuracy: 0.4860 - mse: 0.8608 - f1_m: 0.7504 - precision_m: 0.8228 - recall_m: 0.7000 - weighted_accuracy: 0.4860 - weighted_mse: 0.8608 - weighted_f1_m: 0.7504 - weighted_precision_m: 0.8228 - weighted_recall_m: 0.7000 - val_loss: 0.8727 - val_accuracy: 0.4856 - val_mse: 0.8727 - val_f1_m: 0.7462 - val_precision_m: 0.8090 - val_recall_m: 0.7020 - val_weighted_accuracy: 0.4856 - val_weighted_mse: 0.8727 - val_weighted_f1_m: 0.7462 - val_weighted_precision_m: 0.8090 - val_weighted_recall_m: 0.7020\n",
            "Epoch 110/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8620 - accuracy: 0.4871 - mse: 0.8620 - f1_m: 0.7541 - precision_m: 0.8266 - recall_m: 0.7029 - weighted_accuracy: 0.4871 - weighted_mse: 0.8620 - weighted_f1_m: 0.7541 - weighted_precision_m: 0.8266 - weighted_recall_m: 0.7029 - val_loss: 0.9155 - val_accuracy: 0.4798 - val_mse: 0.9155 - val_f1_m: 0.6814 - val_precision_m: 0.8663 - val_recall_m: 0.5709 - val_weighted_accuracy: 0.4798 - val_weighted_mse: 0.9155 - val_weighted_f1_m: 0.6814 - val_weighted_precision_m: 0.8663 - val_weighted_recall_m: 0.5709\n",
            "Epoch 111/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8655 - accuracy: 0.4864 - mse: 0.8655 - f1_m: 0.7515 - precision_m: 0.8273 - recall_m: 0.7004 - weighted_accuracy: 0.4864 - weighted_mse: 0.8655 - weighted_f1_m: 0.7515 - weighted_precision_m: 0.8273 - weighted_recall_m: 0.7004 - val_loss: 0.8695 - val_accuracy: 0.4855 - val_mse: 0.8695 - val_f1_m: 0.7475 - val_precision_m: 0.8241 - val_recall_m: 0.6935 - val_weighted_accuracy: 0.4855 - val_weighted_mse: 0.8695 - val_weighted_f1_m: 0.7475 - val_weighted_precision_m: 0.8241 - val_weighted_recall_m: 0.6935\n",
            "Epoch 112/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8582 - accuracy: 0.4881 - mse: 0.8582 - f1_m: 0.7567 - precision_m: 0.8294 - recall_m: 0.7048 - weighted_accuracy: 0.4881 - weighted_mse: 0.8582 - weighted_f1_m: 0.7567 - weighted_precision_m: 0.8294 - weighted_recall_m: 0.7048 - val_loss: 0.8905 - val_accuracy: 0.4862 - val_mse: 0.8905 - val_f1_m: 0.7214 - val_precision_m: 0.8651 - val_recall_m: 0.6275 - val_weighted_accuracy: 0.4862 - val_weighted_mse: 0.8905 - val_weighted_f1_m: 0.7214 - val_weighted_precision_m: 0.8651 - val_weighted_recall_m: 0.6275\n",
            "Epoch 113/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8614 - accuracy: 0.4864 - mse: 0.8614 - f1_m: 0.7542 - precision_m: 0.8250 - recall_m: 0.7053 - weighted_accuracy: 0.4864 - weighted_mse: 0.8614 - weighted_f1_m: 0.7542 - weighted_precision_m: 0.8250 - weighted_recall_m: 0.7053 - val_loss: 0.8804 - val_accuracy: 0.4811 - val_mse: 0.8804 - val_f1_m: 0.7457 - val_precision_m: 0.7687 - val_recall_m: 0.7334 - val_weighted_accuracy: 0.4811 - val_weighted_mse: 0.8804 - val_weighted_f1_m: 0.7457 - val_weighted_precision_m: 0.7687 - val_weighted_recall_m: 0.7334\n",
            "Epoch 114/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8577 - accuracy: 0.4867 - mse: 0.8577 - f1_m: 0.7538 - precision_m: 0.8258 - recall_m: 0.7037 - weighted_accuracy: 0.4867 - weighted_mse: 0.8577 - weighted_f1_m: 0.7538 - weighted_precision_m: 0.8258 - weighted_recall_m: 0.7037 - val_loss: 0.8722 - val_accuracy: 0.4862 - val_mse: 0.8722 - val_f1_m: 0.7433 - val_precision_m: 0.8367 - val_recall_m: 0.6775 - val_weighted_accuracy: 0.4862 - val_weighted_mse: 0.8722 - val_weighted_f1_m: 0.7433 - val_weighted_precision_m: 0.8367 - val_weighted_recall_m: 0.6775\n",
            "Epoch 115/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8614 - accuracy: 0.4861 - mse: 0.8614 - f1_m: 0.7521 - precision_m: 0.8268 - recall_m: 0.7002 - weighted_accuracy: 0.4861 - weighted_mse: 0.8614 - weighted_f1_m: 0.7521 - weighted_precision_m: 0.8268 - weighted_recall_m: 0.7002 - val_loss: 0.8803 - val_accuracy: 0.4825 - val_mse: 0.8803 - val_f1_m: 0.7330 - val_precision_m: 0.8278 - val_recall_m: 0.6664 - val_weighted_accuracy: 0.4825 - val_weighted_mse: 0.8803 - val_weighted_f1_m: 0.7330 - val_weighted_precision_m: 0.8278 - val_weighted_recall_m: 0.6664\n",
            "Epoch 116/300\n",
            "996/996 [==============================] - 6s 7ms/step - loss: 0.8623 - accuracy: 0.4871 - mse: 0.8623 - f1_m: 0.7538 - precision_m: 0.8275 - recall_m: 0.7024 - weighted_accuracy: 0.4871 - weighted_mse: 0.8623 - weighted_f1_m: 0.7538 - weighted_precision_m: 0.8275 - weighted_recall_m: 0.7024 - val_loss: 0.8735 - val_accuracy: 0.4861 - val_mse: 0.8735 - val_f1_m: 0.7458 - val_precision_m: 0.8333 - val_recall_m: 0.6839 - val_weighted_accuracy: 0.4861 - val_weighted_mse: 0.8735 - val_weighted_f1_m: 0.7458 - val_weighted_precision_m: 0.8333 - val_weighted_recall_m: 0.6839\n",
            "Epoch 117/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8590 - accuracy: 0.4881 - mse: 0.8590 - f1_m: 0.7549 - precision_m: 0.8232 - recall_m: 0.7070 - weighted_accuracy: 0.4881 - weighted_mse: 0.8590 - weighted_f1_m: 0.7549 - weighted_precision_m: 0.8232 - weighted_recall_m: 0.7070 - val_loss: 0.8824 - val_accuracy: 0.4860 - val_mse: 0.8824 - val_f1_m: 0.7316 - val_precision_m: 0.8469 - val_recall_m: 0.6524 - val_weighted_accuracy: 0.4860 - val_weighted_mse: 0.8824 - val_weighted_f1_m: 0.7316 - val_weighted_precision_m: 0.8469 - val_weighted_recall_m: 0.6524\n",
            "Epoch 118/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8624 - accuracy: 0.4870 - mse: 0.8624 - f1_m: 0.7517 - precision_m: 0.8269 - recall_m: 0.6997 - weighted_accuracy: 0.4870 - weighted_mse: 0.8624 - weighted_f1_m: 0.7517 - weighted_precision_m: 0.8269 - weighted_recall_m: 0.6997 - val_loss: 0.8733 - val_accuracy: 0.4838 - val_mse: 0.8733 - val_f1_m: 0.7484 - val_precision_m: 0.8006 - val_recall_m: 0.7120 - val_weighted_accuracy: 0.4838 - val_weighted_mse: 0.8733 - val_weighted_f1_m: 0.7484 - val_weighted_precision_m: 0.8006 - val_weighted_recall_m: 0.7120\n",
            "Epoch 119/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8582 - accuracy: 0.4864 - mse: 0.8582 - f1_m: 0.7556 - precision_m: 0.8333 - recall_m: 0.7019 - weighted_accuracy: 0.4864 - weighted_mse: 0.8582 - weighted_f1_m: 0.7556 - weighted_precision_m: 0.8333 - weighted_recall_m: 0.7019 - val_loss: 0.8714 - val_accuracy: 0.4854 - val_mse: 0.8714 - val_f1_m: 0.7524 - val_precision_m: 0.8355 - val_recall_m: 0.6939 - val_weighted_accuracy: 0.4854 - val_weighted_mse: 0.8714 - val_weighted_f1_m: 0.7524 - val_weighted_precision_m: 0.8355 - val_weighted_recall_m: 0.6939\n",
            "Epoch 120/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8585 - accuracy: 0.4869 - mse: 0.8585 - f1_m: 0.7572 - precision_m: 0.8299 - recall_m: 0.7055 - weighted_accuracy: 0.4869 - weighted_mse: 0.8585 - weighted_f1_m: 0.7572 - weighted_precision_m: 0.8299 - weighted_recall_m: 0.7055 - val_loss: 0.8689 - val_accuracy: 0.4869 - val_mse: 0.8689 - val_f1_m: 0.7439 - val_precision_m: 0.8254 - val_recall_m: 0.6856 - val_weighted_accuracy: 0.4869 - val_weighted_mse: 0.8689 - val_weighted_f1_m: 0.7439 - val_weighted_precision_m: 0.8254 - val_weighted_recall_m: 0.6856\n",
            "Epoch 121/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8564 - accuracy: 0.4875 - mse: 0.8564 - f1_m: 0.7565 - precision_m: 0.8183 - recall_m: 0.7134 - weighted_accuracy: 0.4875 - weighted_mse: 0.8564 - weighted_f1_m: 0.7565 - weighted_precision_m: 0.8183 - weighted_recall_m: 0.7134 - val_loss: 0.8735 - val_accuracy: 0.4842 - val_mse: 0.8735 - val_f1_m: 0.7489 - val_precision_m: 0.7785 - val_recall_m: 0.7308 - val_weighted_accuracy: 0.4842 - val_weighted_mse: 0.8735 - val_weighted_f1_m: 0.7489 - val_weighted_precision_m: 0.7785 - val_weighted_recall_m: 0.7308\n",
            "Epoch 122/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8559 - accuracy: 0.4876 - mse: 0.8559 - f1_m: 0.7561 - precision_m: 0.8283 - recall_m: 0.7050 - weighted_accuracy: 0.4876 - weighted_mse: 0.8559 - weighted_f1_m: 0.7561 - weighted_precision_m: 0.8283 - weighted_recall_m: 0.7050 - val_loss: 0.8690 - val_accuracy: 0.4857 - val_mse: 0.8690 - val_f1_m: 0.7518 - val_precision_m: 0.8245 - val_recall_m: 0.7003 - val_weighted_accuracy: 0.4857 - val_weighted_mse: 0.8690 - val_weighted_f1_m: 0.7518 - val_weighted_precision_m: 0.8245 - val_weighted_recall_m: 0.7003\n",
            "Epoch 123/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8598 - accuracy: 0.4873 - mse: 0.8598 - f1_m: 0.7552 - precision_m: 0.8279 - recall_m: 0.7062 - weighted_accuracy: 0.4873 - weighted_mse: 0.8598 - weighted_f1_m: 0.7552 - weighted_precision_m: 0.8279 - weighted_recall_m: 0.7062 - val_loss: 0.8758 - val_accuracy: 0.4821 - val_mse: 0.8758 - val_f1_m: 0.7373 - val_precision_m: 0.8214 - val_recall_m: 0.6781 - val_weighted_accuracy: 0.4821 - val_weighted_mse: 0.8758 - val_weighted_f1_m: 0.7373 - val_weighted_precision_m: 0.8214 - val_weighted_recall_m: 0.6781\n",
            "Epoch 124/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8569 - accuracy: 0.4874 - mse: 0.8569 - f1_m: 0.7542 - precision_m: 0.8215 - recall_m: 0.7076 - weighted_accuracy: 0.4874 - weighted_mse: 0.8569 - weighted_f1_m: 0.7542 - weighted_precision_m: 0.8215 - weighted_recall_m: 0.7076 - val_loss: 0.8672 - val_accuracy: 0.4865 - val_mse: 0.8672 - val_f1_m: 0.7460 - val_precision_m: 0.8308 - val_recall_m: 0.6856 - val_weighted_accuracy: 0.4865 - val_weighted_mse: 0.8672 - val_weighted_f1_m: 0.7460 - val_weighted_precision_m: 0.8308 - val_weighted_recall_m: 0.6856\n",
            "Epoch 125/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8644 - accuracy: 0.4857 - mse: 0.8644 - f1_m: 0.7500 - precision_m: 0.8254 - recall_m: 0.6983 - weighted_accuracy: 0.4857 - weighted_mse: 0.8644 - weighted_f1_m: 0.7500 - weighted_precision_m: 0.8254 - weighted_recall_m: 0.6983 - val_loss: 0.8701 - val_accuracy: 0.4855 - val_mse: 0.8701 - val_f1_m: 0.7484 - val_precision_m: 0.7935 - val_recall_m: 0.7176 - val_weighted_accuracy: 0.4855 - val_weighted_mse: 0.8701 - val_weighted_f1_m: 0.7484 - val_weighted_precision_m: 0.7935 - val_weighted_recall_m: 0.7176\n",
            "Epoch 126/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8592 - accuracy: 0.4862 - mse: 0.8592 - f1_m: 0.7550 - precision_m: 0.8252 - recall_m: 0.7062 - weighted_accuracy: 0.4862 - weighted_mse: 0.8592 - weighted_f1_m: 0.7550 - weighted_precision_m: 0.8252 - weighted_recall_m: 0.7062 - val_loss: 0.8756 - val_accuracy: 0.4856 - val_mse: 0.8756 - val_f1_m: 0.7375 - val_precision_m: 0.8378 - val_recall_m: 0.6679 - val_weighted_accuracy: 0.4856 - val_weighted_mse: 0.8756 - val_weighted_f1_m: 0.7375 - val_weighted_precision_m: 0.8378 - val_weighted_recall_m: 0.6679\n",
            "Epoch 127/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8610 - accuracy: 0.4865 - mse: 0.8610 - f1_m: 0.7521 - precision_m: 0.8215 - recall_m: 0.7040 - weighted_accuracy: 0.4865 - weighted_mse: 0.8610 - weighted_f1_m: 0.7521 - weighted_precision_m: 0.8215 - weighted_recall_m: 0.7040 - val_loss: 0.8751 - val_accuracy: 0.4836 - val_mse: 0.8751 - val_f1_m: 0.7310 - val_precision_m: 0.8364 - val_recall_m: 0.6574 - val_weighted_accuracy: 0.4836 - val_weighted_mse: 0.8751 - val_weighted_f1_m: 0.7310 - val_weighted_precision_m: 0.8364 - val_weighted_recall_m: 0.6574\n",
            "Epoch 128/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8546 - accuracy: 0.4873 - mse: 0.8546 - f1_m: 0.7561 - precision_m: 0.8207 - recall_m: 0.7113 - weighted_accuracy: 0.4873 - weighted_mse: 0.8546 - weighted_f1_m: 0.7561 - weighted_precision_m: 0.8207 - weighted_recall_m: 0.7113 - val_loss: 0.8721 - val_accuracy: 0.4835 - val_mse: 0.8721 - val_f1_m: 0.7441 - val_precision_m: 0.8072 - val_recall_m: 0.6994 - val_weighted_accuracy: 0.4835 - val_weighted_mse: 0.8721 - val_weighted_f1_m: 0.7441 - val_weighted_precision_m: 0.8072 - val_weighted_recall_m: 0.6994\n",
            "Epoch 129/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8588 - accuracy: 0.4874 - mse: 0.8588 - f1_m: 0.7558 - precision_m: 0.8180 - recall_m: 0.7141 - weighted_accuracy: 0.4874 - weighted_mse: 0.8588 - weighted_f1_m: 0.7558 - weighted_precision_m: 0.8180 - weighted_recall_m: 0.7141 - val_loss: 0.8672 - val_accuracy: 0.4867 - val_mse: 0.8672 - val_f1_m: 0.7469 - val_precision_m: 0.8053 - val_recall_m: 0.7051 - val_weighted_accuracy: 0.4867 - val_weighted_mse: 0.8672 - val_weighted_f1_m: 0.7469 - val_weighted_precision_m: 0.8053 - val_weighted_recall_m: 0.7051\n",
            "Epoch 130/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8555 - accuracy: 0.4887 - mse: 0.8555 - f1_m: 0.7596 - precision_m: 0.8243 - recall_m: 0.7141 - weighted_accuracy: 0.4887 - weighted_mse: 0.8555 - weighted_f1_m: 0.7596 - weighted_precision_m: 0.8243 - weighted_recall_m: 0.7141 - val_loss: 0.9016 - val_accuracy: 0.4764 - val_mse: 0.9016 - val_f1_m: 0.7450 - val_precision_m: 0.7421 - val_recall_m: 0.7582 - val_weighted_accuracy: 0.4764 - val_weighted_mse: 0.9016 - val_weighted_f1_m: 0.7450 - val_weighted_precision_m: 0.7421 - val_weighted_recall_m: 0.7582\n",
            "Epoch 131/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8610 - accuracy: 0.4869 - mse: 0.8610 - f1_m: 0.7536 - precision_m: 0.8260 - recall_m: 0.7035 - weighted_accuracy: 0.4869 - weighted_mse: 0.8610 - weighted_f1_m: 0.7536 - weighted_precision_m: 0.8260 - weighted_recall_m: 0.7035 - val_loss: 0.8698 - val_accuracy: 0.4849 - val_mse: 0.8698 - val_f1_m: 0.7438 - val_precision_m: 0.8118 - val_recall_m: 0.6951 - val_weighted_accuracy: 0.4849 - val_weighted_mse: 0.8698 - val_weighted_f1_m: 0.7438 - val_weighted_precision_m: 0.8118 - val_weighted_recall_m: 0.6951\n",
            "Epoch 132/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8538 - accuracy: 0.4881 - mse: 0.8538 - f1_m: 0.7611 - precision_m: 0.8222 - recall_m: 0.7179 - weighted_accuracy: 0.4881 - weighted_mse: 0.8538 - weighted_f1_m: 0.7611 - weighted_precision_m: 0.8222 - weighted_recall_m: 0.7179 - val_loss: 0.8686 - val_accuracy: 0.4870 - val_mse: 0.8686 - val_f1_m: 0.7550 - val_precision_m: 0.8220 - val_recall_m: 0.7074 - val_weighted_accuracy: 0.4870 - val_weighted_mse: 0.8686 - val_weighted_f1_m: 0.7550 - val_weighted_precision_m: 0.8220 - val_weighted_recall_m: 0.7074\n",
            "Epoch 133/300\n",
            "996/996 [==============================] - 8s 8ms/step - loss: 0.8531 - accuracy: 0.4881 - mse: 0.8531 - f1_m: 0.7602 - precision_m: 0.8304 - recall_m: 0.7108 - weighted_accuracy: 0.4881 - weighted_mse: 0.8531 - weighted_f1_m: 0.7602 - weighted_precision_m: 0.8304 - weighted_recall_m: 0.7108 - val_loss: 0.8682 - val_accuracy: 0.4861 - val_mse: 0.8682 - val_f1_m: 0.7554 - val_precision_m: 0.8025 - val_recall_m: 0.7224 - val_weighted_accuracy: 0.4861 - val_weighted_mse: 0.8682 - val_weighted_f1_m: 0.7554 - val_weighted_precision_m: 0.8025 - val_weighted_recall_m: 0.7224\n",
            "Epoch 134/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8520 - accuracy: 0.4888 - mse: 0.8520 - f1_m: 0.7619 - precision_m: 0.8318 - recall_m: 0.7133 - weighted_accuracy: 0.4888 - weighted_mse: 0.8520 - weighted_f1_m: 0.7619 - weighted_precision_m: 0.8318 - weighted_recall_m: 0.7133 - val_loss: 0.8717 - val_accuracy: 0.4842 - val_mse: 0.8717 - val_f1_m: 0.7508 - val_precision_m: 0.7787 - val_recall_m: 0.7351 - val_weighted_accuracy: 0.4842 - val_weighted_mse: 0.8717 - val_weighted_f1_m: 0.7508 - val_weighted_precision_m: 0.7787 - val_weighted_recall_m: 0.7351\n",
            "Epoch 135/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8542 - accuracy: 0.4884 - mse: 0.8542 - f1_m: 0.7602 - precision_m: 0.8332 - recall_m: 0.7096 - weighted_accuracy: 0.4884 - weighted_mse: 0.8542 - weighted_f1_m: 0.7602 - weighted_precision_m: 0.8332 - weighted_recall_m: 0.7096 - val_loss: 0.8653 - val_accuracy: 0.4875 - val_mse: 0.8653 - val_f1_m: 0.7576 - val_precision_m: 0.8259 - val_recall_m: 0.7089 - val_weighted_accuracy: 0.4875 - val_weighted_mse: 0.8653 - val_weighted_f1_m: 0.7576 - val_weighted_precision_m: 0.8259 - val_weighted_recall_m: 0.7089\n",
            "Epoch 136/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8562 - accuracy: 0.4878 - mse: 0.8562 - f1_m: 0.7580 - precision_m: 0.8246 - recall_m: 0.7107 - weighted_accuracy: 0.4878 - weighted_mse: 0.8562 - weighted_f1_m: 0.7580 - weighted_precision_m: 0.8246 - weighted_recall_m: 0.7107 - val_loss: 0.8746 - val_accuracy: 0.4827 - val_mse: 0.8746 - val_f1_m: 0.7336 - val_precision_m: 0.8214 - val_recall_m: 0.6720 - val_weighted_accuracy: 0.4827 - val_weighted_mse: 0.8746 - val_weighted_f1_m: 0.7336 - val_weighted_precision_m: 0.8214 - val_weighted_recall_m: 0.6720\n",
            "Epoch 137/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8567 - accuracy: 0.4879 - mse: 0.8567 - f1_m: 0.7581 - precision_m: 0.8217 - recall_m: 0.7132 - weighted_accuracy: 0.4879 - weighted_mse: 0.8567 - weighted_f1_m: 0.7581 - weighted_precision_m: 0.8217 - weighted_recall_m: 0.7132 - val_loss: 0.8675 - val_accuracy: 0.4872 - val_mse: 0.8675 - val_f1_m: 0.7473 - val_precision_m: 0.8335 - val_recall_m: 0.6857 - val_weighted_accuracy: 0.4872 - val_weighted_mse: 0.8675 - val_weighted_f1_m: 0.7473 - val_weighted_precision_m: 0.8335 - val_weighted_recall_m: 0.6857\n",
            "Epoch 138/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8548 - accuracy: 0.4873 - mse: 0.8548 - f1_m: 0.7588 - precision_m: 0.8307 - recall_m: 0.7087 - weighted_accuracy: 0.4873 - weighted_mse: 0.8548 - weighted_f1_m: 0.7588 - weighted_precision_m: 0.8307 - weighted_recall_m: 0.7087 - val_loss: 0.8708 - val_accuracy: 0.4866 - val_mse: 0.8708 - val_f1_m: 0.7383 - val_precision_m: 0.8301 - val_recall_m: 0.6733 - val_weighted_accuracy: 0.4866 - val_weighted_mse: 0.8708 - val_weighted_f1_m: 0.7383 - val_weighted_precision_m: 0.8301 - val_weighted_recall_m: 0.6733\n",
            "Epoch 139/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8539 - accuracy: 0.4882 - mse: 0.8539 - f1_m: 0.7587 - precision_m: 0.8260 - recall_m: 0.7108 - weighted_accuracy: 0.4882 - weighted_mse: 0.8539 - weighted_f1_m: 0.7587 - weighted_precision_m: 0.8260 - weighted_recall_m: 0.7108 - val_loss: 0.8658 - val_accuracy: 0.4856 - val_mse: 0.8658 - val_f1_m: 0.7453 - val_precision_m: 0.8142 - val_recall_m: 0.6963 - val_weighted_accuracy: 0.4856 - val_weighted_mse: 0.8658 - val_weighted_f1_m: 0.7453 - val_weighted_precision_m: 0.8142 - val_weighted_recall_m: 0.6963\n",
            "Epoch 140/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8734 - accuracy: 0.4837 - mse: 0.8734 - f1_m: 0.7503 - precision_m: 0.8176 - recall_m: 0.7048 - weighted_accuracy: 0.4837 - weighted_mse: 0.8734 - weighted_f1_m: 0.7503 - weighted_precision_m: 0.8176 - weighted_recall_m: 0.7048 - val_loss: 0.8889 - val_accuracy: 0.4797 - val_mse: 0.8889 - val_f1_m: 0.7387 - val_precision_m: 0.7621 - val_recall_m: 0.7271 - val_weighted_accuracy: 0.4797 - val_weighted_mse: 0.8889 - val_weighted_f1_m: 0.7387 - val_weighted_precision_m: 0.7621 - val_weighted_recall_m: 0.7271\n",
            "Epoch 141/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8636 - accuracy: 0.4858 - mse: 0.8636 - f1_m: 0.7496 - precision_m: 0.8355 - recall_m: 0.6899 - weighted_accuracy: 0.4858 - weighted_mse: 0.8636 - weighted_f1_m: 0.7496 - weighted_precision_m: 0.8355 - weighted_recall_m: 0.6899 - val_loss: 0.8763 - val_accuracy: 0.4822 - val_mse: 0.8763 - val_f1_m: 0.7361 - val_precision_m: 0.8334 - val_recall_m: 0.6683 - val_weighted_accuracy: 0.4822 - val_weighted_mse: 0.8763 - val_weighted_f1_m: 0.7361 - val_weighted_precision_m: 0.8334 - val_weighted_recall_m: 0.6683\n",
            "Epoch 142/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8587 - accuracy: 0.4873 - mse: 0.8587 - f1_m: 0.7573 - precision_m: 0.8287 - recall_m: 0.7082 - weighted_accuracy: 0.4873 - weighted_mse: 0.8587 - weighted_f1_m: 0.7573 - weighted_precision_m: 0.8287 - weighted_recall_m: 0.7082 - val_loss: 0.8711 - val_accuracy: 0.4852 - val_mse: 0.8711 - val_f1_m: 0.7347 - val_precision_m: 0.8288 - val_recall_m: 0.6686 - val_weighted_accuracy: 0.4852 - val_weighted_mse: 0.8711 - val_weighted_f1_m: 0.7347 - val_weighted_precision_m: 0.8288 - val_weighted_recall_m: 0.6686\n",
            "Epoch 143/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8555 - accuracy: 0.4878 - mse: 0.8555 - f1_m: 0.7565 - precision_m: 0.8311 - recall_m: 0.7050 - weighted_accuracy: 0.4878 - weighted_mse: 0.8555 - weighted_f1_m: 0.7565 - weighted_precision_m: 0.8311 - weighted_recall_m: 0.7050 - val_loss: 0.8692 - val_accuracy: 0.4868 - val_mse: 0.8692 - val_f1_m: 0.7518 - val_precision_m: 0.8463 - val_recall_m: 0.6856 - val_weighted_accuracy: 0.4868 - val_weighted_mse: 0.8692 - val_weighted_f1_m: 0.7518 - val_weighted_precision_m: 0.8463 - val_weighted_recall_m: 0.6856\n",
            "Epoch 144/300\n",
            "996/996 [==============================] - 6s 6ms/step - loss: 0.8524 - accuracy: 0.4887 - mse: 0.8524 - f1_m: 0.7614 - precision_m: 0.8329 - recall_m: 0.7104 - weighted_accuracy: 0.4887 - weighted_mse: 0.8524 - weighted_f1_m: 0.7614 - weighted_precision_m: 0.8329 - weighted_recall_m: 0.7104 - val_loss: 0.8779 - val_accuracy: 0.4843 - val_mse: 0.8779 - val_f1_m: 0.7321 - val_precision_m: 0.8618 - val_recall_m: 0.6451 - val_weighted_accuracy: 0.4843 - val_weighted_mse: 0.8779 - val_weighted_f1_m: 0.7321 - val_weighted_precision_m: 0.8618 - val_weighted_recall_m: 0.6451\n",
            "Epoch 145/300\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 0.8565 - accuracy: 0.4875 - mse: 0.8565 - f1_m: 0.7571 - precision_m: 0.8329 - recall_m: 0.7043 - weighted_accuracy: 0.4875 - weighted_mse: 0.8565 - weighted_f1_m: 0.7571 - weighted_precision_m: 0.8329 - weighted_recall_m: 0.7043 - val_loss: 0.8699 - val_accuracy: 0.4862 - val_mse: 0.8699 - val_f1_m: 0.7334 - val_precision_m: 0.8329 - val_recall_m: 0.6640 - val_weighted_accuracy: 0.4862 - val_weighted_mse: 0.8699 - val_weighted_f1_m: 0.7334 - val_weighted_precision_m: 0.8329 - val_weighted_recall_m: 0.6640\n",
            "Epoch 146/300\n",
            "515/996 [==============>...............] - ETA: 2s - loss: 0.8525 - accuracy: 0.4883 - mse: 0.8525 - f1_m: 0.7611 - precision_m: 0.8378 - recall_m: 0.7073 - weighted_accuracy: 0.4883 - weighted_mse: 0.8525 - weighted_f1_m: 0.7611 - weighted_precision_m: 0.8378 - weighted_recall_m: 0.7073"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bd4b57b873a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m               weighted_metrics=['accuracy', 'mse', f1_m,precision_m, recall_m])\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mMLP_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "# Multi Layer Perceptron\n",
        "\n",
        "y_train=np.asarray(y_train ,dtype=int)\n",
        "MLP_model = Sequential()\n",
        "MLP_model.add(Dense(1024, activation='relu',  input_dim = 18 ))\n",
        "MLP_model.add(Dense(512, activation='relu'))\n",
        "MLP_model.add(Dense(256,activation='relu'))\n",
        "MLP_model.add(Dense(128,activation='relu'))\n",
        "MLP_model.add(Dense(64,activation='relu'))\n",
        "MLP_model.add(Dense(32,activation='relu'))\n",
        "MLP_model.add(Dense(16,activation='relu'))\n",
        "MLP_model.add(Dense(8,activation='relu'))\n",
        "MLP_model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "MLP_model.compile(optimizer=Adam(lr=0.001), loss= tf.keras.losses.MeanSquaredError(), \n",
        "              metrics=['accuracy', 'mse', f1_m,precision_m, recall_m],\n",
        "              weighted_metrics=['accuracy', 'mse', f1_m,precision_m, recall_m])\n",
        "\n",
        "MLP_model.fit(X_train, y_train, validation_data = (X_valid,y_valid), epochs= 300, batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7sWlBA00bih"
      },
      "outputs": [],
      "source": [
        "from keras.engine.base_layer import Layer\n",
        "# Linear Regression: Standard and Bayesian Ridge\n",
        "\n",
        "def MLP_Classifier(act_fctn, layer, X_train, y_train,X_test, y_test):\n",
        "\n",
        "  nlp_model = MLPClassifier(activation = act_fctn, hidden_layer_sizes = (layer,))\n",
        "  nlp_model.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = nlp_model.predict(X_test)\n",
        "\n",
        "  RMSE = mean_squared_error(y_test, y_pred)\n",
        "  # r2_score = r2_score(y_test, y_pred)\n",
        "  accuracy = accuracy_score(y_test, y_pred)*100\n",
        "\n",
        "  print(\"RMSE = %.3f \" %RMSE, '\\n' )\n",
        "  # print(\"r2 Score  = %.3f \" %r2, '% \\n' )\n",
        "  print(f'Accuracy for activation {act_fctn} for {layer} : %.4f' % accuracy)\n",
        "  print('f1 score : %.4f' % (f1_score(y_test, y_pred, average='micro')))\n",
        "\n",
        "\n",
        "  return nlp_model, accuracy, nlp_model.score(X_test, y_test)\n",
        "\n",
        "act_fcts = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
        "\n",
        "layers = np.arange(1, 10, 2)\n",
        "act_fct = \"logistic\"\n",
        "\n",
        "Score_NLC_Id = []; Score_NLC_lg = []; Score_NLC_t = []; Score_NLC_rl = []\n",
        "Accuracy_NLC_Id = []; Accuracy_NLC_lg = []; Accuracy_NLC_t = []; Accuracy_NLC_rl = []\n",
        "\n",
        "i = 0\n",
        "\n",
        "for act_fct in act_fcts:    \n",
        "  for layer in layers:\n",
        "    \n",
        "    model_nlp, accuracy, score = MLP_Classifier(act_fct, layer, X_train, y_train,X_test, y_test) \n",
        "    if i == 0:\n",
        "      Score_NLC_Id.append(score)\n",
        "      Accuracy_NLC_Id.append(accuracy)\n",
        "    if i == 1:\n",
        "      Score_NLC_lg.append(score)\n",
        "      Accuracy_NLC_lg.append(accuracy)\n",
        "    if i == 2:\n",
        "      Score_NLC_t.append(score)\n",
        "      Accuracy_NLC_t.append(accuracy)\n",
        "    if i == 3: \n",
        "      Score_NLC_rl.append(score)\n",
        "      Accuracy_NLC_rl.append(accuracy)\n",
        "  i= i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJxQYLmDZ3SM"
      },
      "outputs": [],
      "source": [
        "model_nlp, accuracy, score = MLP_Classifier('logistic', 10, X_train, y_train,X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL3eDjWraSi_"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'MLP_Function_Lib_Model_Thermal_Comfort.pt'\n",
        "path = f\"/content/drive/MyDrive/WPI/Deep Learning/Project/Models Trained/ Thermal_Comfort/{model_save_name}\" \n",
        "model.save(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE1GYP2D1hCE"
      },
      "source": [
        "### CNN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDqgHB0uyHde"
      },
      "outputs": [],
      "source": [
        "# CNN\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim = 18, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss= tf.keras.losses.MeanSquaredError(), \n",
        "              metrics=['accuracy', 'mse', f1_m,precision_m, recall_m],\n",
        "              weighted_metrics=['accuracy', 'mse', f1_m,precision_m, recall_m])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data = (X_valid,y_valid), epochs= 500, batch_size = 120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS6FpPvo0n8H"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model_save_name = 'CNN_Model_Thermal_Comfort_1.pt'\n",
        "path = f\"/content/drive/MyDrive/WPI/Deep Learning/Project/Models Trained/ Thermal_Comfort/{model_save_name}\" \n",
        "model.save(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blwL8RyA1F8-"
      },
      "outputs": [],
      "source": [
        "# CNN\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim = 18, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss= tf.keras.losses.MeanSquaredError(), \n",
        "              metrics=['accuracy', 'mse', f1_m,precision_m, recall_m],\n",
        "              weighted_metrics=['accuracy', 'mse', f1_m,precision_m, recall_m])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data = (X_valid,y_valid), epochs= 100, batch_size=235)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAh2f8CPQrsc"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model_save_name = 'CNN_Model_Thermal_Comfort.pt'\n",
        "path = f\"/content/drive/MyDrive/WPI/Deep Learning/Project/Models Trained/ Thermal_Comfort/{model_save_name}\" \n",
        "model.save(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9e4OJky1fty"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrsosF2H5Pkd"
      },
      "outputs": [],
      "source": [
        "df_ashrae = pd.read_csv(\"/content/drive/MyDrive/WPI/Deep Learning/Project/db_measurements_v2.1.0.csv\")\n",
        "\n",
        "df_ashrae_mod = df_ashrae[['age', 'gender', 't_out', 'ta', 'rh', 'vel', 'tr', 'thermal_acceptability',\n",
        "                           'thermal_preference', 'thermal_comfort', 'met', 'clo', 'thermal_sensation']]\n",
        "\n",
        "columns = df_ashrae_mod.columns\n",
        "df_ashrae_mod = df_ashrae_mod.dropna().reset_index().drop('index', axis = 1)         \n",
        "\n",
        "#Making the range from [-3,3] to[2,2]\n",
        "df_ashrae_mod['thermal_sensation'] = df_ashrae_mod['thermal_sensation'].apply(lambda x: -2 if x <= -2 else x)\n",
        "df_ashrae_mod['thermal_sensation'] = df_ashrae_mod['thermal_sensation'].apply(lambda x: 2 if x >= 2 else x)\n",
        "#Rounding off the values to make it categorical in nature \n",
        "df_ashrae_mod['thermal_sensation'] = df_ashrae_mod['thermal_sensation'].apply(lambda x: np.round(x))\n",
        "df_ashrae_mod = df_ashrae_mod.round(3)\n",
        "\n",
        "# Sampling Minority Data\n",
        "\n",
        "X = df_ashrae_mod.drop(['thermal_sensation'], axis = 1)\n",
        "y = df_ashrae_mod[ 'thermal_sensation']\n",
        "\n",
        "X = pd.get_dummies(X, columns =['gender', 'thermal_acceptability' , 'thermal_preference'])\n",
        "X = X.values\n",
        "y = y.values\n",
        "sm = RandomOverSampler(sampling_strategy = 'minority', random_state=42)\n",
        "X_resampled, y_resampled = sm.fit_resample(X, y)\n",
        "\n",
        "from collections import Counter\n",
        "print('Original dataset shape %s' % Counter(y))\n",
        "print('Original dataset shape %s' % Counter(y_resampled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYtTvmndxL8V"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=5)\n",
        "y_test = to_categorical(y_test, num_classes=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYgZu0fCJQ5Y"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Embedding,Conv1D,LSTM,Input,TimeDistributed,SpatialDropout1D,Flatten,Dropout, Bidirectional\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(256, return_sequences=True))\n",
        "model_lstm.add(LSTM(128, return_sequences=True))\n",
        "model_lstm.add(Dense(8,activation='sigmoid'))\n",
        "model_lstm.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "\n",
        "model_lstm.compile(optimizer=Adam(lr=0.001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy', 'mse', f1_m,precision_m, recall_m],\n",
        "              weighted_metrics=['accuracy', 'mse', f1_m,precision_m, recall_m])\n",
        "\n",
        "model_lstm.fit(X_train, y_train, epochs = 150, validation_data=(X_test,y_test), batch_size = 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1_7rBTx0uFL"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'LSTM_Model_Thermal_Comfort_1.pt'\n",
        "path = f\"/content/drive/MyDrive/WPI/Deep Learning/Project/Models Trained/ Thermal_Comfort/{model_save_name}\" \n",
        "model.save(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA0fSCbSc5vn"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Embedding,Conv1D,LSTM,Input,TimeDistributed,SpatialDropout1D,Flatten,Dropout, Bidirectional\n",
        "\n",
        "model=Sequential()\n",
        "x_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1],-1)\n",
        "model.add(LSTM(256, return_sequences=True, input_shape=(18,1)))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001),\n",
        "              loss = tf.keras.losses.MeanSquaredError() ,\n",
        "              metrics=['accuracy', 'mse', f1_m,precision_m, recall_m],\n",
        "              weighted_metrics=['accuracy', 'mse', f1_m,precision_m, recall_m])\n",
        "  \n",
        "model.fit(x_train, y_train, epochs = 150, validation_data=(X_valid,y_valid), batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny5QtypGdtUb"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'LSTM_Model_Thermal_Comfort.pt'\n",
        "path = f\"/content/drive/MyDrive/WPI/Deep Learning/Project/Models Trained/ Thermal_Comfort/{model_save_name}\" \n",
        "model.save(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwLLZCch1suQ"
      },
      "source": [
        "### bi_LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPLB_B9o1tF6"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional, Embedding, Flatten\n",
        "\n",
        "model=Sequential()\n",
        "x_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1],-1)\n",
        "model.add(Bidirectional(LSTM(256,return_sequences=True, input_shape=(18,1))))\n",
        "model.add(LSTM(256,return_sequences=True))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(1,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001),\n",
        "              loss = tf.keras.losses.MeanSquaredError() ,\n",
        "              metrics=['accuracy', 'mse', f1_m,precision_m, recall_m],\n",
        "              weighted_metrics=['accuracy', 'mse', f1_m,precision_m, recall_m])\n",
        "  \n",
        "model.fit(x_train, y_train, validation_data=(X_valid,y_valid), epochs = 100,  batch_size = 235)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsSoJmfoPqhx"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'Bi_LSTM_Model_Thermal_Comfort.pt'\n",
        "path = f\"/content/drive/MyDrive/WPI/Deep Learning/Project/Models Trained/ Thermal_Comfort/{model_save_name}\" \n",
        "model.save(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_-OkyAh1igm"
      },
      "source": [
        "### LSTM-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrwOaS1BQP3c"
      },
      "outputs": [],
      "source": [
        "  y_train=np.asarray(y_train ,dtype=int)\n",
        "  y_train=to_categorical(y_train,num_classes=5)\n",
        "  X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],-1)\n",
        "\n",
        "  model=Sequential()\n",
        "  model.add(Conv1D(filters=128,kernel_size=5,padding='same',input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "  model.add(SpatialDropout1D(0.1))\n",
        "  model.add(LSTM(256,return_sequences=True))\n",
        "  model.add(LSTM(256,return_sequences=True))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(32,activation='relu'))\n",
        "  model.add(Dense(16,activation='relu'))\n",
        "  model.add(Dense(8,activation='relu'))\n",
        "  model.add(Dense(5,activation='softmax'))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'],weighted_metrics=['accuracy'])\n",
        "  \n",
        "  checkpoint_filepath = '/tmp/checkpoint'\n",
        "  \n",
        "  es=ModelCheckpoint(filepath=checkpoint_filepath,monitor='val_accuracy',save_best_only=True,mode='max',save_weights_only=True)\n",
        "  model.fit(X_train,y_train,epochs=100,validation_split=0.2,batch_size=64,callbacks=[es],class_weight=weight_dicts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYitBNII055B"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'LSTM_CNN_Model_Thermal_Comfort.pt'\n",
        "path = f\"/content/drive/MyDrive/WPI/Deep Learning/Project/Models Trained/ Thermal_Comfort/{model_save_name}\" \n",
        "model.save(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-UBjkY9QRG8"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nngZNJAJRvw5"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "X_train1=X_train_temp.reshape(X_train_temp.shape[0],X_train_temp.shape[1],-1)\n",
        "model.add(LSTM(256,return_sequences=True,input_shape=(X_train1.shape[1],X_train1.shape[2])))\n",
        "model.add(LSTM(256,return_sequences=True))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(16,activation='relu'))\n",
        "model.add(Dense(8,activation='relu'))\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "\n",
        "\n",
        "model.layers[-1].set_weights(weights)\n",
        "model.layers[-1].trainable=False\n",
        "\n",
        "\n",
        "X_t1,X_t2,y_t1,y_t2=train_test_split(X_test,y_test,test_size=0.1,random_state=2)\n",
        "\n",
        "X_t=X_t1.values\n",
        "X_t=X_t.reshape(X_t.shape[0],X_t.shape[1],-1)\n",
        "\n",
        "#Target domain DL model\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'],weighted_metrics=['accuracy'])\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "es=ModelCheckpoint(filepath=checkpoint_filepath,monitor='val_accuracy',save_best_only=True,mode='max',save_weights_only=True)\n",
        "model.fit(X_t,y_t1,epochs=100,validation_split=0.2,batch_size=64,callbacks=[es])\n",
        "model.load_weights(checkpoint_filepath)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8 (main, Oct 13 2022, 10:17:43) [Clang 14.0.0 (clang-1400.0.29.102)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
